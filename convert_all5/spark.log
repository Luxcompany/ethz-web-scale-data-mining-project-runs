2014-07-10 20:37:15,719 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-10 20:37:15,721 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-10 20:37:16,182 [sparkMaster-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-10 20:37:16,250 [sparkMaster-akka.actor.default-dispatcher-5] INFO  Remoting - Starting remoting
2014-07-10 20:37:16,433 [sparkMaster-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077]
2014-07-10 20:37:16,674 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Starting Spark master at spark://dco-node121.dco.ethz.ch:7077
2014-07-10 20:37:16,702 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:37:16,763 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:8080
2014-07-10 20:37:16,766 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.ui.MasterWebUI - Started MasterWebUI at http://dco-node121-mgt.dco.ethz.ch:8080
2014-07-10 20:37:16,786 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - I have been elected leader! New state: ALIVE
2014-07-10 20:37:17,984 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-10 20:37:17,986 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-10 20:37:18,439 [sparkWorker-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-10 20:37:18,508 [sparkWorker-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-10 20:37:18,695 [sparkWorker-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:52004]
2014-07-10 20:37:18,865 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker dco-node121-mgt.dco.ethz.ch:52004 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:18,865 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /root/spark
2014-07-10 20:37:18,952 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:37:19,007 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:8081
2014-07-10 20:37:19,009 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Started WorkerWebUI at http://dco-node121-mgt.dco.ethz.ch:8081
2014-07-10 20:37:19,010 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark://dco-node121.dco.ethz.ch:7077...
2014-07-10 20:37:19,482 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node126-mgt.dco.ethz.ch:33819 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,493 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node135-mgt.dco.ethz.ch:45535 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,494 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node130-mgt.dco.ethz.ch:42939 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,495 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node128-mgt.dco.ethz.ch:48003 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,496 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node124-mgt.dco.ethz.ch:44781 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,497 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node133-mgt.dco.ethz.ch:52223 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,499 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node122-mgt.dco.ethz.ch:37368 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,500 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node123-mgt.dco.ethz.ch:44579 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,501 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node121-mgt.dco.ethz.ch:52004 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,502 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node131-mgt.dco.ethz.ch:50274 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,505 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node127-mgt.dco.ethz.ch:59067 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,506 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node132-mgt.dco.ethz.ch:33279 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,507 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node136-mgt.dco.ethz.ch:33772 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,509 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node129-mgt.dco.ethz.ch:53498 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,513 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node125-mgt.dco.ethz.ch:34224 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,514 [sparkMaster-akka.actor.default-dispatcher-22] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node134-mgt.dco.ethz.ch:46311 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:19,519 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://dco-node121.dco.ethz.ch:7077
2014-07-10 20:37:27,958 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-10 20:37:27,959 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-10 20:37:28,420 [sparkMaster-akka.actor.default-dispatcher-5] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-10 20:37:28,485 [sparkMaster-akka.actor.default-dispatcher-5] INFO  Remoting - Starting remoting
2014-07-10 20:37:28,683 [sparkMaster-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077]
2014-07-10 20:37:28,923 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Starting Spark master at spark://dco-node121.dco.ethz.ch:7077
2014-07-10 20:37:28,950 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:37:29,006 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:8080
2014-07-10 20:37:29,010 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.ui.MasterWebUI - Started MasterWebUI at http://dco-node121-mgt.dco.ethz.ch:8080
2014-07-10 20:37:29,029 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - I have been elected leader! New state: ALIVE
2014-07-10 20:37:30,229 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-10 20:37:30,231 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-10 20:37:30,688 [sparkWorker-akka.actor.default-dispatcher-6] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-10 20:37:30,744 [sparkWorker-akka.actor.default-dispatcher-6] INFO  Remoting - Starting remoting
2014-07-10 20:37:30,939 [sparkWorker-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]
2014-07-10 20:37:31,117 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Starting Spark worker dco-node121-mgt.dco.ethz.ch:60479 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,117 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Spark home: /root/spark
2014-07-10 20:37:31,205 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:37:31,264 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:8081
2014-07-10 20:37:31,267 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.ui.WorkerWebUI - Started WorkerWebUI at http://dco-node121-mgt.dco.ethz.ch:8081
2014-07-10 20:37:31,268 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Connecting to master spark://dco-node121.dco.ethz.ch:7077...
2014-07-10 20:37:31,709 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node133-mgt.dco.ethz.ch:48081 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,720 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node127-mgt.dco.ethz.ch:34515 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,721 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node125-mgt.dco.ethz.ch:42839 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,722 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node129-mgt.dco.ethz.ch:44845 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,724 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node134-mgt.dco.ethz.ch:39082 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,725 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node130-mgt.dco.ethz.ch:48548 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,726 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node126-mgt.dco.ethz.ch:60480 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,727 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node131-mgt.dco.ethz.ch:51773 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,728 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node124-mgt.dco.ethz.ch:39781 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,730 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node122-mgt.dco.ethz.ch:45826 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,731 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node135-mgt.dco.ethz.ch:58580 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,732 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node121-mgt.dco.ethz.ch:60479 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,734 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node136-mgt.dco.ethz.ch:49584 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,735 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node132-mgt.dco.ethz.ch:60810 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,736 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node128-mgt.dco.ethz.ch:51757 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,737 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering worker dco-node123-mgt.dco.ethz.ch:58212 with 16 cores, 125.0 GB RAM
2014-07-10 20:37:31,745 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Successfully registered with master spark://dco-node121.dco.ethz.ch:7077
2014-07-10 20:38:10,815 [main] WARN  org.apache.spark.SparkConf - 
SPARK_JAVA_OPTS was detected (set to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
2014-07-10 20:38:10,817 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.executor.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-10 20:38:10,818 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.driver.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-10 20:38:10,871 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-10 20:38:10,872 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-10 20:38:11,303 [spark-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-10 20:38:11,362 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-10 20:38:11,539 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]
2014-07-10 20:38:11,541 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]
2014-07-10 20:38:11,571 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2014-07-10 20:38:11,574 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2014-07-10 20:38:11,591 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-local-20140710203811-5390
2014-07-10 20:38:11,595 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-10 20:38:11,624 [main] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 56896 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,56896)
2014-07-10 20:38:11,629 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-10 20:38:11,634 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:56896 with 40.3 GB RAM
2014-07-10 20:38:11,636 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-10 20:38:11,655 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-10 20:38:11,712 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:38:11,733 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:59250
2014-07-10 20:38:11,734 [main] INFO  org.apache.spark.broadcast.HttpBroadcast - Broadcast server started at http://172.31.109.131:59250
2014-07-10 20:38:11,741 [main] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-4585feb3-a582-4a06-b500-3d0e569073e1
2014-07-10 20:38:11,741 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-10 20:38:11,742 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:38:11,745 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:46280
2014-07-10 20:38:12,107 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:38:12,122 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2014-07-10 20:38:12,129 [main] INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://dco-node121-mgt.dco.ethz.ch:4040
2014-07-10 20:38:12,346 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-10 20:38:13,001 [main] INFO  org.apache.spark.scheduler.EventLoggingListener - Logging events to hdfs://dco-node121.dco.ethz.ch:54310/spark_event_log/html-to-text-conversion-application-1405017492453
2014-07-10 20:38:13,254 [main] INFO  org.apache.spark.SparkContext - Added JAR file:/disk3/user_work/runs/convert_all5/run.jar at http://172.31.109.131:46280/jars/run.jar with timestamp 1405017493253
2014-07-10 20:38:13,321 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Connecting to master spark://dco-node121.dco.ethz.ch:7077...
2014-07-10 20:38:13,601 [main] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(239409) called with curMem=0, maxMem=43218213273
2014-07-10 20:38:13,604 [main] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values to memory (estimated size 233.8 KB, free 40.2 GB)
2014-07-10 20:38:13,690 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Registering app HTML to Text Conversion Application
2014-07-10 20:38:13,699 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Registered app HTML to Text Conversion Application with ID app-20140710203813-0000
2014-07-10 20:38:13,725 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-10 20:38:13,725 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Connected to Spark cluster with app ID app-20140710203813-0000
2014-07-10 20:38:13,728 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-10 20:38:13,728 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-10 20:38:13,729 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-10 20:38:13,729 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-10 20:38:13,729 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-10 20:38:13,729 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-10 20:38:13,730 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-10 20:38:13,730 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-10 20:38:13,730 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-10 20:38:13,736 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-10 20:38:13,736 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-10 20:38:13,736 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-10 20:38:13,737 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-10 20:38:13,737 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-10 20:38:13,737 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140710203813-0000/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-10 20:38:13,751 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/0 on worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773 (dco-node131-mgt.dco.ethz.ch:51773) with 16 cores
2014-07-10 20:38:13,753 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/0 on hostPort dco-node131-mgt.dco.ethz.ch:51773 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,753 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/1 on worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480 (dco-node126-mgt.dco.ethz.ch:60480) with 16 cores
2014-07-10 20:38:13,754 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/1 on hostPort dco-node126-mgt.dco.ethz.ch:60480 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,756 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/2 on worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839 (dco-node125-mgt.dco.ethz.ch:42839) with 16 cores
2014-07-10 20:38:13,757 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/2 on hostPort dco-node125-mgt.dco.ethz.ch:42839 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,758 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/3 on worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212 (dco-node123-mgt.dco.ethz.ch:58212) with 16 cores
2014-07-10 20:38:13,758 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/3 on hostPort dco-node123-mgt.dco.ethz.ch:58212 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,759 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/4 on worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580 (dco-node135-mgt.dco.ethz.ch:58580) with 16 cores
2014-07-10 20:38:13,760 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/4 on hostPort dco-node135-mgt.dco.ethz.ch:58580 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,761 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/5 on worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081 (dco-node133-mgt.dco.ethz.ch:48081) with 16 cores
2014-07-10 20:38:13,762 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/5 on hostPort dco-node133-mgt.dco.ethz.ch:48081 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,763 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/6 on worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082 (dco-node134-mgt.dco.ethz.ch:39082) with 16 cores
2014-07-10 20:38:13,763 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/6 on hostPort dco-node134-mgt.dco.ethz.ch:39082 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,764 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/7 on worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515 (dco-node127-mgt.dco.ethz.ch:34515) with 16 cores
2014-07-10 20:38:13,764 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/7 on hostPort dco-node127-mgt.dco.ethz.ch:34515 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,766 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/8 on worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548 (dco-node130-mgt.dco.ethz.ch:48548) with 16 cores
2014-07-10 20:38:13,766 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/8 on hostPort dco-node130-mgt.dco.ethz.ch:48548 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,767 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/9 on worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479 (dco-node121-mgt.dco.ethz.ch:60479) with 16 cores
2014-07-10 20:38:13,767 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/9 on hostPort dco-node121-mgt.dco.ethz.ch:60479 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,768 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/10 on worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757 (dco-node128-mgt.dco.ethz.ch:51757) with 16 cores
2014-07-10 20:38:13,769 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/10 on hostPort dco-node128-mgt.dco.ethz.ch:51757 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,770 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/11 on worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781 (dco-node124-mgt.dco.ethz.ch:39781) with 16 cores
2014-07-10 20:38:13,770 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/11 on hostPort dco-node124-mgt.dco.ethz.ch:39781 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,771 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/12 on worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810 (dco-node132-mgt.dco.ethz.ch:60810) with 16 cores
2014-07-10 20:38:13,772 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/12 on hostPort dco-node132-mgt.dco.ethz.ch:60810 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,772 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/13 on worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826 (dco-node122-mgt.dco.ethz.ch:45826) with 16 cores
2014-07-10 20:38:13,772 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140710203813-0000/9 for HTML to Text Conversion Application
2014-07-10 20:38:13,773 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/13 on hostPort dco-node122-mgt.dco.ethz.ch:45826 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,773 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/14 on worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584 (dco-node136-mgt.dco.ethz.ch:49584) with 16 cores
2014-07-10 20:38:13,773 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/14 on hostPort dco-node136-mgt.dco.ethz.ch:49584 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,774 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140710203813-0000/15 on worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845 (dco-node129-mgt.dco.ethz.ch:44845) with 16 cores
2014-07-10 20:38:13,774 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140710203813-0000/15 on hostPort dco-node129-mgt.dco.ethz.ch:44845 with 16 cores, 70.0 GB RAM
2014-07-10 20:38:13,785 [ExecutorRunner for app-20140710203813-0000/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-10 20:38:13,785 [ExecutorRunner for app-20140710203813-0000/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-10 20:38:13,852 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/11 is now RUNNING
2014-07-10 20:38:13,853 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/10 is now RUNNING
2014-07-10 20:38:13,856 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/3 is now RUNNING
2014-07-10 20:38:13,858 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/8 is now RUNNING
2014-07-10 20:38:13,860 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/4 is now RUNNING
2014-07-10 20:38:13,863 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/5 is now RUNNING
2014-07-10 20:38:13,865 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/9 is now RUNNING
2014-07-10 20:38:13,868 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/13 is now RUNNING
2014-07-10 20:38:13,870 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/14 is now RUNNING
2014-07-10 20:38:13,872 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/2 is now RUNNING
2014-07-10 20:38:13,874 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/15 is now RUNNING
2014-07-10 20:38:13,876 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/0 is now RUNNING
2014-07-10 20:38:13,877 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/6 is now RUNNING
2014-07-10 20:38:13,879 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/12 is now RUNNING
2014-07-10 20:38:13,881 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/1 is now RUNNING
2014-07-10 20:38:13,883 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140710203813-0000/7 is now RUNNING
2014-07-10 20:38:14,783 [ExecutorRunner for app-20140710203813-0000/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140710203813-0000"
2014-07-10 20:38:15,692 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-10 20:38:15,878 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-10 20:38:15,879 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-10 20:38:16,332 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-10 20:38:16,397 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  Remoting - Starting remoting
2014-07-10 20:38:16,602 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]
2014-07-10 20:38:16,606 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]
2014-07-10 20:38:16,624 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705/user/CoarseGrainedScheduler
2014-07-10 20:38:16,630 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-10 20:38:16,820 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-10 20:38:16,859 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node131-mgt.dco.ethz.ch:52255/user/Executor#1377245382] with ID 0
2014-07-10 20:38:16,865 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node133-mgt.dco.ethz.ch:44465/user/Executor#1870005723] with ID 5
2014-07-10 20:38:16,867 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node122-mgt.dco.ethz.ch:37241/user/Executor#1151756116] with ID 13
2014-07-10 20:38:16,869 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node136-mgt.dco.ethz.ch:53434/user/Executor#-1455031341] with ID 14
2014-07-10 20:38:16,877 [spark-akka.actor.default-dispatcher-14] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node132-mgt.dco.ethz.ch:60508/user/Executor#707692403] with ID 12
2014-07-10 20:38:16,893 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node126-mgt.dco.ethz.ch:41761/user/Executor#811226946] with ID 1
2014-07-10 20:38:16,900 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node129-mgt.dco.ethz.ch:35971/user/Executor#-718727463] with ID 15
2014-07-10 20:38:16,902 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node134-mgt.dco.ethz.ch:40798/user/Executor#-2052636235] with ID 6
2014-07-10 20:38:16,908 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node135-mgt.dco.ethz.ch:50725/user/Executor#83311785] with ID 4
2014-07-10 20:38:16,920 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node123-mgt.dco.ethz.ch:48911/user/Executor#980966487] with ID 3
2014-07-10 20:38:16,928 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node127-mgt.dco.ethz.ch:46773/user/Executor#2085928299] with ID 7
2014-07-10 20:38:16,929 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node125-mgt.dco.ethz.ch:41812/user/Executor#-654788476] with ID 2
2014-07-10 20:38:16,933 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node128-mgt.dco.ethz.ch:50998/user/Executor#-776076355] with ID 10
2014-07-10 20:38:16,937 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node124-mgt.dco.ethz.ch:34545/user/Executor#2785634] with ID 11
2014-07-10 20:38:16,939 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node130-mgt.dco.ethz.ch:49483/user/Executor#-934044825] with ID 8
2014-07-10 20:38:16,983 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092/user/Executor#1403842947] with ID 9
2014-07-10 20:38:17,020 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2014-07-10 20:38:17,043 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-10 20:38:17,043 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-10 20:38:17,080 [spark-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-10 20:38:17,090 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-10 20:38:17,111 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:45769]
2014-07-10 20:38:17,113 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:45769]
2014-07-10 20:38:17,128 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SparkEnv - Connecting to MapOutputTracker: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705/user/MapOutputTracker
2014-07-10 20:38:17,164 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node122-mgt.dco.ethz.ch:38077 with 40.3 GB RAM
2014-07-10 20:38:17,170 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node133-mgt.dco.ethz.ch:39395 with 40.3 GB RAM
2014-07-10 20:38:17,170 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node129-mgt.dco.ethz.ch:54358 with 40.3 GB RAM
2014-07-10 20:38:17,171 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node132-mgt.dco.ethz.ch:52218 with 40.3 GB RAM
2014-07-10 20:38:17,172 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node131-mgt.dco.ethz.ch:51850 with 40.3 GB RAM
2014-07-10 20:38:17,175 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node126-mgt.dco.ethz.ch:44084 with 40.3 GB RAM
2014-07-10 20:38:17,176 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:47137 with 40.3 GB RAM
2014-07-10 20:38:17,177 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node136-mgt.dco.ethz.ch:51828 with 40.3 GB RAM
2014-07-10 20:38:17,184 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SparkEnv - Connecting to BlockManagerMaster: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705/user/BlockManagerMaster
2014-07-10 20:38:17,192 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node123-mgt.dco.ethz.ch:33135 with 40.3 GB RAM
2014-07-10 20:38:17,200 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node127-mgt.dco.ethz.ch:45675 with 40.3 GB RAM
2014-07-10 20:38:17,204 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node128-mgt.dco.ethz.ch:34757 with 40.3 GB RAM
2014-07-10 20:38:17,206 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node135-mgt.dco.ethz.ch:52568 with 40.3 GB RAM
2014-07-10 20:38:17,209 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node125-mgt.dco.ethz.ch:43565 with 40.3 GB RAM
2014-07-10 20:38:17,213 [spark-akka.actor.default-dispatcher-35] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node124-mgt.dco.ethz.ch:42779 with 40.3 GB RAM
2014-07-10 20:38:17,217 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node130-mgt.dco.ethz.ch:60619 with 40.3 GB RAM
2014-07-10 20:38:17,230 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /disk3/spark_local_dirs/spark-local-20140710203817-ec2f
2014-07-10 20:38:17,235 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-10 20:38:17,266 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 40066 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,40066)
2014-07-10 20:38:17,272 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-10 20:38:17,284 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:40066 with 40.3 GB RAM
2014-07-10 20:38:17,290 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-10 20:38:17,318 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-1e40458d-ce45-41a8-a620-bcc58cc1ea91
2014-07-10 20:38:17,321 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-10 20:38:17,382 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-10 20:38:17,404 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:35762
2014-07-10 20:41:02,515 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 33447
2014-07-10 20:43:56,028 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 33447
2014-07-10 20:43:56,182 [main] INFO  org.apache.hadoop.mapreduce.lib.input.CombineFileInputFormat - DEBUG: Terminated node allocation with : CompletedNodes: 1, size left: 909764664
2014-07-10 20:43:56,218 [main] INFO  org.apache.spark.SparkContext - Starting job: foreach at HtmlToTextConversionApp.scala:57
2014-07-10 20:43:56,241 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.scheduler.DAGScheduler - Got job 0 (foreach at HtmlToTextConversionApp.scala:57) with 497 output partitions (allowLocal=false)
2014-07-10 20:43:56,241 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.scheduler.DAGScheduler - Final stage: Stage 0(foreach at HtmlToTextConversionApp.scala:57)
2014-07-10 20:43:56,242 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
2014-07-10 20:43:56,258 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
2014-07-10 20:43:56,262 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting Stage 0 (WholeTextFileRDD[0] at wholeTextFiles at HtmlToTextConversionApp.scala:55), which has no missing parents
2014-07-10 20:43:56,310 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.scheduler.DAGScheduler - Submitting 497 missing tasks from Stage 0 (WholeTextFileRDD[0] at wholeTextFiles at HtmlToTextConversionApp.scala:55)
2014-07-10 20:43:56,317 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 497 tasks
2014-07-10 20:43:56,333 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:0 as TID 0 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,338 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:0 as 5956 bytes in 3 ms
2014-07-10 20:43:56,340 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:1 as TID 1 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,341 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:1 as 5808 bytes in 1 ms
2014-07-10 20:43:56,341 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:2 as TID 2 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,342 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:2 as 5808 bytes in 1 ms
2014-07-10 20:43:56,343 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:3 as TID 3 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,344 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:3 as 5731 bytes in 1 ms
2014-07-10 20:43:56,345 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:4 as TID 4 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,346 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:4 as 5808 bytes in 1 ms
2014-07-10 20:43:56,346 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:5 as TID 5 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,347 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:5 as 5808 bytes in 0 ms
2014-07-10 20:43:56,348 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:6 as TID 6 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,348 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:6 as 5808 bytes in 0 ms
2014-07-10 20:43:56,349 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:7 as TID 7 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,349 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:7 as 5808 bytes in 0 ms
2014-07-10 20:43:56,350 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:8 as TID 8 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,351 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:8 as 5808 bytes in 1 ms
2014-07-10 20:43:56,351 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:9 as TID 9 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,352 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:9 as 5808 bytes in 1 ms
2014-07-10 20:43:56,352 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:10 as TID 10 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,353 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:10 as 5808 bytes in 1 ms
2014-07-10 20:43:56,353 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:11 as TID 11 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,354 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:11 as 5808 bytes in 1 ms
2014-07-10 20:43:56,354 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:12 as TID 12 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,355 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:12 as 5808 bytes in 1 ms
2014-07-10 20:43:56,355 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:13 as TID 13 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,356 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:13 as 5808 bytes in 1 ms
2014-07-10 20:43:56,357 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:14 as TID 14 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,357 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:14 as 5808 bytes in 0 ms
2014-07-10 20:43:56,358 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:15 as TID 15 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,358 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:15 as 5808 bytes in 0 ms
2014-07-10 20:43:56,359 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:16 as TID 16 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,359 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:16 as 5808 bytes in 0 ms
2014-07-10 20:43:56,360 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:17 as TID 17 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,360 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:17 as 5808 bytes in 0 ms
2014-07-10 20:43:56,361 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:18 as TID 18 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,361 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:18 as 5808 bytes in 0 ms
2014-07-10 20:43:56,361 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:19 as TID 19 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,362 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:19 as 5808 bytes in 1 ms
2014-07-10 20:43:56,362 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:20 as TID 20 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,363 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:20 as 5808 bytes in 1 ms
2014-07-10 20:43:56,363 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:21 as TID 21 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,363 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:21 as 5808 bytes in 0 ms
2014-07-10 20:43:56,364 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:22 as TID 22 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,364 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:22 as 5808 bytes in 0 ms
2014-07-10 20:43:56,365 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:23 as TID 23 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,365 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:23 as 5808 bytes in 0 ms
2014-07-10 20:43:56,365 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:24 as TID 24 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,366 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:24 as 5882 bytes in 0 ms
2014-07-10 20:43:56,366 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:25 as TID 25 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,367 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:25 as 5882 bytes in 1 ms
2014-07-10 20:43:56,367 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:26 as TID 26 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,368 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:26 as 5808 bytes in 1 ms
2014-07-10 20:43:56,368 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:27 as TID 27 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,369 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:27 as 5808 bytes in 0 ms
2014-07-10 20:43:56,369 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:28 as TID 28 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,369 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:28 as 5731 bytes in 0 ms
2014-07-10 20:43:56,370 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:29 as TID 29 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,370 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:29 as 5808 bytes in 0 ms
2014-07-10 20:43:56,371 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:30 as TID 30 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,371 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:30 as 5808 bytes in 0 ms
2014-07-10 20:43:56,371 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:31 as TID 31 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,372 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:31 as 5808 bytes in 1 ms
2014-07-10 20:43:56,372 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:32 as TID 32 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,373 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:32 as 5808 bytes in 1 ms
2014-07-10 20:43:56,373 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:33 as TID 33 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,374 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:33 as 5808 bytes in 1 ms
2014-07-10 20:43:56,374 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:34 as TID 34 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,374 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:34 as 5808 bytes in 0 ms
2014-07-10 20:43:56,375 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:35 as TID 35 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,375 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:35 as 5808 bytes in 0 ms
2014-07-10 20:43:56,375 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:36 as TID 36 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,376 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:36 as 5731 bytes in 0 ms
2014-07-10 20:43:56,376 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:37 as TID 37 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,377 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:37 as 5808 bytes in 1 ms
2014-07-10 20:43:56,377 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:38 as TID 38 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,377 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:38 as 5808 bytes in 0 ms
2014-07-10 20:43:56,378 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:39 as TID 39 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,378 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:39 as 5808 bytes in 0 ms
2014-07-10 20:43:56,378 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:40 as TID 40 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,379 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:40 as 5808 bytes in 1 ms
2014-07-10 20:43:56,379 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:41 as TID 41 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,380 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:41 as 5808 bytes in 1 ms
2014-07-10 20:43:56,380 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:42 as TID 42 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,380 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:42 as 5731 bytes in 0 ms
2014-07-10 20:43:56,381 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:43 as TID 43 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,381 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:43 as 5808 bytes in 0 ms
2014-07-10 20:43:56,381 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:44 as TID 44 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,382 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:44 as 5808 bytes in 1 ms
2014-07-10 20:43:56,382 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:45 as TID 45 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,383 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:45 as 5808 bytes in 0 ms
2014-07-10 20:43:56,383 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:46 as TID 46 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,383 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:46 as 5808 bytes in 0 ms
2014-07-10 20:43:56,384 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:47 as TID 47 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,384 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:47 as 5808 bytes in 0 ms
2014-07-10 20:43:56,384 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:48 as TID 48 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,385 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:48 as 5882 bytes in 1 ms
2014-07-10 20:43:56,385 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:49 as TID 49 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,386 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:49 as 5956 bytes in 1 ms
2014-07-10 20:43:56,386 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:50 as TID 50 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,386 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:50 as 5808 bytes in 0 ms
2014-07-10 20:43:56,386 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:51 as TID 51 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,387 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:51 as 5808 bytes in 0 ms
2014-07-10 20:43:56,387 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:52 as TID 52 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,388 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:52 as 5808 bytes in 1 ms
2014-07-10 20:43:56,388 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:53 as TID 53 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,388 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:53 as 5808 bytes in 0 ms
2014-07-10 20:43:56,388 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:54 as TID 54 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,389 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:54 as 5808 bytes in 0 ms
2014-07-10 20:43:56,389 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:55 as TID 55 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,390 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:55 as 5731 bytes in 1 ms
2014-07-10 20:43:56,390 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:56 as TID 56 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,390 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:56 as 5808 bytes in 0 ms
2014-07-10 20:43:56,391 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:57 as TID 57 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,391 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:57 as 5808 bytes in 0 ms
2014-07-10 20:43:56,391 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:58 as TID 58 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,392 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:58 as 5808 bytes in 1 ms
2014-07-10 20:43:56,392 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:59 as TID 59 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,392 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:59 as 5731 bytes in 0 ms
2014-07-10 20:43:56,392 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:60 as TID 60 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,393 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:60 as 5808 bytes in 0 ms
2014-07-10 20:43:56,394 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:61 as TID 61 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,394 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:61 as 5808 bytes in 0 ms
2014-07-10 20:43:56,394 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:62 as TID 62 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,395 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:62 as 5731 bytes in 1 ms
2014-07-10 20:43:56,395 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:63 as TID 63 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,395 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:63 as 5808 bytes in 0 ms
2014-07-10 20:43:56,396 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:64 as TID 64 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,396 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:64 as 5808 bytes in 0 ms
2014-07-10 20:43:56,396 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:65 as TID 65 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,397 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:65 as 5808 bytes in 0 ms
2014-07-10 20:43:56,397 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:66 as TID 66 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,398 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:66 as 5808 bytes in 1 ms
2014-07-10 20:43:56,398 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:67 as TID 67 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,398 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:67 as 5808 bytes in 0 ms
2014-07-10 20:43:56,398 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:68 as TID 68 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,399 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:68 as 5808 bytes in 1 ms
2014-07-10 20:43:56,399 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:69 as TID 69 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,399 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:69 as 5808 bytes in 0 ms
2014-07-10 20:43:56,400 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:70 as TID 70 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,400 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:70 as 5808 bytes in 0 ms
2014-07-10 20:43:56,400 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:71 as TID 71 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,401 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:71 as 5956 bytes in 1 ms
2014-07-10 20:43:56,401 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:72 as TID 72 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,401 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:72 as 5956 bytes in 0 ms
2014-07-10 20:43:56,402 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:73 as TID 73 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,402 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:73 as 5808 bytes in 0 ms
2014-07-10 20:43:56,402 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:74 as TID 74 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,403 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:74 as 5882 bytes in 1 ms
2014-07-10 20:43:56,403 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:75 as TID 75 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,403 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:75 as 5882 bytes in 0 ms
2014-07-10 20:43:56,404 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:76 as TID 76 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,404 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:76 as 5808 bytes in 0 ms
2014-07-10 20:43:56,404 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:77 as TID 77 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,405 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:77 as 5808 bytes in 1 ms
2014-07-10 20:43:56,405 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:78 as TID 78 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,405 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:78 as 5808 bytes in 0 ms
2014-07-10 20:43:56,405 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:79 as TID 79 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,406 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:79 as 5808 bytes in 0 ms
2014-07-10 20:43:56,406 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:80 as TID 80 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,407 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:80 as 5882 bytes in 0 ms
2014-07-10 20:43:56,407 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:81 as TID 81 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,407 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:81 as 5808 bytes in 0 ms
2014-07-10 20:43:56,407 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:82 as TID 82 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,408 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:82 as 5808 bytes in 1 ms
2014-07-10 20:43:56,408 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:83 as TID 83 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,408 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:83 as 5882 bytes in 0 ms
2014-07-10 20:43:56,409 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:84 as TID 84 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,409 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:84 as 5956 bytes in 0 ms
2014-07-10 20:43:56,409 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:85 as TID 85 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,410 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:85 as 5882 bytes in 0 ms
2014-07-10 20:43:56,410 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:86 as TID 86 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,410 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:86 as 5808 bytes in 0 ms
2014-07-10 20:43:56,410 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:87 as TID 87 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,411 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:87 as 5808 bytes in 1 ms
2014-07-10 20:43:56,411 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:88 as TID 88 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,411 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:88 as 5808 bytes in 0 ms
2014-07-10 20:43:56,412 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:89 as TID 89 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,412 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:89 as 5882 bytes in 0 ms
2014-07-10 20:43:56,412 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:90 as TID 90 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,413 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:90 as 5808 bytes in 1 ms
2014-07-10 20:43:56,413 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:91 as TID 91 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,413 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:91 as 5808 bytes in 0 ms
2014-07-10 20:43:56,413 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:92 as TID 92 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,414 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:92 as 5882 bytes in 1 ms
2014-07-10 20:43:56,414 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:93 as TID 93 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,414 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:93 as 5808 bytes in 0 ms
2014-07-10 20:43:56,414 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:94 as TID 94 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,415 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:94 as 5882 bytes in 1 ms
2014-07-10 20:43:56,415 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:95 as TID 95 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,415 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:95 as 5956 bytes in 0 ms
2014-07-10 20:43:56,416 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:96 as TID 96 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,416 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:96 as 5956 bytes in 0 ms
2014-07-10 20:43:56,416 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:97 as TID 97 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,417 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:97 as 5882 bytes in 1 ms
2014-07-10 20:43:56,417 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:98 as TID 98 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,417 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:98 as 5956 bytes in 0 ms
2014-07-10 20:43:56,418 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:99 as TID 99 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,418 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:99 as 5882 bytes in 0 ms
2014-07-10 20:43:56,418 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:100 as TID 100 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,419 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:100 as 5882 bytes in 1 ms
2014-07-10 20:43:56,419 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:101 as TID 101 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,419 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:101 as 5808 bytes in 0 ms
2014-07-10 20:43:56,419 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:102 as TID 102 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,420 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:102 as 5808 bytes in 1 ms
2014-07-10 20:43:56,420 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:103 as TID 103 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,420 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:103 as 5882 bytes in 0 ms
2014-07-10 20:43:56,420 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:104 as TID 104 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,421 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:104 as 5882 bytes in 0 ms
2014-07-10 20:43:56,421 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:105 as TID 105 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,422 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:105 as 5808 bytes in 1 ms
2014-07-10 20:43:56,422 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:106 as TID 106 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,422 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:106 as 6923 bytes in 0 ms
2014-07-10 20:43:56,422 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:107 as TID 107 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,423 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:107 as 7219 bytes in 1 ms
2014-07-10 20:43:56,423 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:108 as TID 108 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,423 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:108 as 7145 bytes in 0 ms
2014-07-10 20:43:56,424 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:109 as TID 109 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,424 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:109 as 7219 bytes in 0 ms
2014-07-10 20:43:56,424 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:110 as TID 110 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,424 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:110 as 7145 bytes in 0 ms
2014-07-10 20:43:56,425 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:111 as TID 111 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,425 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:111 as 6624 bytes in 0 ms
2014-07-10 20:43:56,425 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:112 as TID 112 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,426 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:112 as 7441 bytes in 1 ms
2014-07-10 20:43:56,426 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:113 as TID 113 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,426 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:113 as 7515 bytes in 0 ms
2014-07-10 20:43:56,426 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:114 as TID 114 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,427 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:114 as 7591 bytes in 1 ms
2014-07-10 20:43:56,427 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:115 as TID 115 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,427 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:115 as 6400 bytes in 0 ms
2014-07-10 20:43:56,427 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:116 as TID 116 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,428 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:116 as 7665 bytes in 1 ms
2014-07-10 20:43:56,428 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:117 as TID 117 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,428 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:117 as 7964 bytes in 0 ms
2014-07-10 20:43:56,429 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:118 as TID 118 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,429 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:118 as 8706 bytes in 0 ms
2014-07-10 20:43:56,429 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:119 as TID 119 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,430 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:119 as 9153 bytes in 0 ms
2014-07-10 20:43:56,430 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:120 as TID 120 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,430 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:120 as 9449 bytes in 0 ms
2014-07-10 20:43:56,430 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:121 as TID 121 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,431 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:121 as 9523 bytes in 1 ms
2014-07-10 20:43:56,431 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:122 as TID 122 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,431 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:122 as 9972 bytes in 0 ms
2014-07-10 20:43:56,431 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:123 as TID 123 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,432 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:123 as 10120 bytes in 1 ms
2014-07-10 20:43:56,432 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:124 as TID 124 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,432 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:124 as 9673 bytes in 0 ms
2014-07-10 20:43:56,433 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:125 as TID 125 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,433 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:125 as 9301 bytes in 0 ms
2014-07-10 20:43:56,433 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:126 as TID 126 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,434 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:126 as 8857 bytes in 1 ms
2014-07-10 20:43:56,434 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:127 as TID 127 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,434 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:127 as 6775 bytes in 0 ms
2014-07-10 20:43:56,435 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:128 as TID 128 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,435 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:128 as 8556 bytes in 0 ms
2014-07-10 20:43:56,435 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:129 as TID 129 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,436 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:129 as 9079 bytes in 1 ms
2014-07-10 20:43:56,436 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:130 as TID 130 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,436 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:130 as 9079 bytes in 0 ms
2014-07-10 20:43:56,437 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:131 as TID 131 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,437 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:131 as 8780 bytes in 0 ms
2014-07-10 20:43:56,437 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:132 as TID 132 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,437 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:132 as 8780 bytes in 0 ms
2014-07-10 20:43:56,438 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:133 as TID 133 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,438 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:133 as 8706 bytes in 0 ms
2014-07-10 20:43:56,438 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:134 as TID 134 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,438 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:134 as 8706 bytes in 0 ms
2014-07-10 20:43:56,439 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:135 as TID 135 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,439 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:135 as 8931 bytes in 0 ms
2014-07-10 20:43:56,439 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:136 as TID 136 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,439 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:136 as 8408 bytes in 0 ms
2014-07-10 20:43:56,440 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:137 as TID 137 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,440 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:137 as 8556 bytes in 0 ms
2014-07-10 20:43:56,440 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:138 as TID 138 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,440 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:138 as 8260 bytes in 0 ms
2014-07-10 20:43:56,441 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:139 as TID 139 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,441 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:139 as 8408 bytes in 0 ms
2014-07-10 20:43:56,441 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:140 as TID 140 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,441 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:140 as 7441 bytes in 0 ms
2014-07-10 20:43:56,442 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:141 as TID 141 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,442 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:141 as 6030 bytes in 0 ms
2014-07-10 20:43:56,442 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:142 as TID 142 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,442 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:142 as 8038 bytes in 0 ms
2014-07-10 20:43:56,443 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:143 as TID 143 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,443 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:143 as 8112 bytes in 0 ms
2014-07-10 20:43:56,443 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:144 as TID 144 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,443 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:144 as 7591 bytes in 0 ms
2014-07-10 20:43:56,443 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:145 as TID 145 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,444 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:145 as 7890 bytes in 0 ms
2014-07-10 20:43:56,444 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:146 as TID 146 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,444 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:146 as 7219 bytes in 0 ms
2014-07-10 20:43:56,445 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:147 as TID 147 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,445 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:147 as 7515 bytes in 0 ms
2014-07-10 20:43:56,445 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:148 as TID 148 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,445 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:148 as 7145 bytes in 0 ms
2014-07-10 20:43:56,446 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:149 as TID 149 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,446 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:149 as 8112 bytes in 0 ms
2014-07-10 20:43:56,446 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:150 as TID 150 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,446 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:150 as 7890 bytes in 0 ms
2014-07-10 20:43:56,446 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:151 as TID 151 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,447 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:151 as 7219 bytes in 0 ms
2014-07-10 20:43:56,447 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:152 as TID 152 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,447 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:152 as 6775 bytes in 0 ms
2014-07-10 20:43:56,447 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:153 as TID 153 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,448 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:153 as 6849 bytes in 1 ms
2014-07-10 20:43:56,448 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:154 as TID 154 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,448 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:154 as 6849 bytes in 0 ms
2014-07-10 20:43:56,448 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:155 as TID 155 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,449 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:155 as 6698 bytes in 1 ms
2014-07-10 20:43:56,449 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:156 as TID 156 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,449 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:156 as 6624 bytes in 0 ms
2014-07-10 20:43:56,449 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:157 as TID 157 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,450 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:157 as 6474 bytes in 1 ms
2014-07-10 20:43:56,450 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:158 as TID 158 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,450 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:158 as 6400 bytes in 0 ms
2014-07-10 20:43:56,450 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:159 as TID 159 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,451 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:159 as 6252 bytes in 0 ms
2014-07-10 20:43:56,451 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:160 as TID 160 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,451 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:160 as 6178 bytes in 0 ms
2014-07-10 20:43:56,451 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:161 as TID 161 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,451 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:161 as 6104 bytes in 0 ms
2014-07-10 20:43:56,452 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:162 as TID 162 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,452 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:162 as 6104 bytes in 0 ms
2014-07-10 20:43:56,452 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:163 as TID 163 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,452 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:163 as 6104 bytes in 0 ms
2014-07-10 20:43:56,452 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:164 as TID 164 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,453 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:164 as 6030 bytes in 0 ms
2014-07-10 20:43:56,453 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:165 as TID 165 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,453 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:165 as 6030 bytes in 0 ms
2014-07-10 20:43:56,453 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:166 as TID 166 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,454 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:166 as 6474 bytes in 1 ms
2014-07-10 20:43:56,454 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:167 as TID 167 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,454 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:167 as 7219 bytes in 0 ms
2014-07-10 20:43:56,454 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:168 as TID 168 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,455 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:168 as 7367 bytes in 1 ms
2014-07-10 20:43:56,455 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:169 as TID 169 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,455 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:169 as 7145 bytes in 0 ms
2014-07-10 20:43:56,455 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:170 as TID 170 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,456 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:170 as 6624 bytes in 0 ms
2014-07-10 20:43:56,456 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:171 as TID 171 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,456 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:171 as 6400 bytes in 0 ms
2014-07-10 20:43:56,456 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:172 as TID 172 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,456 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:172 as 6252 bytes in 0 ms
2014-07-10 20:43:56,457 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:173 as TID 173 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,457 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:173 as 6252 bytes in 0 ms
2014-07-10 20:43:56,457 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:174 as TID 174 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,457 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:174 as 6252 bytes in 0 ms
2014-07-10 20:43:56,457 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:175 as TID 175 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,458 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:175 as 6400 bytes in 0 ms
2014-07-10 20:43:56,458 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:176 as TID 176 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,458 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:176 as 6252 bytes in 0 ms
2014-07-10 20:43:56,458 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:177 as TID 177 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,459 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:177 as 6326 bytes in 1 ms
2014-07-10 20:43:56,459 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:178 as TID 178 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,459 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:178 as 6400 bytes in 0 ms
2014-07-10 20:43:56,459 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:179 as TID 179 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,460 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:179 as 6326 bytes in 1 ms
2014-07-10 20:43:56,460 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:180 as TID 180 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,460 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:180 as 6252 bytes in 0 ms
2014-07-10 20:43:56,460 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:181 as TID 181 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,461 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:181 as 6252 bytes in 0 ms
2014-07-10 20:43:56,461 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:182 as TID 182 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,461 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:182 as 6178 bytes in 0 ms
2014-07-10 20:43:56,461 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:183 as TID 183 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,461 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:183 as 6178 bytes in 0 ms
2014-07-10 20:43:56,462 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:184 as TID 184 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,462 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:184 as 6104 bytes in 0 ms
2014-07-10 20:43:56,462 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:185 as TID 185 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,462 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:185 as 6178 bytes in 0 ms
2014-07-10 20:43:56,462 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:186 as TID 186 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,463 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:186 as 6104 bytes in 0 ms
2014-07-10 20:43:56,463 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:187 as TID 187 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,463 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:187 as 6104 bytes in 0 ms
2014-07-10 20:43:56,463 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:188 as TID 188 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,464 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:188 as 6030 bytes in 1 ms
2014-07-10 20:43:56,464 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:189 as TID 189 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,464 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:189 as 6104 bytes in 0 ms
2014-07-10 20:43:56,464 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:190 as TID 190 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,465 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:190 as 6030 bytes in 1 ms
2014-07-10 20:43:56,465 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:191 as TID 191 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,465 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:191 as 6030 bytes in 0 ms
2014-07-10 20:43:56,465 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:192 as TID 192 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,466 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:192 as 6178 bytes in 1 ms
2014-07-10 20:43:56,466 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:193 as TID 193 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,467 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:193 as 6326 bytes in 1 ms
2014-07-10 20:43:56,467 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:194 as TID 194 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,467 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:194 as 6104 bytes in 0 ms
2014-07-10 20:43:56,467 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:195 as TID 195 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,468 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:195 as 6400 bytes in 1 ms
2014-07-10 20:43:56,468 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:196 as TID 196 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,468 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:196 as 6624 bytes in 0 ms
2014-07-10 20:43:56,468 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:197 as TID 197 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,468 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:197 as 9079 bytes in 0 ms
2014-07-10 20:43:56,469 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:198 as TID 198 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,469 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:198 as 8556 bytes in 0 ms
2014-07-10 20:43:56,469 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:199 as TID 199 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,469 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:199 as 8482 bytes in 0 ms
2014-07-10 20:43:56,470 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:200 as TID 200 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,470 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:200 as 8334 bytes in 0 ms
2014-07-10 20:43:56,470 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:201 as TID 201 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,470 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:201 as 6923 bytes in 0 ms
2014-07-10 20:43:56,470 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:202 as TID 202 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,471 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:202 as 7071 bytes in 1 ms
2014-07-10 20:43:56,471 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:203 as TID 203 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,471 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:203 as 6474 bytes in 0 ms
2014-07-10 20:43:56,471 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:204 as TID 204 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,472 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:204 as 6326 bytes in 1 ms
2014-07-10 20:43:56,472 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:205 as TID 205 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,472 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:205 as 6400 bytes in 0 ms
2014-07-10 20:43:56,472 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:206 as TID 206 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,473 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:206 as 6474 bytes in 1 ms
2014-07-10 20:43:56,473 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:207 as TID 207 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,473 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:207 as 6252 bytes in 0 ms
2014-07-10 20:43:56,473 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:208 as TID 208 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,473 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:208 as 6326 bytes in 0 ms
2014-07-10 20:43:56,474 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:209 as TID 209 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,474 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:209 as 6252 bytes in 0 ms
2014-07-10 20:43:56,474 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:210 as TID 210 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,474 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:210 as 6252 bytes in 0 ms
2014-07-10 20:43:56,474 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:211 as TID 211 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,475 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:211 as 6178 bytes in 0 ms
2014-07-10 20:43:56,475 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:212 as TID 212 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,475 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:212 as 6178 bytes in 0 ms
2014-07-10 20:43:56,475 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:213 as TID 213 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,476 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:213 as 6178 bytes in 1 ms
2014-07-10 20:43:56,476 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:214 as TID 214 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,476 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:214 as 6104 bytes in 0 ms
2014-07-10 20:43:56,476 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:215 as TID 215 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,477 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:215 as 6178 bytes in 0 ms
2014-07-10 20:43:56,477 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:216 as TID 216 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,477 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:216 as 6178 bytes in 0 ms
2014-07-10 20:43:56,477 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:217 as TID 217 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,477 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:217 as 6178 bytes in 0 ms
2014-07-10 20:43:56,478 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:218 as TID 218 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,478 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:218 as 6178 bytes in 0 ms
2014-07-10 20:43:56,478 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:219 as TID 219 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,478 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:219 as 6178 bytes in 0 ms
2014-07-10 20:43:56,478 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:220 as TID 220 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,479 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:220 as 6178 bytes in 1 ms
2014-07-10 20:43:56,479 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:221 as TID 221 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,479 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:221 as 6104 bytes in 0 ms
2014-07-10 20:43:56,479 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:222 as TID 222 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,480 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:222 as 6178 bytes in 1 ms
2014-07-10 20:43:56,480 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:223 as TID 223 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,480 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:223 as 6550 bytes in 0 ms
2014-07-10 20:43:56,480 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:224 as TID 224 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,480 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:224 as 7367 bytes in 0 ms
2014-07-10 20:43:56,481 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:225 as TID 225 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,481 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:225 as 7591 bytes in 0 ms
2014-07-10 20:43:56,481 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:226 as TID 226 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,481 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:226 as 6698 bytes in 0 ms
2014-07-10 20:43:56,481 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:227 as TID 227 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,482 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:227 as 6997 bytes in 0 ms
2014-07-10 20:43:56,482 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:228 as TID 228 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,482 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:228 as 6775 bytes in 0 ms
2014-07-10 20:43:56,482 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:229 as TID 229 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,483 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:229 as 6698 bytes in 1 ms
2014-07-10 20:43:56,483 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:230 as TID 230 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,483 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:230 as 6624 bytes in 0 ms
2014-07-10 20:43:56,483 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:231 as TID 231 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,484 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:231 as 6474 bytes in 1 ms
2014-07-10 20:43:56,484 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:232 as TID 232 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,484 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:232 as 6400 bytes in 0 ms
2014-07-10 20:43:56,484 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:233 as TID 233 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,484 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:233 as 6178 bytes in 0 ms
2014-07-10 20:43:56,485 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:234 as TID 234 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,485 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:234 as 6104 bytes in 0 ms
2014-07-10 20:43:56,485 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:235 as TID 235 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,485 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:235 as 6252 bytes in 0 ms
2014-07-10 20:43:56,486 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:236 as TID 236 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,486 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:236 as 6178 bytes in 0 ms
2014-07-10 20:43:56,486 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:237 as TID 237 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,486 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:237 as 6030 bytes in 0 ms
2014-07-10 20:43:56,486 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:238 as TID 238 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,487 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:238 as 6252 bytes in 0 ms
2014-07-10 20:43:56,487 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:239 as TID 239 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,487 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:239 as 6178 bytes in 0 ms
2014-07-10 20:43:56,487 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:240 as TID 240 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,488 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:240 as 6178 bytes in 1 ms
2014-07-10 20:43:56,488 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:241 as TID 241 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,488 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:241 as 6178 bytes in 0 ms
2014-07-10 20:43:56,488 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:242 as TID 242 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,488 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:242 as 6030 bytes in 0 ms
2014-07-10 20:43:56,489 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:243 as TID 243 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,489 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:243 as 6326 bytes in 0 ms
2014-07-10 20:43:56,489 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:244 as TID 244 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,489 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:244 as 6178 bytes in 0 ms
2014-07-10 20:43:56,489 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:245 as TID 245 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,490 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:245 as 6178 bytes in 0 ms
2014-07-10 20:43:56,490 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:246 as TID 246 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,490 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:246 as 6104 bytes in 0 ms
2014-07-10 20:43:56,490 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:247 as TID 247 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,491 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:247 as 6698 bytes in 1 ms
2014-07-10 20:43:56,491 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:248 as TID 248 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,491 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:248 as 7515 bytes in 0 ms
2014-07-10 20:43:56,491 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:249 as TID 249 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,492 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:249 as 7441 bytes in 0 ms
2014-07-10 20:43:56,492 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:250 as TID 250 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,492 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:250 as 6997 bytes in 0 ms
2014-07-10 20:43:56,492 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:251 as TID 251 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,492 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:251 as 6923 bytes in 0 ms
2014-07-10 20:43:56,493 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:252 as TID 252 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,493 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:252 as 6775 bytes in 0 ms
2014-07-10 20:43:56,493 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:253 as TID 253 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,494 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:253 as 6775 bytes in 1 ms
2014-07-10 20:43:56,494 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:254 as TID 254 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,494 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:254 as 6550 bytes in 0 ms
2014-07-10 20:43:56,494 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:255 as TID 255 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 20:43:56,495 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:255 as 6400 bytes in 1 ms
2014-07-10 20:43:56,521 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 12
2014-07-10 20:43:56,528 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 28
2014-07-10 20:43:56,530 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 44
2014-07-10 20:43:56,531 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 60
2014-07-10 20:43:56,532 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 76
2014-07-10 20:43:56,534 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 92
2014-07-10 20:43:56,534 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task ID 28
2014-07-10 20:43:56,536 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Running task ID 60
2014-07-10 20:43:56,534 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Running task ID 44
2014-07-10 20:43:56,535 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Running task ID 76
2014-07-10 20:43:56,536 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 108
2014-07-10 20:43:56,537 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Running task ID 92
2014-07-10 20:43:56,537 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task ID 12
2014-07-10 20:43:56,538 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 124
2014-07-10 20:43:56,539 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Running task ID 108
2014-07-10 20:43:56,539 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 140
2014-07-10 20:43:56,540 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 124
2014-07-10 20:43:56,541 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 156
2014-07-10 20:43:56,542 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 140
2014-07-10 20:43:56,542 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 172
2014-07-10 20:43:56,543 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 188
2014-07-10 20:43:56,546 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Running task ID 172
2014-07-10 20:43:56,547 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Running task ID 156
2014-07-10 20:43:56,548 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 204
2014-07-10 20:43:56,549 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 188
2014-07-10 20:43:56,550 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 220
2014-07-10 20:43:56,551 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 204
2014-07-10 20:43:56,551 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 236
2014-07-10 20:43:56,551 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Running task ID 220
2014-07-10 20:43:56,552 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 252
2014-07-10 20:43:56,553 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Running task ID 236
2014-07-10 20:43:56,556 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Running task ID 252
2014-07-10 20:43:56,582 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Fetching http://172.31.109.131:46280/jars/run.jar with timestamp 1405017493253
2014-07-10 20:43:56,585 [Executor task launch worker-4] INFO  org.apache.spark.util.Utils - Fetching http://172.31.109.131:46280/jars/run.jar to /disk3/spark_local_dirs/fetchFileTemp3167822175256683814.tmp
2014-07-10 20:43:56,916 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Adding file:/disk3/spark_work/app-20140710203813-0000/9/./run.jar to class loader
2014-07-10 20:43:57,026 [Executor task launch worker-15] INFO  org.apache.spark.broadcast.HttpBroadcast - Started reading broadcast variable 0
2014-07-10 20:43:57,321 [Executor task launch worker-15] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
2014-07-10 20:43:57,496 [Executor task launch worker-15] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(433588) called with curMem=0, maxMem=43218213273
2014-07-10 20:43:57,499 [Executor task launch worker-15] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values to memory (estimated size 423.4 KB, free 40.2 GB)
2014-07-10 20:43:57,505 [Executor task launch worker-15] INFO  org.apache.spark.broadcast.HttpBroadcast - Reading broadcast variable 0 took 0.478458225 s
2014-07-10 20:43:57,508 [Executor task launch worker-4] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,510 [Executor task launch worker-3] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,511 [Executor task launch worker-9] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,512 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,512 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,513 [Executor task launch worker-6] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,513 [Executor task launch worker-0] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,516 [Executor task launch worker-13] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,517 [Executor task launch worker-2] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,517 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,518 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,519 [Executor task launch worker-5] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,519 [Executor task launch worker-10] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,524 [Executor task launch worker-14] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,524 [Executor task launch worker-1] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 20:43:57,562 [Executor task launch worker-13] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-30.warc:0+67514403,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-31.warc:0+70764529,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-32.warc:0+69391587,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-33.warc:0+74711085,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-34.warc:0+72310925,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-35.warc:0+69128483,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-36.warc:0+67969464,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-37.warc:0+70404637,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-38.warc:0+72304550,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-39.warc:0+67665293,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-40.warc:0+72893822,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-41.warc:0+73434355,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-42.warc:0+72287628,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-43.warc:0+70443221,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-44.warc:0+68219089,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-45.warc:0+68134004,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-46.warc:0+65194589,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-47.warc:0+62158750,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-48.warc:0+63812120,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-49.warc:0+64562688,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-50.warc:0+65081902,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-51.warc:0+63882131,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-52.warc:0+63841626,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-53.warc:0+64397890,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-54.warc:0+65644514,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-55.warc:0+70108052,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-56.warc:0+70176562,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-57.warc:0+71855126,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-58.warc:0+70628881,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-59.warc:0+70594647,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-60.warc:0+65530094,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-61.warc:0+70679227,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-62.warc:0+74662275,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-63.warc:0+74317219,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-64.warc:0+71142732,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-65.warc:0+69797123,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-66.warc:0+69509374,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-67.warc:0+65799485,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-68.warc:0+73021470,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-69.warc:0+71226926,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-70.warc:0+68189205,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-71.warc:0+71924435,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-72.warc:0+69368669,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-73.warc:0+69041533,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-74.warc:0+71902297,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-75.warc:0+74190587,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-76.warc:0+71130560,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-77.warc:0+72894615,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-78.warc:0+72069027,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-79.warc:0+71486905,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-80.warc:0+72301668,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-81.warc:0+75787402,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-82.warc:0+70721295,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-83.warc:0+65710292,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-84.warc:0+64042091,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-85.warc:0+63168563,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-86.warc:0+63737554,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-87.warc:0+63430597,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-88.warc:0+64917997,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-89.warc:0+67019639,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-90.warc:0+64299220,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-91.warc:0+63095676,/mnt/cw12/cw-data/ClueWeb12_09/0916wb/0916wb-92.warc:0+67567209
2014-07-10 20:43:57,562 [Executor task launch worker-9] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_07/0711wb/0711wb-04.warc:0+37878759,/mnt/cw12/cw-data/ClueWeb12_07/0711wb/0711wb-05.warc:0+56924215,/mnt/cw12/cw-data/ClueWeb12_07/0711wb/0711wb-06.warc:0+59987646,/mnt/cw12/cw-data/ClueWeb12_07/0711wb/0711wb-07.warc:0+57559985,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-12.warc:0+59806049,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-13.warc:0+60686427,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-14.warc:0+68182331,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-15.warc:0+67905951,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-16.warc:0+64832510,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-17.warc:0+62382433,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-18.warc:0+66057017,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-19.warc:0+71534512,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-20.warc:0+64884570,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-21.warc:0+41252364,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-24.warc:0+31026827,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-25.warc:0+59380524,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-26.warc:0+61004810,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-27.warc:0+60639694,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-28.warc:0+60886040,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-29.warc:0+67306709,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-30.warc:0+68569755,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-31.warc:0+68144874,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-32.warc:0+68491047,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-33.warc:0+69236056,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-34.warc:0+68680864,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-35.warc:0+68780556,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-36.warc:0+66974801,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-37.warc:0+69224870,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-38.warc:0+69297936,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-39.warc:0+65730343,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-40.warc:0+66108965,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-41.warc:0+61919720,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-42.warc:0+66822819,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-43.warc:0+60678366,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-44.warc:0+65725121,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-45.warc:0+71340230,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-46.warc:0+66392877,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-47.warc:0+35106368,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-50.warc:0+17179664,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-51.warc:0+75066261,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-52.warc:0+62657883,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-53.warc:0+60998600,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-54.warc:0+64720201,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-55.warc:0+65879939,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-56.warc:0+60459358,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-57.warc:0+64514881,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-58.warc:0+61475956,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-59.warc:0+64256982,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-60.warc:0+66778847,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-61.warc:0+72486361,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-62.warc:0+66058036,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-63.warc:0+37752500,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-66.warc:0+25465881,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-67.warc:0+67959047,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-68.warc:0+70708548,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-69.warc:0+63651793,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-70.warc:0+62796190,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-71.warc:0+65774468,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-72.warc:0+63623218,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-73.warc:0+64019707,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-74.warc:0+70710646,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-75.warc:0+68465508,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-76.warc:0+68232893,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-77.warc:0+69930263,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-78.warc:0+70237249,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-79.warc:0+68333194,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-80.warc:0+68612286,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-81.warc:0+67817384,/mnt/cw12/cw-data/ClueWeb12_07/0712wb/0712wb-82.warc:0+70540371
2014-07-10 20:43:57,563 [Executor task launch worker-8] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-66.warc:0+45714124,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-67.warc:0+45291098,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-68.warc:0+41820358,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-69.warc:0+47831162,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-70.warc:0+46693900,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-71.warc:0+15064751,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-73.warc:0+40264158,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-74.warc:0+45218737,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-75.warc:0+45543228,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-76.warc:0+43220866,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-77.warc:0+47037376,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-78.warc:0+70594507,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-00.warc:0+53600102,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-01.warc:0+15683731,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-02.warc:0+3470052,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-03.warc:0+46147139,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-04.warc:0+44117849,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-05.warc:0+47161699,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-06.warc:0+71812578,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-07.warc:0+62976440,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-08.warc:0+63934333,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-09.warc:0+70510266,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-10.warc:0+71311721,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-11.warc:0+74474928,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-12.warc:0+56629778,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-13.warc:0+44050885,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-14.warc:0+42627951,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-15.warc:0+26856921,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-17.warc:0+38263137,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-18.warc:0+43183699,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-19.warc:0+50918805,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-20.warc:0+43300284,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-21.warc:0+45933787,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-23.warc:0+15462950,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-24.warc:0+42901501,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-25.warc:0+43976936,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-26.warc:0+43818129,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-27.warc:0+42762501,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-28.warc:0+59635466,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-29.warc:0+70265820,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-30.warc:0+70627059,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-31.warc:0+71589257,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-32.warc:0+74349114,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-33.warc:0+58093922,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-34.warc:0+42877573,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-35.warc:0+44362884,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-36.warc:0+36927507,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-38.warc:0+24868654,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-39.warc:0+42224173,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-40.warc:0+45030728,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-41.warc:0+46217186,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-42.warc:0+46526014,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-43.warc:0+43756770,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-44.warc:0+47146491,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-79.warc:0+71319002,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-80.warc:0+71289953,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-81.warc:0+49026351,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-82.warc:0+42020626,/mnt/cw12/cw-data/ClueWeb12_06/0612wb/0612wb-45.warc:0+15039457,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-10.warc:0+69823471,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-11.warc:0+73146046,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-12.warc:0+73112982,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-13.warc:0+67540209,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-14.warc:0+73233465,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-15.warc:0+71231363,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-16.warc:0+70505183,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-17.warc:0+71423123,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-18.warc:0+71157968,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-19.warc:0+70751973,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-20.warc:0+71036317,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-21.warc:0+71363112,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-22.warc:0+73543928,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-23.warc:0+70862838,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-24.warc:0+72762504,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-25.warc:0+70467650,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-26.warc:0+72277047,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-27.warc:0+71713139,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-28.warc:0+76086254,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-29.warc:0+71888013,/mnt/cw12/cw-data/ClueWeb12_07/0700tw/0700tw-30.warc:0+69592825
2014-07-10 20:43:57,564 [Executor task launch worker-2] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-35.warc:0+72423521,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-36.warc:0+75587100,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-37.warc:0+76374078,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-38.warc:0+78235799,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-39.warc:0+71823205,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-40.warc:0+71231706,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-41.warc:0+71181600,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-42.warc:0+73645826,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-43.warc:0+75408883,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-44.warc:0+72899925,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-45.warc:0+73315407,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-46.warc:0+79423499,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-47.warc:0+83752066,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-48.warc:0+75359283,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-49.warc:0+76897968,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-50.warc:0+73935632,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-51.warc:0+76360120,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-52.warc:0+70854834,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-53.warc:0+73748663,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-54.warc:0+72706840,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-55.warc:0+73680071,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-56.warc:0+75480865,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-57.warc:0+73827382,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-58.warc:0+70679209,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-59.warc:0+74367203,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-60.warc:0+72143409,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-61.warc:0+75357265,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-62.warc:0+75025181,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-63.warc:0+75312022,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-64.warc:0+79870354,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-65.warc:0+77140152,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-66.warc:0+73532745,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-67.warc:0+77425052,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-68.warc:0+72685769,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-69.warc:0+74384239,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-70.warc:0+75060559,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-71.warc:0+74529435,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-72.warc:0+83546214,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-73.warc:0+74704507,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-74.warc:0+70511069,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-75.warc:0+73985684,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-76.warc:0+73701462,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-77.warc:0+71707239,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-78.warc:0+73366245,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-79.warc:0+79756547,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-80.warc:0+72266024,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-81.warc:0+71871854,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-82.warc:0+69417199,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-83.warc:0+72973974,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-84.warc:0+71600805,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-85.warc:0+77911275,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-86.warc:0+73101210,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-87.warc:0+76862870,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-88.warc:0+74343880,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-89.warc:0+76350496,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-90.warc:0+72966345,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-91.warc:0+75845934,/mnt/cw12/cw-data/ClueWeb12_01/0110wb/0110wb-92.warc:0+73985936
2014-07-10 20:43:57,563 [Executor task launch worker-10] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-45.warc:0+72937998,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-46.warc:0+75907709,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-47.warc:0+70000788,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-48.warc:0+74027959,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-49.warc:0+73583036,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-50.warc:0+68455976,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-51.warc:0+62438947,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-52.warc:0+62301541,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-53.warc:0+63591718,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-54.warc:0+64219562,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-55.warc:0+62693004,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-56.warc:0+60755658,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-57.warc:0+63083168,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-58.warc:0+61810750,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-59.warc:0+63995510,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-60.warc:0+63626391,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-61.warc:0+66060041,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-62.warc:0+69384146,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-63.warc:0+72334893,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-64.warc:0+68488336,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-65.warc:0+72110010,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-66.warc:0+68604029,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-67.warc:0+65766867,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-68.warc:0+63267119,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-69.warc:0+64216327,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-70.warc:0+62297153,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-71.warc:0+61678733,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-72.warc:0+65104517,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-73.warc:0+64673566,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-74.warc:0+67309911,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-75.warc:0+71572683,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-76.warc:0+71367720,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-77.warc:0+68192629,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-78.warc:0+71841157,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-79.warc:0+72442788,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-80.warc:0+71843097,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-81.warc:0+74769893,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-82.warc:0+71173136,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-83.warc:0+75349766,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-84.warc:0+68556033,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-85.warc:0+70566741,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-86.warc:0+67555200,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-87.warc:0+67363909,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-88.warc:0+74213134,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-89.warc:0+72548125,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-90.warc:0+69772985,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-91.warc:0+72890555,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-92.warc:0+67790358,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-93.warc:0+64274655,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-94.warc:0+63769108,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-95.warc:0+61836103,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-96.warc:0+64728197,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-97.warc:0+63913261,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-98.warc:0+63419967,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-99.warc:0+63724402,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-00.warc:0+62849971,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-01.warc:0+65091830,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-02.warc:0+62662133,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-03.warc:0+64786366,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-04.warc:0+73647030,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-05.warc:0+73109035,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-06.warc:0+66109450,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-07.warc:0+71051401,/mnt/cw12/cw-data/ClueWeb12_08/0804wb/0804wb-08.warc:0+69302104
2014-07-10 20:43:57,563 [Executor task launch worker-5] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-72.warc:0+75369988,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-73.warc:0+74540931,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-74.warc:0+70613601,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-75.warc:0+74119396,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-76.warc:0+75581692,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-77.warc:0+72352912,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-78.warc:0+73115620,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-79.warc:0+71845694,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-80.warc:0+74032771,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-81.warc:0+73711586,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-82.warc:0+71977680,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-83.warc:0+73591494,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-84.warc:0+74425335,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-85.warc:0+74579692,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-86.warc:0+73424895,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-87.warc:0+74398307,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-88.warc:0+68032103,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-89.warc:0+75401584,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-90.warc:0+73875592,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-91.warc:0+71613560,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-92.warc:0+74121785,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-93.warc:0+72710824,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-94.warc:0+72789555,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-95.warc:0+72022667,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-96.warc:0+70476390,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-97.warc:0+73019607,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-98.warc:0+69834913,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-99.warc:0+78285020,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-00.warc:0+81812510,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-01.warc:0+73694865,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-02.warc:0+73176951,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-03.warc:0+75172425,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-04.warc:0+74358608,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-05.warc:0+78231544,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-06.warc:0+72396633,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-07.warc:0+75145306,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-08.warc:0+74266004,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-09.warc:0+72169600,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-10.warc:0+73365980,/mnt/cw12/cw-data/ClueWeb12_03/0310wb/0310wb-11.warc:0+75761511,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-14.warc:0+73425733,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-15.warc:0+72786044,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-16.warc:0+75134924,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-17.warc:0+72832085,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-18.warc:0+72446318,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-19.warc:0+74175607,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-20.warc:0+73035181,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-21.warc:0+73172660,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-22.warc:0+74097617,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-23.warc:0+74717160,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-24.warc:0+80530546,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-25.warc:0+74312878,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-26.warc:0+72914091,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-27.warc:0+74102346,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-28.warc:0+74500769,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-29.warc:0+70167962,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-30.warc:0+74735104,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-31.warc:0+74288687,/mnt/cw12/cw-data/ClueWeb12_03/0311wb/0311wb-32.warc:0+72923339
2014-07-10 20:43:57,562 [Executor task launch worker-0] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-89.warc:0+73747617,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-90.warc:0+72940771,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-91.warc:0+73590717,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-92.warc:0+75377770,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-93.warc:0+73575959,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-94.warc:0+76623408,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-95.warc:0+74901381,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-96.warc:0+73885484,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-97.warc:0+71347435,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-98.warc:0+74219874,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-99.warc:0+73897436,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-00.warc:0+79133528,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-01.warc:0+74009227,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-02.warc:0+80430330,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-03.warc:0+73701237,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-04.warc:0+74340265,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-05.warc:0+74242806,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-06.warc:0+73391812,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-07.warc:0+74133458,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-08.warc:0+73758528,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-09.warc:0+73982566,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-10.warc:0+73699809,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-11.warc:0+70234155,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-12.warc:0+74881916,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-13.warc:0+73241700,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-14.warc:0+73786462,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-15.warc:0+74859093,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-16.warc:0+72370372,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-17.warc:0+74299596,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-18.warc:0+75935349,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-19.warc:0+74261918,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-20.warc:0+80870166,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-21.warc:0+73230329,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-22.warc:0+74453106,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-23.warc:0+78116800,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-24.warc:0+72853975,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-25.warc:0+74911574,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-26.warc:0+75404200,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-27.warc:0+73305296,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-28.warc:0+75169814,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-29.warc:0+74468730,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-30.warc:0+73540450,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-31.warc:0+76851845,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-32.warc:0+75953809,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-33.warc:0+75241383,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-34.warc:0+74550803,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-35.warc:0+76031694,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-36.warc:0+74262320,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-37.warc:0+71715082,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-38.warc:0+74828669,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-39.warc:0+73389244,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-40.warc:0+72778533,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-41.warc:0+74730788,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-42.warc:0+70585549,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-43.warc:0+76704373,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-44.warc:0+74045799,/mnt/cw12/cw-data/ClueWeb12_00/0006wb/0006wb-45.warc:0+75623442,/mnt/cw12/cw-data/ClueWeb12_00/0007wb/0007wb-14.warc:0+74597959
2014-07-10 20:43:57,562 [Executor task launch worker-15] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-89.warc:0+61225011,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-90.warc:0+52754648,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-91.warc:0+56415979,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-92.warc:0+65303776,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-93.warc:0+68412969,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-94.warc:0+62904764,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-95.warc:0+52157789,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-96.warc:0+56857234,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-97.warc:0+72098542,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-98.warc:0+69116588,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-99.warc:0+55148977,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-00.warc:0+57507894,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-01.warc:0+56787292,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-02.warc:0+54642242,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-03.warc:0+59415682,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-04.warc:0+56807355,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-05.warc:0+57811661,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-06.warc:0+58025670,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-07.warc:0+57236629,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-08.warc:0+58981177,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-09.warc:0+58688431,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-10.warc:0+57564495,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-11.warc:0+56132641,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-12.warc:0+57159396,/mnt/cw12/cw-data/ClueWeb12_10/1016wb/1016wb-13.warc:0+69242803,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-14.warc:0+57360059,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-15.warc:0+65625636,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-16.warc:0+55761767,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-17.warc:0+57224747,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-18.warc:0+55093218,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-19.warc:0+53613913,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-20.warc:0+56794327,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-21.warc:0+54849526,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-22.warc:0+55751060,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-23.warc:0+55453980,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-24.warc:0+56506709,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-25.warc:0+58876296,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-26.warc:0+56331730,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-27.warc:0+55586839,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-28.warc:0+57816041,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-29.warc:0+54703524,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-30.warc:0+55713439,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-31.warc:0+54030720,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-32.warc:0+66037021,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-33.warc:0+69279501,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-34.warc:0+71094999,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-35.warc:0+72802128,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-36.warc:0+73165478,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-37.warc:0+73038265,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-38.warc:0+57691453,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-39.warc:0+55513632,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-40.warc:0+66428435,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-41.warc:0+69089094,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-42.warc:0+66681920,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-43.warc:0+58058282,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-44.warc:0+60053588,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-45.warc:0+58417973,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-46.warc:0+60836118,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-47.warc:0+70209308,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-48.warc:0+69148568,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-49.warc:0+66679892,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-50.warc:0+56973468,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-51.warc:0+60905796,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-52.warc:0+58347822,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-53.warc:0+60054240,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-54.warc:0+57511085,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-55.warc:0+61709448,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-56.warc:0+57708644,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-57.warc:0+59518126,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-58.warc:0+61167995,/mnt/cw12/cw-data/ClueWeb12_10/1017wb/1017wb-59.warc:0+60223051
2014-07-10 20:43:57,562 [Executor task launch worker-14] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-20.warc:0+71502205,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-21.warc:0+72322116,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-22.warc:0+73502861,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-23.warc:0+69866496,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-24.warc:0+71827672,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-25.warc:0+70840405,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-26.warc:0+71875367,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-27.warc:0+71764436,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-28.warc:0+71748136,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-29.warc:0+69920422,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-30.warc:0+69808182,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-31.warc:0+65535386,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-64.warc:0+69513181,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-65.warc:0+70248655,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-66.warc:0+71894916,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-67.warc:0+71952998,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-68.warc:0+73594014,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-69.warc:0+72523947,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-70.warc:0+74006227,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-71.warc:0+72482137,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-72.warc:0+73796375,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-73.warc:0+72437280,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-74.warc:0+69465238,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-75.warc:0+72714864,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-76.warc:0+70295668,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-77.warc:0+74204379,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-78.warc:0+70422079,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-79.warc:0+72911081,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-80.warc:0+73387162,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-81.warc:0+76177909,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-82.warc:0+72816992,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-83.warc:0+73000955,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-84.warc:0+80800033,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-85.warc:0+72281910,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-86.warc:0+71529814,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-87.warc:0+71511854,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-88.warc:0+64991864,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-89.warc:0+65508954,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-90.warc:0+62576430,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-91.warc:0+65410946,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-92.warc:0+63055427,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-93.warc:0+63254455,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-94.warc:0+62006271,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-95.warc:0+62791891,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-96.warc:0+66175445,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-97.warc:0+62528045,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-98.warc:0+63678955,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-99.warc:0+65031338,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-32.warc:0+63402364,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-33.warc:0+62128188,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-34.warc:0+63704160,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-35.warc:0+61055893,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-36.warc:0+63178519,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-37.warc:0+60659915,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-38.warc:0+62677273,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-39.warc:0+65272394,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-40.warc:0+62067148,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-41.warc:0+64448818,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-42.warc:0+65546612,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-43.warc:0+63308989,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-44.warc:0+60626000,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-45.warc:0+63870923,/mnt/cw12/cw-data/ClueWeb12_10/1006wb/1006wb-46.warc:0+62858654
2014-07-10 20:43:57,562 [Executor task launch worker-12] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_09/0905wb/0905wb-17.warc:0+71643430,/mnt/cw12/cw-data/ClueWeb12_09/0905wb/0905wb-18.warc:0+68380969,/mnt/cw12/cw-data/ClueWeb12_09/0905wb/0905wb-19.warc:0+75166265,/mnt/cw12/cw-data/ClueWeb12_09/0905wb/0905wb-20.warc:0+73528706,/mnt/cw12/cw-data/ClueWeb12_09/0905wb/0905wb-21.warc:0+74656278,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-10.warc:0+67913945,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-11.warc:0+65170137,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-12.warc:0+58992491,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-13.warc:0+55382090,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-14.warc:0+56399221,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-15.warc:0+58333736,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-16.warc:0+60764353,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-17.warc:0+59014487,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-18.warc:0+60665539,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-19.warc:0+55767119,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-20.warc:0+60556050,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-21.warc:0+57137197,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-22.warc:0+59378961,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-23.warc:0+61538340,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-24.warc:0+62722931,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-25.warc:0+67398858,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-26.warc:0+66140096,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-27.warc:0+70309667,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-28.warc:0+73776668,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-29.warc:0+71221071,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-30.warc:0+72408867,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-31.warc:0+72618932,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-32.warc:0+73300683,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-33.warc:0+69148622,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-34.warc:0+70140318,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-35.warc:0+72430154,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-36.warc:0+69671715,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-37.warc:0+70979463,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-38.warc:0+69074593,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-39.warc:0+73420965,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-40.warc:0+68295383,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-41.warc:0+65051617,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-42.warc:0+59487700,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-43.warc:0+56693132,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-44.warc:0+56062549,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-45.warc:0+58616916,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-46.warc:0+59622099,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-47.warc:0+60694405,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-48.warc:0+60093291,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-49.warc:0+59000679,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-50.warc:0+61936945,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-51.warc:0+58617197,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-52.warc:0+60562823,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-53.warc:0+61048265,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-54.warc:0+69289196,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-55.warc:0+72339138,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-56.warc:0+70102398,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-57.warc:0+67841070,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-58.warc:0+71963115,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-59.warc:0+72077367,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-60.warc:0+67631897,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-61.warc:0+71533457,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-62.warc:0+69180220,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-63.warc:0+69992905,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-64.warc:0+71873774,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-65.warc:0+70258631,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-66.warc:0+68804899,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-67.warc:0+74107915,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-68.warc:0+68396060,/mnt/cw12/cw-data/ClueWeb12_09/0906wb/0906wb-69.warc:0+69693719
2014-07-10 20:43:57,562 [Executor task launch worker-4] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-40.warc:0+76103099,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-41.warc:0+73574281,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-42.warc:0+71747877,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-43.warc:0+73671053,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-44.warc:0+73729897,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-45.warc:0+74696131,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-46.warc:0+76130125,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-47.warc:0+76728980,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-48.warc:0+75537645,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-49.warc:0+76719734,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-50.warc:0+75466187,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-51.warc:0+73648228,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-52.warc:0+69726068,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-53.warc:0+73177257,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-54.warc:0+72906258,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-55.warc:0+73187506,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-56.warc:0+74618371,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-57.warc:0+74874275,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-58.warc:0+76962846,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-59.warc:0+71733605,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-60.warc:0+75924156,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-61.warc:0+74158327,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-62.warc:0+72209349,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-63.warc:0+74275237,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-64.warc:0+80011705,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-65.warc:0+72619924,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-66.warc:0+75605692,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-67.warc:0+73673711,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-68.warc:0+72832552,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-69.warc:0+75915632,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-70.warc:0+75387438,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-71.warc:0+74194945,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-72.warc:0+76174498,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-73.warc:0+74191738,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-74.warc:0+72452845,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-75.warc:0+76897663,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-76.warc:0+72121259,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-77.warc:0+78501240,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-78.warc:0+78719354,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-79.warc:0+73599802,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-80.warc:0+73360734,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-81.warc:0+71537378,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-82.warc:0+73010946,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-83.warc:0+73765552,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-84.warc:0+73923659,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-85.warc:0+76772540,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-86.warc:0+71799326,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-87.warc:0+77271500,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-88.warc:0+73302874,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-89.warc:0+73571230,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-90.warc:0+73850116,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-91.warc:0+75152131,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-92.warc:0+75491674,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-93.warc:0+74348886,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-94.warc:0+71328852,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-95.warc:0+76539129,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-96.warc:0+72853006,/mnt/cw12/cw-data/ClueWeb12_03/0301wb/0301wb-97.warc:0+82559766
2014-07-10 20:43:57,567 [Executor task launch worker-6] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-70.warc:0+73337764,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-71.warc:0+48736980,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-72.warc:0+48551534,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-73.warc:0+48380206,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-74.warc:0+48030135,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-75.warc:0+54076340,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-76.warc:0+49905444,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-77.warc:0+49095860,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-78.warc:0+52426738,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-79.warc:0+77080073,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-80.warc:0+73913442,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-81.warc:0+49816096,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-82.warc:0+48135903,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-83.warc:0+73181835,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-84.warc:0+75886345,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-85.warc:0+59835466,/mnt/cw12/cw-data/ClueWeb12_04/0406wb/0406wb-86.warc:0+48503021,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-74.warc:0+45752721,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-75.warc:0+51623944,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-76.warc:0+76884098,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-77.warc:0+73369361,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-78.warc:0+47718605,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-79.warc:0+47289149,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-80.warc:0+47383240,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-81.warc:0+45596174,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-82.warc:0+56474438,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-83.warc:0+61465833,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-84.warc:0+46952543,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-85.warc:0+73899979,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-86.warc:0+75570589,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-87.warc:0+72636014,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-88.warc:0+74135330,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-89.warc:0+66852540,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-90.warc:0+46592135,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-91.warc:0+48188478,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-92.warc:0+47611645,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-93.warc:0+45912756,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-94.warc:0+46942063,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-95.warc:0+48896588,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-00.warc:0+67231250,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-01.warc:0+68327196,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-02.warc:0+55904860,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-03.warc:0+61060395,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-04.warc:0+67436693,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-05.warc:0+49088629,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-06.warc:0+48124973,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-07.warc:0+46826359,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-08.warc:0+48297404,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-09.warc:0+45902916,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-10.warc:0+49660096,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-11.warc:0+43191312,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-12.warc:0+47213421,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-13.warc:0+56020679,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-14.warc:0+80875331,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-15.warc:0+73998331,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-16.warc:0+76839139,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-17.warc:0+73895573,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-18.warc:0+71956231,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-19.warc:0+73439449,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-20.warc:0+58520760,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-21.warc:0+45958112,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-22.warc:0+48847591,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-23.warc:0+47308917,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-24.warc:0+48407788,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-25.warc:0+47012299,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-26.warc:0+46031018,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-27.warc:0+47455563,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-28.warc:0+46615273,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-29.warc:0+48701677,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-30.warc:0+47628023,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-31.warc:0+48714786,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-32.warc:0+47473521,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-33.warc:0+48327025,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-34.warc:0+70720951,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-35.warc:0+79910571,/mnt/cw12/cw-data/ClueWeb12_04/0407wb/0407wb-36.warc:0+64040767
2014-07-10 20:43:57,567 [Executor task launch worker-7] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-21.warc:0+43410791,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-22.warc:0+46250948,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-23.warc:0+50724508,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-24.warc:0+44027112,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-25.warc:0+19621936,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-26.warc:0+925030,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-27.warc:0+41133144,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-28.warc:0+43637838,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-29.warc:0+41436627,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-30.warc:0+1656902,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-31.warc:0+20018285,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-32.warc:0+44423752,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-33.warc:0+3086132,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-34.warc:0+18358603,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-35.warc:0+49230317,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-36.warc:0+76919284,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-37.warc:0+73767976,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-38.warc:0+50454025,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-39.warc:0+49480673,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-40.warc:0+41132817,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-41.warc:0+45458409,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-42.warc:0+46684924,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-43.warc:0+41212294,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-44.warc:0+20096920,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-45.warc:0+1798997,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-46.warc:0+54970556,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-47.warc:0+21829508,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-49.warc:0+45092902,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-50.warc:0+46255068,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-51.warc:0+44871868,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-52.warc:0+50301641,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-53.warc:0+37479760,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-55.warc:0+25676582,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-56.warc:0+39703443,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-57.warc:0+43814260,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-58.warc:0+17377994,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-59.warc:0+5552565,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-60.warc:0+46805271,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-61.warc:0+47738591,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-62.warc:0+48273727,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-63.warc:0+174862,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-64.warc:0+32982158,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-65.warc:0+43365905,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-66.warc:0+75166219,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-67.warc:0+67498599,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-68.warc:0+41345406,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-69.warc:0+47571256,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-70.warc:0+22748190,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-72.warc:0+43029971,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-73.warc:0+49877971,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-74.warc:0+44631005,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-75.warc:0+43854318,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-76.warc:0+39977170,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-78.warc:0+24312700,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-79.warc:0+50456320,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-80.warc:0+50169139,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-81.warc:0+45689695,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-82.warc:0+47069201,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-83.warc:0+13144102,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-84.warc:0+7749387,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-85.warc:0+70211737,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-86.warc:0+47716232,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-87.warc:0+45215383,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-88.warc:0+45522651,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-89.warc:0+49907572,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-90.warc:0+38659423,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-92.warc:0+24516398,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-93.warc:0+38750831,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-94.warc:0+45800389,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-95.warc:0+48612480,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-96.warc:0+47854344,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-97.warc:0+20146610,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-99.warc:0+37768968,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-00.warc:0+49984607,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-01.warc:0+43468464,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-03.warc:0+26899475,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-04.warc:0+34290800,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-06.warc:0+28204223,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-07.warc:0+45692674,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-08.warc:0+43824078,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-09.warc:0+43846922,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-10.warc:0+38930928,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-12.warc:0+28340375,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-13.warc:0+44665362,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-14.warc:0+45556809,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-15.warc:0+29273475,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-17.warc:0+36108585,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-18.warc:0+17818400,/mnt/cw12/cw-data/ClueWeb12_05/0509wb/0509wb-19.warc:0+12727200,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-06.warc:0+43074561,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-07.warc:0+45015867,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-08.warc:0+48285296,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-09.warc:0+44027626,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-10.warc:0+25709070,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-12.warc:0+66268639,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-13.warc:0+74042557,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-14.warc:0+51876845,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-15.warc:0+31140309,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-17.warc:0+33299626,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-18.warc:0+48609988,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-19.warc:0+43200850,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-20.warc:0+44833809,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-21.warc:0+44927115,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-22.warc:0+47010518,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-23.warc:0+30334960,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-25.warc:0+31605899,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-26.warc:0+47107142,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-27.warc:0+47946347,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-28.warc:0+1063372,/mnt/cw12/cw-data/ClueWeb12_05/0510wb/0510wb-29.warc:0+44939329
2014-07-10 20:43:57,563 [Executor task launch worker-1] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_01/0100wb/0100wb-13.warc:0+72822554,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-46.warc:0+81442190,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-47.warc:0+74486882,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-48.warc:0+76718222,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-49.warc:0+82528272,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-50.warc:0+76034977,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-51.warc:0+66055456,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-52.warc:0+75803555,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-53.warc:0+75250045,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-54.warc:0+77627363,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-55.warc:0+75219039,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-56.warc:0+78243409,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-57.warc:0+76031370,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-58.warc:0+73064136,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-59.warc:0+74215785,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-60.warc:0+76072468,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-61.warc:0+75890383,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-62.warc:0+75483124,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-63.warc:0+80525639,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-64.warc:0+76450206,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-65.warc:0+75573800,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-66.warc:0+75226116,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-67.warc:0+73256785,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-68.warc:0+80675879,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-69.warc:0+74289905,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-70.warc:0+74108465,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-71.warc:0+76052754,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-72.warc:0+76341635,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-73.warc:0+74295508,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-74.warc:0+76436127,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-75.warc:0+72369586,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-76.warc:0+74471795,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-77.warc:0+76462885,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-78.warc:0+71877472,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-79.warc:0+76036085,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-80.warc:0+74713701,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-81.warc:0+72489231,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-82.warc:0+78755628,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-83.warc:0+72141137,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-84.warc:0+73808465,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-85.warc:0+74450893,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-86.warc:0+74535859,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-87.warc:0+77803717,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-88.warc:0+72732331,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-89.warc:0+74037496,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-90.warc:0+72966417,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-91.warc:0+72095241,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-92.warc:0+77623939,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-93.warc:0+72929162,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-94.warc:0+76056120,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-95.warc:0+75260215,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-96.warc:0+75313331,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-97.warc:0+75097785,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-98.warc:0+75869503,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-99.warc:0+71265633,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-00.warc:0+73980546,/mnt/cw12/cw-data/ClueWeb12_01/0101wb/0101wb-01.warc:0+73919574
2014-07-10 20:43:57,563 [Executor task launch worker-11] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-74.warc:0+66735467,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-75.warc:0+68425917,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-76.warc:0+68528477,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-77.warc:0+70817708,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-78.warc:0+74112664,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-79.warc:0+70914789,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-80.warc:0+71788269,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-81.warc:0+69429504,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-82.warc:0+72316782,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-83.warc:0+68164121,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-84.warc:0+70503742,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-85.warc:0+73569229,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-86.warc:0+73336700,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-87.warc:0+75526120,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-88.warc:0+73791283,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-89.warc:0+77527725,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-90.warc:0+69630710,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-91.warc:0+74927295,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-92.warc:0+69295751,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-93.warc:0+73460567,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-94.warc:0+68713334,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-95.warc:0+72544006,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-96.warc:0+75459032,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-97.warc:0+72641554,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-98.warc:0+66669607,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-99.warc:0+74631284,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-00.warc:0+69714044,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-01.warc:0+67576005,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-02.warc:0+68358551,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-03.warc:0+68012594,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-04.warc:0+68189196,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-05.warc:0+68334549,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-06.warc:0+67178435,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-07.warc:0+66757052,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-08.warc:0+66844805,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-09.warc:0+67099602,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-10.warc:0+70263215,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-11.warc:0+70530512,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-12.warc:0+68943568,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-13.warc:0+70268372,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-14.warc:0+65571130,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-15.warc:0+69712707,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-16.warc:0+67416943,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-17.warc:0+73196034,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-18.warc:0+72725970,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-19.warc:0+72199947,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-20.warc:0+72481021,/mnt/cw12/cw-data/ClueWeb12_08/0814wb/0814wb-21.warc:0+73170062,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-78.warc:0+69587018,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-79.warc:0+70233881,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-80.warc:0+68332544,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-81.warc:0+67253191,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-82.warc:0+66835812,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-83.warc:0+68890938,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-84.warc:0+70299676,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-85.warc:0+68657750,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-86.warc:0+70369756,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-87.warc:0+70350829,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-88.warc:0+72984500,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-89.warc:0+71096726,/mnt/cw12/cw-data/ClueWeb12_08/0815wb/0815wb-90.warc:0+72563994
2014-07-10 20:43:57,563 [Executor task launch worker-3] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-97.warc:0+80034975,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-98.warc:0+71900553,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-99.warc:0+69902567,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-00.warc:0+73146584,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-01.warc:0+74111213,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-02.warc:0+74525427,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-03.warc:0+74200473,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-04.warc:0+75483582,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-05.warc:0+75514150,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-06.warc:0+69644451,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-07.warc:0+72714717,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-08.warc:0+79103093,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-09.warc:0+78037170,/mnt/cw12/cw-data/ClueWeb12_02/0205wb/0205wb-10.warc:0+76753132,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-46.warc:0+71745957,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-47.warc:0+74129159,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-48.warc:0+73101349,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-49.warc:0+75651097,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-50.warc:0+73231426,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-51.warc:0+71995726,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-52.warc:0+72107319,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-53.warc:0+75466247,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-54.warc:0+75159279,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-55.warc:0+77494944,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-56.warc:0+76938067,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-57.warc:0+75725982,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-58.warc:0+73269244,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-59.warc:0+75511878,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-60.warc:0+74768554,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-61.warc:0+67911951,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-62.warc:0+76318887,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-63.warc:0+74150943,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-64.warc:0+74257038,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-65.warc:0+74139803,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-66.warc:0+74116037,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-67.warc:0+73046027,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-68.warc:0+68079899,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-69.warc:0+70575408,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-70.warc:0+71979748,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-71.warc:0+71214037,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-72.warc:0+72876078,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-73.warc:0+76532226,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-74.warc:0+78094061,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-75.warc:0+72759124,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-76.warc:0+87078924,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-77.warc:0+73651278,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-78.warc:0+73843564,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-79.warc:0+73386934,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-80.warc:0+71319219,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-81.warc:0+74772305,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-82.warc:0+71339172,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-83.warc:0+75524848,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-84.warc:0+73923324,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-85.warc:0+74785248,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-86.warc:0+75240685,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-87.warc:0+72944392,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-88.warc:0+72177280,/mnt/cw12/cw-data/ClueWeb12_02/0206wb/0206wb-89.warc:0+68920745
2014-07-10 21:01:56,584 [Executor task launch worker-1] ERROR WarcFileProcessor - Exception processing record: clueweb12-0101wb-51-22353
2014-07-10 21:59:12,679 [Executor task launch worker-4] ERROR WarcFileProcessor - Exception processing record: clueweb12-0301wb-69-14899
2014-07-10 22:05:26,318 [Executor task launch worker-1] ERROR WarcFileProcessor - Exception processing record: clueweb12-0101wb-74-29914
2014-07-10 22:24:11,597 [spark-akka.actor.default-dispatcher-21] WARN  org.apache.spark.storage.BlockManagerMasterActor - Removing BlockManager BlockManagerId(6, dco-node134-mgt.dco.ethz.ch, 47137, 0) with no recent heart beats: 69391ms exceeds 45000ms
2014-07-10 22:24:13,325 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:47137 with 40.3 GB RAM
2014-07-10 22:25:32,481 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:256 as TID 256 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:25:32,483 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:256 as 6474 bytes in 1 ms
2014-07-10 22:25:32,501 [Result resolver thread-0] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 5 (task 0.0:5)
2014-07-10 22:25:32,508 [Result resolver thread-0] WARN  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException
org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1347)
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updatePipeline(ClientNamenodeProtocolTranslatorPB.java:791)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1047)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:823)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:475)
2014-07-10 22:33:10,924 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:5 as TID 257 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:33:10,924 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:5 as 5808 bytes in 0 ms
2014-07-10 22:33:10,949 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 9 in 6554579 ms on dco-node126-mgt.dco.ethz.ch (progress: 1/497)
2014-07-10 22:33:10,950 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 9)
2014-07-10 22:37:09,218 [Executor task launch worker-15] ERROR WarcFileProcessor - Exception processing record: clueweb12-1017wb-43-20004
2014-07-10 22:46:47,837 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:257 as TID 258 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:46:47,838 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:257 as 6849 bytes in 1 ms
2014-07-10 22:46:47,849 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 16 in 7371480 ms on dco-node133-mgt.dco.ethz.ch (progress: 2/497)
2014-07-10 22:46:47,849 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 16)
2014-07-10 22:50:33,458 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:258 as TID 259 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:50:33,458 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:258 as 6326 bytes in 0 ms
2014-07-10 22:50:33,466 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 8 in 7597109 ms on dco-node132-mgt.dco.ethz.ch (progress: 3/497)
2014-07-10 22:50:33,466 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 8)
2014-07-10 22:50:57,192 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:259 as TID 260 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:50:57,193 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:259 as 5956 bytes in 1 ms
2014-07-10 22:50:57,201 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 6 in 7620845 ms on dco-node129-mgt.dco.ethz.ch (progress: 4/497)
2014-07-10 22:50:57,201 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 6)
2014-07-10 22:54:29,567 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:260 as TID 261 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:54:29,568 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:260 as 6400 bytes in 1 ms
2014-07-10 22:54:29,588 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 2 in 7833227 ms on dco-node123-mgt.dco.ethz.ch (progress: 5/497)
2014-07-10 22:54:29,588 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 2)
2014-07-10 22:54:30,132 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:261 as TID 262 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:54:30,132 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:261 as 6400 bytes in 0 ms
2014-07-10 22:54:30,137 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 4 in 7833789 ms on dco-node130-mgt.dco.ethz.ch (progress: 6/497)
2014-07-10 22:54:30,138 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 4)
2014-07-10 22:54:51,316 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:262 as TID 263 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:54:51,316 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:262 as 6178 bytes in 0 ms
2014-07-10 22:54:51,322 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 0 in 7854986 ms on dco-node133-mgt.dco.ethz.ch (progress: 7/497)
2014-07-10 22:54:51,322 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 0)
2014-07-10 22:54:54,694 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:263 as TID 264 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:54:54,694 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:263 as 6252 bytes in 0 ms
2014-07-10 22:54:54,700 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 3 in 7858352 ms on dco-node131-mgt.dco.ethz.ch (progress: 8/497)
2014-07-10 22:54:54,700 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 3)
2014-07-10 22:56:51,514 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:264 as TID 265 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:56:51,515 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:264 as 6178 bytes in 0 ms
2014-07-10 22:56:51,519 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 20 in 7975153 ms on dco-node130-mgt.dco.ethz.ch (progress: 9/497)
2014-07-10 22:56:51,519 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 20)
2014-07-10 22:57:36,453 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:265 as TID 266 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:57:36,453 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:265 as 6252 bytes in 0 ms
2014-07-10 22:57:36,459 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 11 in 8020101 ms on dco-node124-mgt.dco.ethz.ch (progress: 10/497)
2014-07-10 22:57:36,459 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 11)
2014-07-10 22:57:57,125 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:266 as TID 267 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:57:57,126 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:266 as 6326 bytes in 1 ms
2014-07-10 22:57:57,131 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 22)
2014-07-10 22:57:57,131 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 22 in 8040762 ms on dco-node129-mgt.dco.ethz.ch (progress: 11/497)
2014-07-10 22:57:57,963 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:267 as TID 268 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:57:57,964 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:267 as 6252 bytes in 1 ms
2014-07-10 22:57:57,967 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 10 in 8041612 ms on dco-node128-mgt.dco.ethz.ch (progress: 12/497)
2014-07-10 22:57:57,967 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 10)
2014-07-10 22:59:10,967 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:268 as TID 269 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:59:10,968 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:268 as 6178 bytes in 0 ms
2014-07-10 22:59:10,973 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 90 in 8114556 ms on dco-node128-mgt.dco.ethz.ch (progress: 13/497)
2014-07-10 22:59:10,973 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 90)
2014-07-10 22:59:31,228 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:269 as TID 270 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:59:31,228 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:269 as 6474 bytes in 0 ms
2014-07-10 22:59:31,233 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 24 in 8134863 ms on dco-node132-mgt.dco.ethz.ch (progress: 14/497)
2014-07-10 22:59:31,233 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 24)
2014-07-10 22:59:35,493 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:270 as TID 271 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 22:59:35,494 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:270 as 6624 bytes in 0 ms
2014-07-10 22:59:35,500 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 19)
2014-07-10 22:59:35,500 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 19 in 8139133 ms on dco-node131-mgt.dco.ethz.ch (progress: 15/497)
2014-07-10 23:00:02,192 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:271 as TID 272 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:00:02,193 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:271 as 6550 bytes in 1 ms
2014-07-10 23:00:02,197 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 51 in 8165807 ms on dco-node131-mgt.dco.ethz.ch (progress: 16/497)
2014-07-10 23:00:02,197 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 51)
2014-07-10 23:00:21,627 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:272 as TID 273 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:00:21,628 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:272 as 6326 bytes in 1 ms
2014-07-10 23:00:21,632 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 41 in 8185249 ms on dco-node126-mgt.dco.ethz.ch (progress: 17/497)
2014-07-10 23:00:21,632 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 41)
2014-07-10 23:00:54,578 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:273 as TID 274 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:00:54,578 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:273 as 6326 bytes in 0 ms
2014-07-10 23:00:54,582 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 42 in 8218198 ms on dco-node128-mgt.dco.ethz.ch (progress: 18/497)
2014-07-10 23:00:54,582 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 42)
2014-07-10 23:00:59,067 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:274 as TID 275 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:00:59,068 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:274 as 6104 bytes in 0 ms
2014-07-10 23:00:59,073 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 88 in 8222657 ms on dco-node132-mgt.dco.ethz.ch (progress: 19/497)
2014-07-10 23:00:59,073 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 88)
2014-07-10 23:00:59,259 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:275 as TID 276 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:00:59,260 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:275 as 6326 bytes in 0 ms
2014-07-10 23:00:59,264 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 36 in 8222885 ms on dco-node130-mgt.dco.ethz.ch (progress: 20/497)
2014-07-10 23:00:59,264 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 36)
2014-07-10 23:01:08,670 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:276 as TID 277 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:01:08,671 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:276 as 6178 bytes in 1 ms
2014-07-10 23:01:08,675 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 67)
2014-07-10 23:01:08,675 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 67 in 8232273 ms on dco-node131-mgt.dco.ethz.ch (progress: 21/497)
2014-07-10 23:01:19,236 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:277 as TID 278 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:01:19,237 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:277 as 6326 bytes in 1 ms
2014-07-10 23:01:19,241 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 91 in 8242824 ms on dco-node124-mgt.dco.ethz.ch (progress: 22/497)
2014-07-10 23:01:19,241 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 91)
2014-07-10 23:01:28,947 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:278 as TID 279 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:01:28,948 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:278 as 6252 bytes in 0 ms
2014-07-10 23:01:28,953 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 18)
2014-07-10 23:01:28,953 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 18 in 8252588 ms on dco-node123-mgt.dco.ethz.ch (progress: 23/497)
2014-07-10 23:01:31,089 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Serialized size of result for 172 is 535
2014-07-10 23:01:31,090 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Sending result for 172 directly to driver
2014-07-10 23:01:31,092 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Finished task ID 172
2014-07-10 23:01:31,093 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:279 as TID 280 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:01:31,094 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:279 as 6178 bytes in 1 ms
2014-07-10 23:01:31,095 [sparkExecutor-akka.actor.default-dispatcher-17] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 280
2014-07-10 23:01:31,095 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Running task ID 280
2014-07-10 23:01:31,098 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 172 in 8254638 ms on dco-node121-mgt.dco.ethz.ch (progress: 24/497)
2014-07-10 23:01:31,098 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 172)
2014-07-10 23:01:31,098 [Executor task launch worker-10] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:01:31,099 [Executor task launch worker-10] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-16.warc:0+72667413,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-17.warc:0+77018188,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-18.warc:0+72258251,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-19.warc:0+68444777,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-20.warc:0+70800411,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-21.warc:0+70675895,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-22.warc:0+69976559,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-23.warc:0+63121652,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-24.warc:0+62291141,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-25.warc:0+63705880,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-26.warc:0+62810976,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-27.warc:0+63996004,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-28.warc:0+62311650,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-29.warc:0+63873528,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-30.warc:0+62766923,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-31.warc:0+63954689,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-32.warc:0+65521982,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-33.warc:0+63808181,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-34.warc:0+68021437,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-35.warc:0+64419026,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-36.warc:0+61546978,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-37.warc:0+64551216,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-38.warc:0+62242916,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-39.warc:0+61936120,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-40.warc:0+62883526,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-41.warc:0+62109999,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-42.warc:0+62876534,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-43.warc:0+63653059,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-44.warc:0+65425945,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-45.warc:0+63789258,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-46.warc:0+68173186,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-47.warc:0+70748928,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-48.warc:0+69798645,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-49.warc:0+69731701,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-50.warc:0+70271345,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-51.warc:0+72418140,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-52.warc:0+71277748,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-53.warc:0+73160718,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-54.warc:0+71450314,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-55.warc:0+73717660,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-56.warc:0+70384926,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-57.warc:0+70049033,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-58.warc:0+72658544,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-59.warc:0+72803440,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-60.warc:0+72716357,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-61.warc:0+72077330,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-62.warc:0+72382034,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-63.warc:0+72642699,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-64.warc:0+70095276,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-65.warc:0+71081968,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-66.warc:0+68071632,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-67.warc:0+71249164,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-68.warc:0+74591381,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-69.warc:0+71945229,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-70.warc:0+73426113,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-71.warc:0+82045594,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-72.warc:0+76846503,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-73.warc:0+72429468,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-74.warc:0+72901477,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-75.warc:0+80610723,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-76.warc:0+71149750,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-77.warc:0+74807847,/mnt/cw12/cw-data/ClueWeb12_11/1112wb/1112wb-78.warc:0+69197774
2014-07-10 23:02:17,625 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:280 as TID 281 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:02:17,625 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:280 as 6326 bytes in 0 ms
2014-07-10 23:02:17,631 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 74)
2014-07-10 23:02:17,631 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 74 in 8301224 ms on dco-node128-mgt.dco.ethz.ch (progress: 25/497)
2014-07-10 23:02:32,504 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:281 as TID 282 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:02:32,505 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:281 as 6326 bytes in 0 ms
2014-07-10 23:02:32,509 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 48 in 8316121 ms on dco-node133-mgt.dco.ethz.ch (progress: 26/497)
2014-07-10 23:02:32,509 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 48)
2014-07-10 23:02:40,362 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:282 as TID 283 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:02:40,363 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:282 as 6178 bytes in 0 ms
2014-07-10 23:02:40,366 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 50 in 8323977 ms on dco-node123-mgt.dco.ethz.ch (progress: 27/497)
2014-07-10 23:02:40,366 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 50)
2014-07-10 23:02:46,029 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:283 as TID 284 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:02:46,030 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:283 as 6178 bytes in 0 ms
2014-07-10 23:02:46,034 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 72 in 8329629 ms on dco-node132-mgt.dco.ethz.ch (progress: 28/497)
2014-07-10 23:02:46,034 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 72)
2014-07-10 23:03:14,187 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:284 as TID 285 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:03:14,187 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:284 as 6252 bytes in 0 ms
2014-07-10 23:03:14,190 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 104 in 8357767 ms on dco-node132-mgt.dco.ethz.ch (progress: 29/497)
2014-07-10 23:03:14,190 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 104)
2014-07-10 23:03:17,636 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:285 as TID 286 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:03:17,636 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:285 as 6252 bytes in 0 ms
2014-07-10 23:03:17,640 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 32)
2014-07-10 23:03:17,640 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 32 in 8361265 ms on dco-node133-mgt.dco.ethz.ch (progress: 30/497)
2014-07-10 23:03:20,589 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:286 as TID 287 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:03:20,590 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:286 as 6178 bytes in 1 ms
2014-07-10 23:03:20,595 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 68)
2014-07-10 23:03:20,595 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 68 in 8364192 ms on dco-node130-mgt.dco.ethz.ch (progress: 31/497)
2014-07-10 23:03:37,014 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:287 as TID 288 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:03:37,015 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:287 as 6252 bytes in 1 ms
2014-07-10 23:03:37,018 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 99 in 8380597 ms on dco-node131-mgt.dco.ethz.ch (progress: 32/497)
2014-07-10 23:03:37,018 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 99)
2014-07-10 23:03:40,270 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:288 as TID 289 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:03:40,271 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:288 as 6326 bytes in 1 ms
2014-07-10 23:03:40,275 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 35)
2014-07-10 23:03:40,275 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 35 in 8383896 ms on dco-node131-mgt.dco.ethz.ch (progress: 33/497)
2014-07-10 23:03:55,721 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:289 as TID 290 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:03:55,721 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:289 as 6178 bytes in 0 ms
2014-07-10 23:03:55,725 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 26)
2014-07-10 23:03:55,725 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 26 in 8399354 ms on dco-node128-mgt.dco.ethz.ch (progress: 34/497)
2014-07-10 23:04:02,262 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:290 as TID 291 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:02,262 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:290 as 5956 bytes in 0 ms
2014-07-10 23:04:02,266 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 52 in 8405875 ms on dco-node130-mgt.dco.ethz.ch (progress: 35/497)
2014-07-10 23:04:02,266 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 52)
2014-07-10 23:04:07,123 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:291 as TID 292 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:07,123 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:291 as 6104 bytes in 0 ms
2014-07-10 23:04:07,127 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 57 in 8410733 ms on dco-node126-mgt.dco.ethz.ch (progress: 36/497)
2014-07-10 23:04:07,127 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 57)
2014-07-10 23:04:11,245 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:292 as TID 293 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:11,246 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:292 as 6178 bytes in 0 ms
2014-07-10 23:04:11,249 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 86 in 8414836 ms on dco-node129-mgt.dco.ethz.ch (progress: 37/497)
2014-07-10 23:04:11,250 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 86)
2014-07-10 23:04:15,037 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:293 as TID 294 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:15,038 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:293 as 6178 bytes in 1 ms
2014-07-10 23:04:15,042 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 27 in 8418670 ms on dco-node124-mgt.dco.ethz.ch (progress: 38/497)
2014-07-10 23:04:15,042 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 27)
2014-07-10 23:04:18,213 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:294 as TID 295 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:18,213 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:294 as 6252 bytes in 0 ms
2014-07-10 23:04:18,217 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 82 in 8421806 ms on dco-node123-mgt.dco.ethz.ch (progress: 39/497)
2014-07-10 23:04:18,217 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 82)
2014-07-10 23:04:23,988 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:295 as TID 296 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:23,988 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:295 as 6624 bytes in 0 ms
2014-07-10 23:04:23,992 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 34)
2014-07-10 23:04:23,992 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 34 in 8427615 ms on dco-node123-mgt.dco.ethz.ch (progress: 40/497)
2014-07-10 23:04:26,130 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:296 as TID 297 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:26,131 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:296 as 6550 bytes in 0 ms
2014-07-10 23:04:26,134 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 102)
2014-07-10 23:04:26,134 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 102 in 8429712 ms on dco-node129-mgt.dco.ethz.ch (progress: 41/497)
2014-07-10 23:04:43,458 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:297 as TID 298 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:43,458 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:297 as 6400 bytes in 0 ms
2014-07-10 23:04:43,462 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 101 in 8447039 ms on dco-node134-mgt.dco.ethz.ch (progress: 42/497)
2014-07-10 23:04:43,462 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 101)
2014-07-10 23:04:44,129 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:298 as TID 299 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:44,130 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:298 as 6474 bytes in 1 ms
2014-07-10 23:04:44,133 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 66 in 8447733 ms on dco-node123-mgt.dco.ethz.ch (progress: 43/497)
2014-07-10 23:04:44,133 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 66)
2014-07-10 23:04:56,003 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:299 as TID 300 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:04:56,004 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:299 as 6400 bytes in 1 ms
2014-07-10 23:04:56,008 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 58 in 8459613 ms on dco-node128-mgt.dco.ethz.ch (progress: 44/497)
2014-07-10 23:04:56,008 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 58)
2014-07-10 23:05:12,299 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:300 as TID 301 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:05:12,300 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:300 as 6400 bytes in 1 ms
2014-07-10 23:05:12,304 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 53 in 8475912 ms on dco-node134-mgt.dco.ethz.ch (progress: 45/497)
2014-07-10 23:05:12,304 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 53)
2014-07-10 23:05:20,997 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 204 is 535
2014-07-10 23:05:20,998 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 204 directly to driver
2014-07-10 23:05:20,998 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 204
2014-07-10 23:05:21,000 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:301 as TID 302 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:05:21,001 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:301 as 6326 bytes in 1 ms
2014-07-10 23:05:21,002 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 302
2014-07-10 23:05:21,004 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 302
2014-07-10 23:05:21,005 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 204 in 8484530 ms on dco-node121-mgt.dco.ethz.ch (progress: 46/497)
2014-07-10 23:05:21,005 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 204)
2014-07-10 23:05:21,005 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:05:21,006 [Executor task launch worker-12] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-16.warc:0+74846628,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-17.warc:0+73378053,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-18.warc:0+74913603,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-19.warc:0+70933830,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-20.warc:0+71384187,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-21.warc:0+68130373,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-22.warc:0+70678823,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-23.warc:0+55002353,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-24.warc:0+61737890,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-25.warc:0+57425727,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-26.warc:0+73891821,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-27.warc:0+67083940,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-28.warc:0+74151904,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-29.warc:0+71603237,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-30.warc:0+72890443,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-31.warc:0+52308036,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-32.warc:0+53056121,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-33.warc:0+63507099,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-34.warc:0+72809055,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-35.warc:0+71054062,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-36.warc:0+69518841,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-37.warc:0+56544772,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-38.warc:0+73236419,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-39.warc:0+72650897,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-40.warc:0+61829543,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-41.warc:0+71610781,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-42.warc:0+73072880,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-43.warc:0+75555348,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-44.warc:0+69648206,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-45.warc:0+59984809,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-46.warc:0+61682464,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-47.warc:0+47233939,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-48.warc:0+62417466,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-49.warc:0+62652447,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-50.warc:0+60987473,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-51.warc:0+62475240,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-52.warc:0+62224256,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-53.warc:0+62013883,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-54.warc:0+59524571,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-55.warc:0+63642229,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-56.warc:0+65012386,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-57.warc:0+60756854,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-58.warc:0+65448509,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-59.warc:0+63103494,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-60.warc:0+61761071,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-61.warc:0+60494632,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-62.warc:0+63096570,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-63.warc:0+61002078,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-64.warc:0+59866715,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-65.warc:0+60008203,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-66.warc:0+64048614,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-67.warc:0+63063097,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-68.warc:0+60779729,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-69.warc:0+67036618,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-70.warc:0+71485616,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-71.warc:0+72241491,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-72.warc:0+72840661,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-73.warc:0+69700474,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-74.warc:0+71895525,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-75.warc:0+69952488,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-76.warc:0+73166762,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-77.warc:0+73170028,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-78.warc:0+70780111,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-79.warc:0+73302768,/mnt/cw12/cw-data/ClueWeb12_12/1206wb/1206wb-80.warc:0+56616114
2014-07-10 23:05:26,004 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:302 as TID 303 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:05:26,005 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:302 as 6326 bytes in 0 ms
2014-07-10 23:05:26,008 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 105 in 8489584 ms on dco-node126-mgt.dco.ethz.ch (progress: 47/497)
2014-07-10 23:05:26,008 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 105)
2014-07-10 23:05:35,122 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:303 as TID 304 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:05:35,122 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:303 as 6400 bytes in 0 ms
2014-07-10 23:05:35,125 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 43 in 8498742 ms on dco-node124-mgt.dco.ethz.ch (progress: 48/497)
2014-07-10 23:05:35,125 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 43)
2014-07-10 23:05:41,706 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:304 as TID 305 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:05:41,706 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:304 as 6400 bytes in 0 ms
2014-07-10 23:05:41,709 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 75 in 8505303 ms on dco-node124-mgt.dco.ethz.ch (progress: 49/497)
2014-07-10 23:05:41,709 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 75)
2014-07-10 23:05:45,040 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:305 as TID 306 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:05:45,040 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:305 as 6326 bytes in 0 ms
2014-07-10 23:05:45,043 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 64)
2014-07-10 23:05:45,043 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 64 in 8508645 ms on dco-node133-mgt.dco.ethz.ch (progress: 50/497)
2014-07-10 23:06:02,272 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:306 as TID 307 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:06:02,273 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:306 as 6400 bytes in 1 ms
2014-07-10 23:06:02,276 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 192 in 8525808 ms on dco-node133-mgt.dco.ethz.ch (progress: 51/497)
2014-07-10 23:06:02,276 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 192)
2014-07-10 23:06:21,586 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:307 as TID 308 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:06:21,587 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:307 as 6400 bytes in 1 ms
2014-07-10 23:06:21,589 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 70 in 8545187 ms on dco-node129-mgt.dco.ethz.ch (progress: 52/497)
2014-07-10 23:06:21,589 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 70)
2014-07-10 23:06:30,022 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:308 as TID 309 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:06:30,023 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:308 as 6326 bytes in 1 ms
2014-07-10 23:06:30,026 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 56)
2014-07-10 23:06:30,026 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 56 in 8553633 ms on dco-node132-mgt.dco.ethz.ch (progress: 53/497)
2014-07-10 23:06:34,913 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:309 as TID 310 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:06:34,914 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:309 as 6326 bytes in 0 ms
2014-07-10 23:06:34,917 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 25 in 8558548 ms on dco-node126-mgt.dco.ethz.ch (progress: 54/497)
2014-07-10 23:06:34,917 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 25)
2014-07-10 23:06:50,179 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Serialized size of result for 252 is 535
2014-07-10 23:06:50,179 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Sending result for 252 directly to driver
2014-07-10 23:06:50,180 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Finished task ID 252
2014-07-10 23:06:50,182 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:310 as TID 311 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:06:50,182 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:310 as 6400 bytes in 0 ms
2014-07-10 23:06:50,184 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 252 in 8573689 ms on dco-node121-mgt.dco.ethz.ch (progress: 55/497)
2014-07-10 23:06:50,184 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 252)
2014-07-10 23:06:50,183 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 311
2014-07-10 23:06:50,185 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Running task ID 311
2014-07-10 23:06:50,186 [Executor task launch worker-15] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:06:50,187 [Executor task launch worker-15] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-05.warc:0+63890926,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-06.warc:0+65211711,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-07.warc:0+64353618,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-08.warc:0+63782925,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-09.warc:0+65556330,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-10.warc:0+61720585,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-11.warc:0+63383845,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-12.warc:0+64897976,/mnt/cw12/cw-data/ClueWeb12_12/1211wb/1211wb-13.warc:0+65886572,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-14.warc:0+63389341,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-15.warc:0+64398233,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-16.warc:0+63802714,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-17.warc:0+62644551,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-18.warc:0+65416549,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-19.warc:0+60079934,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-20.warc:0+65190294,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-21.warc:0+63657782,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-22.warc:0+63851992,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-23.warc:0+64581303,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-24.warc:0+64346081,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-25.warc:0+60152070,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-26.warc:0+65365672,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-27.warc:0+65041554,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-28.warc:0+63575649,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-29.warc:0+63977330,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-30.warc:0+62123923,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-31.warc:0+63621755,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-32.warc:0+64067162,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-33.warc:0+63977587,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-34.warc:0+62565745,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-35.warc:0+63223651,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-36.warc:0+71479733,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-37.warc:0+43005026,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-38.warc:0+64575820,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-39.warc:0+47035993,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-40.warc:0+68514871,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-41.warc:0+67040313,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-42.warc:0+69848554,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-43.warc:0+73137877,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-44.warc:0+73383420,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-45.warc:0+73377523,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-46.warc:0+72213495,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-47.warc:0+71914721,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-48.warc:0+64208563,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-49.warc:0+66299134,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-50.warc:0+70085271,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-51.warc:0+68641357,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-52.warc:0+70131654,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-53.warc:0+52058346,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-54.warc:0+56141127,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-55.warc:0+63930399,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-56.warc:0+66944602,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-57.warc:0+70333830,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-58.warc:0+52094213,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-59.warc:0+51734556,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-60.warc:0+71439598,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-61.warc:0+66921725,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-62.warc:0+70994517,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-63.warc:0+73146627,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-64.warc:0+74426103,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-65.warc:0+68947555,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-66.warc:0+73040244,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-67.warc:0+74274332,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-68.warc:0+71632546,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-69.warc:0+68940671,/mnt/cw12/cw-data/ClueWeb12_12/1212wb/1212wb-70.warc:0+71289691
2014-07-10 23:06:58,388 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:311 as TID 312 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:06:58,389 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:311 as 6400 bytes in 1 ms
2014-07-10 23:06:58,392 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 164 in 8581937 ms on dco-node130-mgt.dco.ethz.ch (progress: 56/497)
2014-07-10 23:06:58,392 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 164)
2014-07-10 23:07:00,248 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:312 as TID 313 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:00,248 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:312 as 6326 bytes in 0 ms
2014-07-10 23:07:00,251 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 21 in 8583886 ms on dco-node134-mgt.dco.ethz.ch (progress: 57/497)
2014-07-10 23:07:00,251 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 21)
2014-07-10 23:07:04,079 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Serialized size of result for 220 is 535
2014-07-10 23:07:04,079 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Sending result for 220 directly to driver
2014-07-10 23:07:04,079 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Finished task ID 220
2014-07-10 23:07:04,082 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:313 as TID 314 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:04,082 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:313 as 6326 bytes in 0 ms
2014-07-10 23:07:04,083 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 314
2014-07-10 23:07:04,085 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 220 in 8587604 ms on dco-node121-mgt.dco.ethz.ch (progress: 58/497)
2014-07-10 23:07:04,085 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Running task ID 314
2014-07-10 23:07:04,086 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 220)
2014-07-10 23:07:04,087 [Executor task launch worker-13] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:07:04,088 [Executor task launch worker-13] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-02.warc:0+73148986,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-03.warc:0+68923343,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-04.warc:0+72894037,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-05.warc:0+71685655,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-06.warc:0+74742463,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-07.warc:0+69703712,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-08.warc:0+69082523,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-09.warc:0+52723336,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-10.warc:0+57089036,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-11.warc:0+62219647,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-12.warc:0+72070699,/mnt/cw12/cw-data/ClueWeb12_12/1213wb/1213wb-13.warc:0+54430749,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-14.warc:0+69377628,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-15.warc:0+71484644,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-16.warc:0+54728821,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-17.warc:0+49150616,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-18.warc:0+71474536,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-19.warc:0+70105886,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-20.warc:0+70345348,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-21.warc:0+72563053,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-22.warc:0+69182810,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-23.warc:0+54438554,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-24.warc:0+51950492,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-25.warc:0+71330963,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-26.warc:0+69278934,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-27.warc:0+72802656,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-28.warc:0+71161040,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-29.warc:0+70860512,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-30.warc:0+73438860,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-31.warc:0+74174464,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-32.warc:0+72394336,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-33.warc:0+72225441,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-34.warc:0+71248842,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-35.warc:0+47217929,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-36.warc:0+56280921,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-37.warc:0+61126304,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-38.warc:0+71510168,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-39.warc:0+64070095,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-40.warc:0+63492111,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-41.warc:0+62570860,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-42.warc:0+62793898,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-43.warc:0+62341572,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-44.warc:0+64192391,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-45.warc:0+62610495,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-46.warc:0+62769297,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-47.warc:0+63314511,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-48.warc:0+65545317,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-49.warc:0+63870184,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-50.warc:0+62755577,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-51.warc:0+64928717,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-52.warc:0+62879277,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-53.warc:0+61745681,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-54.warc:0+63416646,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-55.warc:0+64543316,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-56.warc:0+62995771,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-57.warc:0+62677672,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-58.warc:0+64384491,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-59.warc:0+65517343,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-60.warc:0+71226173,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-61.warc:0+72301658,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-62.warc:0+73132372,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-63.warc:0+72859142,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-64.warc:0+73085503,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-65.warc:0+71406846,/mnt/cw12/cw-data/ClueWeb12_12/1214wb/1214wb-66.warc:0+73048749
2014-07-10 23:07:04,462 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:314 as TID 315 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:04,462 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:314 as 6252 bytes in 0 ms
2014-07-10 23:07:04,466 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 85 in 8588053 ms on dco-node134-mgt.dco.ethz.ch (progress: 59/497)
2014-07-10 23:07:04,466 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 85)
2014-07-10 23:07:09,288 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:315 as TID 316 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:09,288 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:315 as 6326 bytes in 0 ms
2014-07-10 23:07:09,291 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 96)
2014-07-10 23:07:09,291 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 96 in 8592873 ms on dco-node133-mgt.dco.ethz.ch (progress: 60/497)
2014-07-10 23:07:31,349 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:316 as TID 317 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:31,349 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:316 as 6326 bytes in 0 ms
2014-07-10 23:07:31,352 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 38 in 8614972 ms on dco-node129-mgt.dco.ethz.ch (progress: 61/497)
2014-07-10 23:07:31,352 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 38)
2014-07-10 23:07:45,430 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:317 as TID 318 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:45,431 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:317 as 6474 bytes in 1 ms
2014-07-10 23:07:45,433 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 186)
2014-07-10 23:07:45,433 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 186 in 8628969 ms on dco-node128-mgt.dco.ethz.ch (progress: 62/497)
2014-07-10 23:07:45,463 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:318 as TID 319 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:45,463 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:318 as 6252 bytes in 0 ms
2014-07-10 23:07:45,466 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 80 in 8629057 ms on dco-node133-mgt.dco.ethz.ch (progress: 63/497)
2014-07-10 23:07:45,466 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 80)
2014-07-10 23:07:54,155 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:319 as TID 320 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:07:54,155 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:319 as 6326 bytes in 0 ms
2014-07-10 23:07:54,158 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 216 in 8637679 ms on dco-node132-mgt.dco.ethz.ch (progress: 64/497)
2014-07-10 23:07:54,158 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 216)
2014-07-10 23:08:02,807 [spark-akka.actor.default-dispatcher-21] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:320 as TID 321 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:08:02,807 [spark-akka.actor.default-dispatcher-21] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:320 as 6104 bytes in 0 ms
2014-07-10 23:08:02,809 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 69 in 8646408 ms on dco-node134-mgt.dco.ethz.ch (progress: 65/497)
2014-07-10 23:08:02,809 [spark-akka.actor.default-dispatcher-18] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 69)
2014-07-10 23:08:05,131 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:321 as TID 322 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:08:05,131 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:321 as 6178 bytes in 0 ms
2014-07-10 23:08:05,134 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 40 in 8648753 ms on dco-node132-mgt.dco.ethz.ch (progress: 66/497)
2014-07-10 23:08:05,134 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 40)
2014-07-10 23:08:11,207 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:322 as TID 323 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:08:11,207 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:322 as 6252 bytes in 0 ms
2014-07-10 23:08:11,210 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 245)
2014-07-10 23:08:11,210 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 245 in 8654718 ms on dco-node134-mgt.dco.ethz.ch (progress: 67/497)
2014-07-10 23:08:12,171 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:323 as TID 324 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:08:12,171 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:323 as 6326 bytes in 0 ms
2014-07-10 23:08:12,174 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 100 in 8655753 ms on dco-node130-mgt.dco.ethz.ch (progress: 68/497)
2014-07-10 23:08:12,174 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 100)
2014-07-10 23:08:23,545 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:324 as TID 325 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:08:23,546 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:324 as 6326 bytes in 1 ms
2014-07-10 23:08:23,549 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 37)
2014-07-10 23:08:23,549 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 37 in 8667170 ms on dco-node134-mgt.dco.ethz.ch (progress: 69/497)
2014-07-10 23:08:26,597 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:325 as TID 326 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:08:26,598 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:325 as 6400 bytes in 1 ms
2014-07-10 23:08:26,601 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 83 in 8670190 ms on dco-node131-mgt.dco.ethz.ch (progress: 70/497)
2014-07-10 23:08:26,601 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 83)
2014-07-10 23:08:50,312 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:326 as TID 327 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:08:50,312 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:326 as 6400 bytes in 0 ms
2014-07-10 23:08:50,315 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 54 in 8693925 ms on dco-node129-mgt.dco.ethz.ch (progress: 71/497)
2014-07-10 23:08:50,315 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 54)
2014-07-10 23:09:21,898 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 188 is 535
2014-07-10 23:09:21,899 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 188 directly to driver
2014-07-10 23:09:21,899 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 188
2014-07-10 23:09:21,901 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:327 as TID 328 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:09:21,902 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:327 as 6252 bytes in 1 ms
2014-07-10 23:09:21,904 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 188 in 8725439 ms on dco-node121-mgt.dco.ethz.ch (progress: 72/497)
2014-07-10 23:09:21,904 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 188)
2014-07-10 23:09:21,903 [sparkExecutor-akka.actor.default-dispatcher-20] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 328
2014-07-10 23:09:21,905 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 328
2014-07-10 23:09:21,907 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:09:21,908 [Executor task launch worker-11] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-85.warc:0+63339633,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-86.warc:0+66531050,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-87.warc:0+63103110,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-88.warc:0+63092361,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-89.warc:0+63320183,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-90.warc:0+60922159,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-91.warc:0+62574844,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-92.warc:0+66977858,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-93.warc:0+73407794,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-94.warc:0+71793327,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-95.warc:0+71931177,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-96.warc:0+71236334,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-97.warc:0+72448880,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-98.warc:0+73548262,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-99.warc:0+68466290,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-32.warc:0+66673016,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-33.warc:0+65634905,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-34.warc:0+62421169,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-35.warc:0+65421481,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-36.warc:0+65791856,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-37.warc:0+63965934,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-38.warc:0+66075518,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-39.warc:0+62783619,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-40.warc:0+65178295,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-41.warc:0+63878207,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-42.warc:0+67234484,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-43.warc:0+72088947,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-44.warc:0+72396852,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-45.warc:0+71346660,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-46.warc:0+72924432,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-47.warc:0+70311741,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-48.warc:0+69200547,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-49.warc:0+71821029,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-50.warc:0+74018991,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-51.warc:0+73186485,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-52.warc:0+72364680,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-53.warc:0+73147056,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-54.warc:0+71820502,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-55.warc:0+71922879,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-56.warc:0+69592363,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-57.warc:0+77144471,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-58.warc:0+71285225,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-59.warc:0+41655441,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-60.warc:0+45826174,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-61.warc:0+63797054,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-62.warc:0+72072237,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-63.warc:0+50139040,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-00.warc:0+72199421,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-01.warc:0+72441147,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-02.warc:0+71368354,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-03.warc:0+76752375,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-04.warc:0+73112641,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-05.warc:0+73669995,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-06.warc:0+46310030,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-07.warc:0+46097457,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-08.warc:0+67394194,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-09.warc:0+58486090,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-10.warc:0+61062914,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-11.warc:0+70423154,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-12.warc:0+72010140,/mnt/cw12/cw-data/ClueWeb12_13/1303wb/1303wb-13.warc:0+71935880,/mnt/cw12/cw-data/ClueWeb12_13/1304wb/1304wb-14.warc:0+69401901,/mnt/cw12/cw-data/ClueWeb12_13/1304wb/1304wb-15.warc:0+72405923,/mnt/cw12/cw-data/ClueWeb12_13/1304wb/1304wb-16.warc:0+74608757
2014-07-10 23:09:29,148 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:328 as TID 329 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:09:29,149 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:328 as 6474 bytes in 1 ms
2014-07-10 23:09:29,151 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 98 in 8732732 ms on dco-node123-mgt.dco.ethz.ch (progress: 73/497)
2014-07-10 23:09:29,151 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 98)
2014-07-10 23:09:29,831 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:329 as TID 330 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:09:29,832 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:329 as 6252 bytes in 1 ms
2014-07-10 23:09:29,834 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 176 in 8733374 ms on dco-node133-mgt.dco.ethz.ch (progress: 74/497)
2014-07-10 23:09:29,834 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 176)
2014-07-10 23:09:39,572 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:330 as TID 331 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:09:39,573 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:330 as 6326 bytes in 0 ms
2014-07-10 23:09:39,576 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 84)
2014-07-10 23:09:39,576 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 84 in 8743165 ms on dco-node130-mgt.dco.ethz.ch (progress: 75/497)
2014-07-10 23:09:40,823 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:331 as TID 332 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:09:40,824 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:331 as 6474 bytes in 1 ms
2014-07-10 23:09:40,826 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 89 in 8744413 ms on dco-node126-mgt.dco.ethz.ch (progress: 76/497)
2014-07-10 23:09:40,826 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 89)
2014-07-10 23:09:45,333 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:332 as TID 333 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:09:45,333 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:332 as 6474 bytes in 0 ms
2014-07-10 23:09:45,336 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 59)
2014-07-10 23:09:45,336 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 59 in 8748941 ms on dco-node124-mgt.dco.ethz.ch (progress: 77/497)
2014-07-10 23:09:56,940 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:333 as TID 334 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:09:56,941 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:333 as 8706 bytes in 0 ms
2014-07-10 23:09:56,943 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 73 in 8760540 ms on dco-node126-mgt.dco.ethz.ch (progress: 78/497)
2014-07-10 23:09:56,943 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 73)
2014-07-10 23:10:02,533 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:334 as TID 335 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:10:02,534 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:334 as 8038 bytes in 1 ms
2014-07-10 23:10:02,536 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 234 in 8766049 ms on dco-node128-mgt.dco.ethz.ch (progress: 79/497)
2014-07-10 23:10:02,536 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 234)
2014-07-10 23:10:05,855 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:335 as TID 336 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:10:05,855 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:335 as 7515 bytes in 0 ms
2014-07-10 23:10:05,858 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 218 in 8769379 ms on dco-node128-mgt.dco.ethz.ch (progress: 80/497)
2014-07-10 23:10:05,858 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 218)
2014-07-10 23:10:42,832 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:336 as TID 337 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:10:42,832 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:336 as 7890 bytes in 0 ms
2014-07-10 23:10:42,834 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 160)
2014-07-10 23:10:42,834 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 160 in 8806381 ms on dco-node133-mgt.dco.ethz.ch (progress: 81/497)
2014-07-10 23:10:59,492 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:337 as TID 338 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:10:59,493 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:337 as 7665 bytes in 1 ms
2014-07-10 23:10:59,495 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 163)
2014-07-10 23:10:59,495 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 163 in 8823041 ms on dco-node131-mgt.dco.ethz.ch (progress: 82/497)
2014-07-10 23:11:10,825 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:338 as TID 339 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:11:10,825 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:338 as 7665 bytes in 0 ms
2014-07-10 23:11:10,827 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 214 in 8834349 ms on dco-node129-mgt.dco.ethz.ch (progress: 83/497)
2014-07-10 23:11:10,827 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 214)
2014-07-10 23:11:40,967 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:339 as TID 340 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:11:40,968 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:339 as 8112 bytes in 1 ms
2014-07-10 23:11:40,970 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 244)
2014-07-10 23:11:40,970 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 244 in 8864479 ms on dco-node130-mgt.dco.ethz.ch (progress: 84/497)
2014-07-10 23:11:44,682 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:340 as TID 341 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:11:44,683 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:340 as 7665 bytes in 1 ms
2014-07-10 23:11:44,686 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 219)
2014-07-10 23:11:44,686 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 219 in 8868205 ms on dco-node124-mgt.dco.ethz.ch (progress: 85/497)
2014-07-10 23:12:10,349 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:341 as TID 342 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:12:10,349 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:341 as 7816 bytes in 0 ms
2014-07-10 23:12:10,352 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 14 in 8893993 ms on dco-node136-mgt.dco.ethz.ch (progress: 86/497)
2014-07-10 23:12:10,352 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 14)
2014-07-10 23:12:19,425 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:342 as TID 343 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:12:19,426 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:342 as 7890 bytes in 1 ms
2014-07-10 23:12:19,444 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 162 in 8902989 ms on dco-node123-mgt.dco.ethz.ch (progress: 87/497)
2014-07-10 23:12:19,444 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 162)
2014-07-10 23:12:26,614 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:343 as TID 344 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:12:26,615 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:343 as 7145 bytes in 1 ms
2014-07-10 23:12:26,617 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 240)
2014-07-10 23:12:26,617 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 240 in 8910128 ms on dco-node133-mgt.dco.ethz.ch (progress: 88/497)
2014-07-10 23:12:33,601 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:344 as TID 345 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:12:33,601 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:344 as 6252 bytes in 0 ms
2014-07-10 23:12:33,604 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 184)
2014-07-10 23:12:33,604 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 184 in 8917139 ms on dco-node132-mgt.dco.ethz.ch (progress: 89/497)
2014-07-10 23:12:36,200 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:345 as TID 346 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:12:36,200 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:345 as 7739 bytes in 0 ms
2014-07-10 23:12:36,203 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 180 in 8919740 ms on dco-node130-mgt.dco.ethz.ch (progress: 90/497)
2014-07-10 23:12:36,203 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 180)
2014-07-10 23:12:45,114 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:346 as TID 347 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:12:45,114 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:346 as 7665 bytes in 0 ms
2014-07-10 23:12:45,116 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 196 in 8928646 ms on dco-node130-mgt.dco.ethz.ch (progress: 91/497)
2014-07-10 23:12:45,116 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 196)
2014-07-10 23:13:05,786 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:347 as TID 348 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:05,787 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:347 as 10564 bytes in 0 ms
2014-07-10 23:13:05,790 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 46 in 8949404 ms on dco-node136-mgt.dco.ethz.ch (progress: 92/497)
2014-07-10 23:13:05,790 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 46)
2014-07-10 23:13:06,519 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:348 as TID 349 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:06,520 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:348 as 11531 bytes in 1 ms
2014-07-10 23:13:06,522 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 165)
2014-07-10 23:13:06,522 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 165 in 8950067 ms on dco-node134-mgt.dco.ethz.ch (progress: 93/497)
2014-07-10 23:13:14,541 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:349 as TID 350 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:14,542 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:349 as 8706 bytes in 1 ms
2014-07-10 23:13:14,544 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 242 in 8958054 ms on dco-node123-mgt.dco.ethz.ch (progress: 94/497)
2014-07-10 23:13:14,544 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 242)
2014-07-10 23:13:16,195 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:350 as TID 351 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:16,196 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:350 as 7071 bytes in 1 ms
2014-07-10 23:13:16,198 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 30 in 8959826 ms on dco-node136-mgt.dco.ethz.ch (progress: 95/497)
2014-07-10 23:13:16,198 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 30)
2014-07-10 23:13:20,499 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:351 as TID 352 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:20,500 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:351 as 6849 bytes in 1 ms
2014-07-10 23:13:20,501 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 213 in 8964025 ms on dco-node134-mgt.dco.ethz.ch (progress: 96/497)
2014-07-10 23:13:20,501 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 213)
2014-07-10 23:13:32,532 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:352 as TID 353 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:32,533 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:352 as 6775 bytes in 0 ms
2014-07-10 23:13:32,536 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 182 in 8976072 ms on dco-node129-mgt.dco.ethz.ch (progress: 97/497)
2014-07-10 23:13:32,536 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 182)
2014-07-10 23:13:40,000 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Serialized size of result for 76 is 535
2014-07-10 23:13:40,000 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Sending result for 76 directly to driver
2014-07-10 23:13:40,000 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Finished task ID 76
2014-07-10 23:13:40,003 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:353 as TID 354 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:40,003 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:353 as 6550 bytes in 0 ms
2014-07-10 23:13:40,004 [sparkExecutor-akka.actor.default-dispatcher-17] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 354
2014-07-10 23:13:40,005 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 76 in 8983599 ms on dco-node121-mgt.dco.ethz.ch (progress: 98/497)
2014-07-10 23:13:40,005 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 76)
2014-07-10 23:13:40,006 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Running task ID 354
2014-07-10 23:13:40,008 [Executor task launch worker-4] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:13:40,009 [Executor task launch worker-4] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-56.warc:0+62955581,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-57.warc:0+60431674,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-58.warc:0+61423939,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-59.warc:0+65249042,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-60.warc:0+73369043,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-61.warc:0+68910298,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-62.warc:0+64592974,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-63.warc:0+53437416,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-64.warc:0+55875370,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-65.warc:0+72922591,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-66.warc:0+67389951,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-67.warc:0+70702704,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-68.warc:0+60957229,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-69.warc:0+74364826,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-70.warc:0+68311175,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-71.warc:0+58976511,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-72.warc:0+59806370,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-73.warc:0+63129374,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-74.warc:0+52294117,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-75.warc:0+60653590,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-76.warc:0+70918798,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-77.warc:0+67964282,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-78.warc:0+71462378,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-79.warc:0+62322682,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-80.warc:0+63239049,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-81.warc:0+63850503,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-82.warc:0+62823656,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-83.warc:0+73143816,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-84.warc:0+53792337,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-85.warc:0+56271572,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-86.warc:0+68233066,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-87.warc:0+70883134,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-88.warc:0+73677800,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-89.warc:0+66442844,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-90.warc:0+56958392,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-91.warc:0+60835811,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-92.warc:0+60405658,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-93.warc:0+56228603,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-94.warc:0+59014599,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-95.warc:0+64974066,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-96.warc:0+74198264,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-97.warc:0+71675645,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-98.warc:0+73366893,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-99.warc:0+52411429,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-00.warc:0+71503338,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-01.warc:0+68722893,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-02.warc:0+56126395,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-03.warc:0+47755218,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-04.warc:0+61895968,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-05.warc:0+68862802,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-06.warc:0+65797234,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-07.warc:0+49020178,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-08.warc:0+50355632,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-09.warc:0+60720669,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-10.warc:0+69558207,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-11.warc:0+60055614,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-12.warc:0+48476732,/mnt/cw12/cw-data/ClueWeb12_14/1407wb/1407wb-13.warc:0+56085227,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-14.warc:0+75067908,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-15.warc:0+71712640,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-16.warc:0+68630780,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-17.warc:0+71060679,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-18.warc:0+61288186,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-19.warc:0+61812221,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-20.warc:0+61070912,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-21.warc:0+54033726,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-22.warc:0+53378547,/mnt/cw12/cw-data/ClueWeb12_14/1408wb/1408wb-23.warc:0+70513360
2014-07-10 23:13:40,549 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:354 as TID 355 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:40,550 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:354 as 6400 bytes in 0 ms
2014-07-10 23:13:40,553 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 194)
2014-07-10 23:13:40,553 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 194 in 8984083 ms on dco-node123-mgt.dco.ethz.ch (progress: 99/497)
2014-07-10 23:13:48,091 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:355 as TID 356 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:48,092 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:355 as 6474 bytes in 0 ms
2014-07-10 23:13:48,094 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 246 in 8991602 ms on dco-node129-mgt.dco.ethz.ch (progress: 100/497)
2014-07-10 23:13:48,094 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 246)
2014-07-10 23:13:56,693 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:356 as TID 357 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:13:56,694 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:356 as 6400 bytes in 1 ms
2014-07-10 23:13:56,696 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 230 in 9000211 ms on dco-node129-mgt.dco.ethz.ch (progress: 101/497)
2014-07-10 23:13:56,696 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 230)
2014-07-10 23:14:01,126 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:357 as TID 358 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:01,126 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:357 as 6326 bytes in 0 ms
2014-07-10 23:14:01,129 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 7 in 9004778 ms on dco-node125-mgt.dco.ethz.ch (progress: 102/497)
2014-07-10 23:14:01,129 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 7)
2014-07-10 23:14:08,488 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:358 as TID 359 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:08,488 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:358 as 6326 bytes in 0 ms
2014-07-10 23:14:08,491 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 39)
2014-07-10 23:14:08,491 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 39 in 9012110 ms on dco-node125-mgt.dco.ethz.ch (progress: 103/497)
2014-07-10 23:14:12,074 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:359 as TID 360 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:12,074 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:359 as 6326 bytes in 0 ms
2014-07-10 23:14:12,077 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 185 in 9015612 ms on dco-node126-mgt.dco.ethz.ch (progress: 104/497)
2014-07-10 23:14:12,077 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 185)
2014-07-10 23:14:14,094 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:360 as TID 361 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:14,094 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:360 as 6550 bytes in 0 ms
2014-07-10 23:14:14,097 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 78 in 9017690 ms on dco-node136-mgt.dco.ethz.ch (progress: 105/497)
2014-07-10 23:14:14,097 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 78)
2014-07-10 23:14:14,417 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:361 as TID 362 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:14,418 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:361 as 6252 bytes in 0 ms
2014-07-10 23:14:14,420 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 187 in 9017955 ms on dco-node124-mgt.dco.ethz.ch (progress: 106/497)
2014-07-10 23:14:14,420 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 187)
2014-07-10 23:14:23,776 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:362 as TID 363 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:23,776 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:362 as 6326 bytes in 0 ms
2014-07-10 23:14:23,779 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 243)
2014-07-10 23:14:23,779 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 243 in 9027288 ms on dco-node131-mgt.dco.ethz.ch (progress: 107/497)
2014-07-10 23:14:40,584 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:363 as TID 364 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:40,584 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:363 as 6252 bytes in 0 ms
2014-07-10 23:14:40,587 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 233 in 9044101 ms on dco-node126-mgt.dco.ethz.ch (progress: 108/497)
2014-07-10 23:14:40,587 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 233)
2014-07-10 23:14:50,839 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Serialized size of result for 236 is 535
2014-07-10 23:14:50,839 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Sending result for 236 directly to driver
2014-07-10 23:14:50,839 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Finished task ID 236
2014-07-10 23:14:50,842 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:364 as TID 365 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:14:50,842 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:364 as 6252 bytes in 0 ms
2014-07-10 23:14:50,844 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 365
2014-07-10 23:14:50,845 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Running task ID 365
2014-07-10 23:14:50,845 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 236)
2014-07-10 23:14:50,845 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 236 in 9054357 ms on dco-node121-mgt.dco.ethz.ch (progress: 109/497)
2014-07-10 23:14:50,846 [Executor task launch worker-14] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:14:50,847 [Executor task launch worker-14] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-79.warc:0+67539070,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-80.warc:0+49874384,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-81.warc:0+63392612,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-82.warc:0+70030887,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-83.warc:0+72141552,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-84.warc:0+72347355,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-85.warc:0+72518357,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-86.warc:0+68914654,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-87.warc:0+70498377,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-88.warc:0+73373131,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-89.warc:0+71257829,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-90.warc:0+55295254,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-91.warc:0+47137113,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-92.warc:0+70568977,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-93.warc:0+72403390,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-94.warc:0+71609608,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-95.warc:0+72362336,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-96.warc:0+72945131,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-97.warc:0+72341634,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-98.warc:0+72149747,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-99.warc:0+72164873,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-00.warc:0+62095148,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-01.warc:0+67452505,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-02.warc:0+70765149,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-03.warc:0+74849101,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-04.warc:0+71353576,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-05.warc:0+70952472,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-06.warc:0+74087038,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-07.warc:0+72687198,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-08.warc:0+72711765,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-09.warc:0+64600533,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-10.warc:0+64285260,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-11.warc:0+67035453,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-12.warc:0+66389226,/mnt/cw12/cw-data/ClueWeb12_14/1414wb/1414wb-13.warc:0+66707183,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-14.warc:0+61317342,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-15.warc:0+62272475,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-16.warc:0+63114478,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-17.warc:0+67427901,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-18.warc:0+70615908,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-19.warc:0+71628065,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-20.warc:0+72144537,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-21.warc:0+72253493,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-22.warc:0+69642010,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-23.warc:0+48637989,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-24.warc:0+62516215,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-25.warc:0+63892603,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-26.warc:0+66922875,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-27.warc:0+66993926,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-28.warc:0+66429272,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-29.warc:0+64598326,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-30.warc:0+66082909,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-31.warc:0+68401612,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-32.warc:0+71006717,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-33.warc:0+54477925,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-34.warc:0+56540054,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-35.warc:0+70895114,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-36.warc:0+71451102,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-37.warc:0+68447388,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-38.warc:0+71820461,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-39.warc:0+70137502,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-40.warc:0+70772496,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-41.warc:0+71554180,/mnt/cw12/cw-data/ClueWeb12_14/1415wb/1415wb-42.warc:0+69127667
2014-07-10 23:15:09,593 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:365 as TID 366 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:15:09,594 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:365 as 6252 bytes in 1 ms
2014-07-10 23:15:09,595 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 235 in 9073109 ms on dco-node124-mgt.dco.ethz.ch (progress: 110/497)
2014-07-10 23:15:09,595 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 235)
2014-07-10 23:15:16,795 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:366 as TID 367 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:15:16,796 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:366 as 6252 bytes in 1 ms
2014-07-10 23:15:16,798 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 23 in 9080431 ms on dco-node125-mgt.dco.ethz.ch (progress: 111/497)
2014-07-10 23:15:16,798 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 23)
2014-07-10 23:15:34,020 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:367 as TID 368 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:15:34,020 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:367 as 6178 bytes in 0 ms
2014-07-10 23:15:34,023 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 115 in 9097593 ms on dco-node131-mgt.dco.ethz.ch (progress: 112/497)
2014-07-10 23:15:34,023 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 115)
2014-07-10 23:15:56,402 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:368 as TID 369 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:15:56,403 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:368 as 6030 bytes in 0 ms
2014-07-10 23:15:56,406 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 208 in 9119930 ms on dco-node133-mgt.dco.ethz.ch (progress: 113/497)
2014-07-10 23:15:56,406 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 208)
2014-07-10 23:16:00,711 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:369 as TID 370 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:00,711 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:369 as 6252 bytes in 0 ms
2014-07-10 23:16:00,714 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 232 in 9124227 ms on dco-node132-mgt.dco.ethz.ch (progress: 114/497)
2014-07-10 23:16:00,714 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 232)
2014-07-10 23:16:07,390 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:370 as TID 371 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:07,390 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:370 as 6104 bytes in 0 ms
2014-07-10 23:16:07,393 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 62 in 9130996 ms on dco-node136-mgt.dco.ethz.ch (progress: 115/497)
2014-07-10 23:16:07,393 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 62)
2014-07-10 23:16:08,163 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:371 as TID 372 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:08,163 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:371 as 6252 bytes in 0 ms
2014-07-10 23:16:08,166 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 94 in 9131749 ms on dco-node136-mgt.dco.ethz.ch (progress: 116/497)
2014-07-10 23:16:08,166 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 94)
2014-07-10 23:16:44,153 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:372 as TID 373 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:44,153 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:372 as 6252 bytes in 0 ms
2014-07-10 23:16:44,155 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 174 in 9167696 ms on dco-node136-mgt.dco.ethz.ch (progress: 117/497)
2014-07-10 23:16:44,155 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 174)
2014-07-10 23:16:45,385 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:373 as TID 374 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:45,385 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:373 as 6252 bytes in 0 ms
2014-07-10 23:16:45,388 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 190)
2014-07-10 23:16:45,388 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 190 in 9168922 ms on dco-node136-mgt.dco.ethz.ch (progress: 118/497)
2014-07-10 23:16:46,752 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Serialized size of result for 28 is 535
2014-07-10 23:16:46,752 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Sending result for 28 directly to driver
2014-07-10 23:16:46,752 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task ID 28
2014-07-10 23:16:46,754 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:374 as TID 375 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:46,755 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:374 as 6178 bytes in 0 ms
2014-07-10 23:16:46,758 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 28 in 9170386 ms on dco-node121-mgt.dco.ethz.ch (progress: 119/497)
2014-07-10 23:16:46,756 [sparkExecutor-akka.actor.default-dispatcher-21] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 375
2014-07-10 23:16:46,758 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 28)
2014-07-10 23:16:46,758 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task ID 375
2014-07-10 23:16:46,760 [Executor task launch worker-1] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:16:46,761 [Executor task launch worker-1] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-23.warc:0+71940288,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-24.warc:0+72490037,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-25.warc:0+73578048,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-26.warc:0+72210870,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-27.warc:0+70090385,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-28.warc:0+72362891,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-29.warc:0+71764174,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-30.warc:0+70153340,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-31.warc:0+75197011,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-32.warc:0+50946934,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-33.warc:0+49423798,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-34.warc:0+66506683,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-35.warc:0+71195798,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-36.warc:0+70039593,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-37.warc:0+74791504,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-38.warc:0+71003999,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-39.warc:0+71513464,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-40.warc:0+72091727,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-41.warc:0+68726002,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-42.warc:0+65882133,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-43.warc:0+65391032,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-44.warc:0+65721380,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-45.warc:0+64533951,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-46.warc:0+66738493,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-47.warc:0+65611162,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-48.warc:0+70423630,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-49.warc:0+74008481,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-50.warc:0+66430941,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-51.warc:0+61939412,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-52.warc:0+63047988,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-53.warc:0+62423030,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-54.warc:0+63371687,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-55.warc:0+63522933,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-56.warc:0+64685125,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-57.warc:0+68955266,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-58.warc:0+54368459,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-59.warc:0+69821185,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-60.warc:0+74445201,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-61.warc:0+66592145,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-62.warc:0+49164016,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-63.warc:0+64724888,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-64.warc:0+71398390,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-65.warc:0+71512890,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-66.warc:0+68635558,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-67.warc:0+72743000,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-68.warc:0+71553644,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-69.warc:0+72852909,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-70.warc:0+72753204,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-71.warc:0+72102364,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-72.warc:0+72100475,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-73.warc:0+73397654,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-74.warc:0+74027394,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-75.warc:0+71615231,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-76.warc:0+70325429,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-77.warc:0+70493209,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-78.warc:0+72554829,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-79.warc:0+63885737,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-80.warc:0+50889385,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-81.warc:0+63739948,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-82.warc:0+70993572,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-83.warc:0+68824657,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-84.warc:0+73157303,/mnt/cw12/cw-data/ClueWeb12_15/1503wb/1503wb-85.warc:0+72331521
2014-07-10 23:16:47,579 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:375 as TID 376 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:47,580 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:375 as 6252 bytes in 1 ms
2014-07-10 23:16:47,582 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 170 in 9171125 ms on dco-node128-mgt.dco.ethz.ch (progress: 120/497)
2014-07-10 23:16:47,582 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 170)
2014-07-10 23:16:48,679 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:376 as TID 377 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:48,680 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:376 as 6252 bytes in 1 ms
2014-07-10 23:16:48,682 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 166 in 9172227 ms on dco-node129-mgt.dco.ethz.ch (progress: 121/497)
2014-07-10 23:16:48,682 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 166)
2014-07-10 23:16:54,420 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:377 as TID 378 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:16:54,421 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:377 as 6178 bytes in 0 ms
2014-07-10 23:16:54,423 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 211 in 9177947 ms on dco-node131-mgt.dco.ethz.ch (progress: 122/497)
2014-07-10 23:16:54,423 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 211)
2014-07-10 23:17:20,732 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:378 as TID 379 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:17:20,733 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:378 as 6326 bytes in 0 ms
2014-07-10 23:17:20,735 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 55 in 9204344 ms on dco-node125-mgt.dco.ethz.ch (progress: 123/497)
2014-07-10 23:17:20,735 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 55)
2014-07-10 23:17:38,664 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:379 as TID 380 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:17:38,664 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:379 as 6252 bytes in 0 ms
2014-07-10 23:17:38,667 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 195 in 9222197 ms on dco-node131-mgt.dco.ethz.ch (progress: 124/497)
2014-07-10 23:17:38,667 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 195)
2014-07-10 23:17:42,946 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:380 as TID 381 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:17:42,947 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:380 as 6178 bytes in 1 ms
2014-07-10 23:17:42,950 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 217 in 9226470 ms on dco-node126-mgt.dco.ethz.ch (progress: 125/497)
2014-07-10 23:17:42,950 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 217)
2014-07-10 23:18:19,105 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:381 as TID 382 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:18:19,105 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:381 as 6252 bytes in 0 ms
2014-07-10 23:18:19,108 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 154 in 9262658 ms on dco-node128-mgt.dco.ethz.ch (progress: 126/497)
2014-07-10 23:18:19,109 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 154)
2014-07-10 23:18:38,751 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Serialized size of result for 44 is 535
2014-07-10 23:18:38,751 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Sending result for 44 directly to driver
2014-07-10 23:18:38,751 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Finished task ID 44
2014-07-10 23:18:38,753 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:382 as TID 383 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:18:38,755 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:382 as 6178 bytes in 1 ms
2014-07-10 23:18:38,757 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 44 in 9282374 ms on dco-node121-mgt.dco.ethz.ch (progress: 127/497)
2014-07-10 23:18:38,757 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 44)
2014-07-10 23:18:38,756 [sparkExecutor-akka.actor.default-dispatcher-22] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 383
2014-07-10 23:18:38,758 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Running task ID 383
2014-07-10 23:18:38,760 [Executor task launch worker-2] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:18:38,761 [Executor task launch worker-2] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-33.warc:0+71746122,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-34.warc:0+72881854,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-35.warc:0+65086801,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-36.warc:0+49619714,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-37.warc:0+69901945,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-38.warc:0+70429378,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-39.warc:0+68910535,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-40.warc:0+71798540,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-41.warc:0+73305268,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-42.warc:0+73712231,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-43.warc:0+72762880,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-44.warc:0+73710594,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-45.warc:0+72376104,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-46.warc:0+73031100,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-47.warc:0+71663888,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-48.warc:0+69823955,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-49.warc:0+71518400,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-50.warc:0+68528296,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-51.warc:0+68308312,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-52.warc:0+58290921,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-53.warc:0+69636140,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-54.warc:0+72548710,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-55.warc:0+68117683,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-56.warc:0+72934239,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-57.warc:0+72908387,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-58.warc:0+73717378,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-59.warc:0+50615427,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-60.warc:0+63212287,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-61.warc:0+70102029,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-62.warc:0+80436215,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-63.warc:0+64359503,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-64.warc:0+62542935,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-65.warc:0+64306646,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-66.warc:0+63915593,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-67.warc:0+63410942,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-68.warc:0+63946255,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-69.warc:0+66505387,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-70.warc:0+69025784,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-71.warc:0+63799724,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-72.warc:0+64435107,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-73.warc:0+63879093,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-74.warc:0+63903169,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-75.warc:0+65152917,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-76.warc:0+63405441,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-77.warc:0+70949285,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-78.warc:0+70886982,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-79.warc:0+66988351,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-80.warc:0+75577560,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-81.warc:0+45685724,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-82.warc:0+65595594,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-83.warc:0+72109202,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-84.warc:0+73324169,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-85.warc:0+72574604,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-86.warc:0+71615012,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-87.warc:0+71657063,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-88.warc:0+73195579,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-89.warc:0+72786199,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-90.warc:0+71710347,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-91.warc:0+70929092,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-92.warc:0+70548747,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-93.warc:0+71777430,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-94.warc:0+70880132,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-95.warc:0+73992760
2014-07-10 23:18:51,636 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Serialized size of result for 12 is 535
2014-07-10 23:18:51,636 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Sending result for 12 directly to driver
2014-07-10 23:18:51,636 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task ID 12
2014-07-10 23:18:51,639 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:383 as TID 384 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:18:51,640 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:383 as 6252 bytes in 0 ms
2014-07-10 23:18:51,643 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 12 in 9295287 ms on dco-node121-mgt.dco.ethz.ch (progress: 128/497)
2014-07-10 23:18:51,642 [sparkExecutor-akka.actor.default-dispatcher-25] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 384
2014-07-10 23:18:51,643 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 12)
2014-07-10 23:18:51,644 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task ID 384
2014-07-10 23:18:51,645 [Executor task launch worker-0] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:18:51,647 [Executor task launch worker-0] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-96.warc:0+72445303,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-97.warc:0+72408402,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-98.warc:0+34522710,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-99.warc:0+57027602,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-00.warc:0+72581421,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-01.warc:0+71741351,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-02.warc:0+73509138,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-03.warc:0+73409585,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-04.warc:0+74118793,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-05.warc:0+75498205,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-06.warc:0+76768654,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-07.warc:0+45227806,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-08.warc:0+60930002,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-09.warc:0+69785790,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-10.warc:0+74279091,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-11.warc:0+76352136,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-12.warc:0+72989575,/mnt/cw12/cw-data/ClueWeb12_15/1508wb/1508wb-13.warc:0+70850260,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-46.warc:0+69349292,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-47.warc:0+69983572,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-48.warc:0+71529147,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-49.warc:0+83564974,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-50.warc:0+69031562,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-51.warc:0+70721841,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-52.warc:0+68672386,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-53.warc:0+65604658,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-54.warc:0+64894102,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-55.warc:0+63665243,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-56.warc:0+62628525,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-57.warc:0+64169745,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-58.warc:0+67712062,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-59.warc:0+68245116,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-60.warc:0+65244231,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-61.warc:0+65597926,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-62.warc:0+64720936,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-63.warc:0+62082864,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-64.warc:0+64325013,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-65.warc:0+64377858,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-66.warc:0+70197334,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-67.warc:0+50281320,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-68.warc:0+63950849,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-69.warc:0+72213245,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-70.warc:0+72752986,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-71.warc:0+72302884,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-72.warc:0+72807541,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-73.warc:0+71295375,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-74.warc:0+71497943,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-75.warc:0+72875287,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-76.warc:0+70763192,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-77.warc:0+71863481,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-78.warc:0+68040617,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-79.warc:0+62664827,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-80.warc:0+56572196,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-81.warc:0+72347648,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-82.warc:0+71995569,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-83.warc:0+71865681,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-84.warc:0+72074599,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-85.warc:0+69150848,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-86.warc:0+69462965,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-87.warc:0+69718574,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-88.warc:0+44180488,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-89.warc:0+57439449,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-90.warc:0+68545797,/mnt/cw12/cw-data/ClueWeb12_15/1509wb/1509wb-91.warc:0+69708506
2014-07-10 23:19:00,815 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:384 as TID 385 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:19:00,816 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:384 as 6252 bytes in 0 ms
2014-07-10 23:19:00,818 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 71 in 9304416 ms on dco-node125-mgt.dco.ethz.ch (progress: 129/497)
2014-07-10 23:19:00,818 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 71)
2014-07-10 23:19:13,113 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:385 as TID 386 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:19:13,113 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:385 as 6178 bytes in 0 ms
2014-07-10 23:19:13,115 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 212 in 9316638 ms on dco-node130-mgt.dco.ethz.ch (progress: 130/497)
2014-07-10 23:19:13,115 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 212)
2014-07-10 23:19:17,353 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Serialized size of result for 60 is 535
2014-07-10 23:19:17,353 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Sending result for 60 directly to driver
2014-07-10 23:19:17,354 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Finished task ID 60
2014-07-10 23:19:17,356 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:386 as TID 387 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:19:17,356 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:386 as 6252 bytes in 0 ms
2014-07-10 23:19:17,357 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 387
2014-07-10 23:19:17,359 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 60)
2014-07-10 23:19:17,359 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Running task ID 387
2014-07-10 23:19:17,359 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 60 in 9320964 ms on dco-node121-mgt.dco.ethz.ch (progress: 131/497)
2014-07-10 23:19:17,360 [Executor task launch worker-3] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:19:17,362 [Executor task launch worker-3] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-87.warc:0+69396505,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-88.warc:0+70484634,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-89.warc:0+70213073,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-90.warc:0+74478391,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-91.warc:0+67030450,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-92.warc:0+63963288,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-93.warc:0+62653372,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-94.warc:0+63188929,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-95.warc:0+64635061,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-96.warc:0+64171683,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-97.warc:0+69966439,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-98.warc:0+66431253,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-99.warc:0+64837963,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-00.warc:0+71742459,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-01.warc:0+70583748,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-02.warc:0+68590749,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-03.warc:0+65235635,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-04.warc:0+63972158,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-05.warc:0+65403131,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-06.warc:0+63222464,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-07.warc:0+64756026,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-08.warc:0+64767106,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-09.warc:0+68762762,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-10.warc:0+66469098,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-11.warc:0+64974496,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-12.warc:0+63993237,/mnt/cw12/cw-data/ClueWeb12_15/1510wb/1510wb-13.warc:0+64369313,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-14.warc:0+73247408,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-15.warc:0+73194959,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-16.warc:0+73255356,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-17.warc:0+73370350,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-18.warc:0+72679926,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-19.warc:0+70536972,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-20.warc:0+72165365,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-21.warc:0+69310535,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-22.warc:0+71110002,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-23.warc:0+71965190,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-24.warc:0+71919285,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-25.warc:0+71737542,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-26.warc:0+60679645,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-27.warc:0+46243769,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-28.warc:0+72593098,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-29.warc:0+73719786,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-30.warc:0+75815128,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-31.warc:0+71296341,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-32.warc:0+70976158,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-33.warc:0+69828984,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-34.warc:0+63077207,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-35.warc:0+63830208,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-36.warc:0+62896185,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-37.warc:0+63064451,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-38.warc:0+64743184,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-39.warc:0+64509837,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-40.warc:0+68937689,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-41.warc:0+69784968,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-42.warc:0+64426966,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-43.warc:0+63225323,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-44.warc:0+63543649,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-45.warc:0+64352342,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-46.warc:0+65038578,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-47.warc:0+67622098,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-48.warc:0+70404374,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-49.warc:0+71081884,/mnt/cw12/cw-data/ClueWeb12_15/1511wb/1511wb-50.warc:0+52509735
2014-07-10 23:19:31,172 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:387 as TID 388 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:19:31,172 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:387 as 6178 bytes in 0 ms
2014-07-10 23:19:31,175 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 210 in 9334698 ms on dco-node123-mgt.dco.ethz.ch (progress: 132/497)
2014-07-10 23:19:31,175 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 210)
2014-07-10 23:19:46,961 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:388 as TID 389 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:19:46,961 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:388 as 6178 bytes in 0 ms
2014-07-10 23:19:46,964 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 178 in 9350502 ms on dco-node123-mgt.dco.ethz.ch (progress: 133/497)
2014-07-10 23:19:46,964 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 178)
2014-07-10 23:20:18,726 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:389 as TID 390 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:20:18,727 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:389 as 6252 bytes in 0 ms
2014-07-10 23:20:18,729 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 103 in 9382307 ms on dco-node125-mgt.dco.ethz.ch (progress: 134/497)
2014-07-10 23:20:18,729 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 103)
2014-07-10 23:20:22,568 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:390 as TID 391 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:20:22,569 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:390 as 6178 bytes in 0 ms
2014-07-10 23:20:22,571 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 153 in 9386122 ms on dco-node126-mgt.dco.ethz.ch (progress: 135/497)
2014-07-10 23:20:22,571 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 153)
2014-07-10 23:21:01,470 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:391 as TID 392 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:21:01,470 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:391 as 6178 bytes in 0 ms
2014-07-10 23:21:01,473 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 87 in 9425060 ms on dco-node125-mgt.dco.ethz.ch (progress: 136/497)
2014-07-10 23:21:01,473 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 87)
2014-07-10 23:21:22,586 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:392 as TID 393 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:21:22,587 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:392 as 6178 bytes in 1 ms
2014-07-10 23:21:22,589 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 171)
2014-07-10 23:21:22,589 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 171 in 9446131 ms on dco-node124-mgt.dco.ethz.ch (progress: 137/497)
2014-07-10 23:21:48,820 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:393 as TID 394 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:21:48,821 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:393 as 7293 bytes in 1 ms
2014-07-10 23:21:48,822 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 201 in 9472351 ms on dco-node126-mgt.dco.ethz.ch (progress: 138/497)
2014-07-10 23:21:48,822 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 201)
2014-07-10 23:21:55,419 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Serialized size of result for 156 is 535
2014-07-10 23:21:55,419 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Sending result for 156 directly to driver
2014-07-10 23:21:55,419 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Finished task ID 156
2014-07-10 23:21:55,421 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:394 as TID 395 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:21:55,421 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:394 as 7665 bytes in 0 ms
2014-07-10 23:21:55,423 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 156 in 9478972 ms on dco-node121-mgt.dco.ethz.ch (progress: 139/497)
2014-07-10 23:21:55,423 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 156)
2014-07-10 23:21:55,423 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 395
2014-07-10 23:21:55,424 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Running task ID 395
2014-07-10 23:21:55,426 [Executor task launch worker-9] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:21:55,427 [Executor task launch worker-9] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_15/1515wb/1515wb-08.warc:0+71413558,/mnt/cw12/cw-data/ClueWeb12_15/1515wb/1515wb-09.warc:0+53135111,/mnt/cw12/cw-data/ClueWeb12_15/1515wb/1515wb-10.warc:0+68061688,/mnt/cw12/cw-data/ClueWeb12_15/1515wb/1515wb-11.warc:0+71908139,/mnt/cw12/cw-data/ClueWeb12_15/1515wb/1515wb-12.warc:0+72999842,/mnt/cw12/cw-data/ClueWeb12_15/1515wb/1515wb-13.warc:0+80803634,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-10.warc:0+65572415,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-11.warc:0+65623480,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-12.warc:0+64597303,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-13.warc:0+69227158,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-14.warc:0+69235979,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-15.warc:0+67450443,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-16.warc:0+64673652,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-17.warc:0+64778001,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-18.warc:0+64364148,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-19.warc:0+64802833,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-20.warc:0+70355684,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-21.warc:0+55503707,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-22.warc:0+47595143,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-23.warc:0+72815532,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-24.warc:0+45891492,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-25.warc:0+34095471,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-26.warc:0+36687377,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-27.warc:0+34652947,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-28.warc:0+34510984,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-29.warc:0+37524241,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-30.warc:0+35774215,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-31.warc:0+34877608,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-32.warc:0+31212809,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-33.warc:0+37393655,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-34.warc:0+53348057,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-35.warc:0+73296389,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-36.warc:0+73056706,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-37.warc:0+72940986,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-38.warc:0+44352565,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-39.warc:0+36880672,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-40.warc:0+36046370,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-41.warc:0+37120174,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-42.warc:0+38089815,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-43.warc:0+59337811,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-44.warc:0+72194647,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-45.warc:0+72143464,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-46.warc:0+71528372,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-47.warc:0+70276203,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-48.warc:0+69894889,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-49.warc:0+68480584,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-50.warc:0+38742918,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-51.warc:0+37167341,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-52.warc:0+36175144,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-53.warc:0+53431647,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-54.warc:0+70256522,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-55.warc:0+38681994,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-56.warc:0+36213571,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-57.warc:0+35756868,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-58.warc:0+58423943,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-59.warc:0+71528781,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-60.warc:0+57430247,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-61.warc:0+34903890,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-62.warc:0+36948970,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-63.warc:0+38712015,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-64.warc:0+36218445,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-65.warc:0+45096790,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-66.warc:0+73670845,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-67.warc:0+46188374,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-68.warc:0+37136648,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-69.warc:0+37968658,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-70.warc:0+36816846,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-71.warc:0+35971713,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-72.warc:0+37706057,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-73.warc:0+36417307,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-74.warc:0+39018038,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-75.warc:0+47185383,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-76.warc:0+73350009,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-77.warc:0+60423549,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-78.warc:0+35928657,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-79.warc:0+62743424,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-80.warc:0+66566274,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-81.warc:0+36198421,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-82.warc:0+39792066,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-83.warc:0+38145786,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-84.warc:0+37002851,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-85.warc:0+27189607,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-00.warc:0+38483260
2014-07-10 23:21:57,785 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Serialized size of result for 92 is 535
2014-07-10 23:21:57,785 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Sending result for 92 directly to driver
2014-07-10 23:21:57,785 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Finished task ID 92
2014-07-10 23:21:57,787 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:395 as TID 396 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:21:57,788 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:395 as 6326 bytes in 0 ms
2014-07-10 23:21:57,790 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 92 in 9481375 ms on dco-node121-mgt.dco.ethz.ch (progress: 140/497)
2014-07-10 23:21:57,791 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 92)
2014-07-10 23:21:57,790 [sparkExecutor-akka.actor.default-dispatcher-24] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 396
2014-07-10 23:21:57,791 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Running task ID 396
2014-07-10 23:21:57,792 [Executor task launch worker-5] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:21:57,793 [Executor task launch worker-5] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-01.warc:0+68473720,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-02.warc:0+73338939,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-03.warc:0+37300417,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-04.warc:0+35030241,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-05.warc:0+36248637,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-06.warc:0+36582778,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-07.warc:0+43497670,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-08.warc:0+65768384,/mnt/cw12/cw-data/ClueWeb12_15/1516wb/1516wb-09.warc:0+64235092,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-33.warc:0+66619628,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-34.warc:0+68296635,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-35.warc:0+69369994,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-36.warc:0+69344464,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-37.warc:0+71521381,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-38.warc:0+69572639,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-39.warc:0+70463091,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-40.warc:0+72643929,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-41.warc:0+72697002,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-42.warc:0+70216587,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-43.warc:0+70652625,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-44.warc:0+70772775,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-45.warc:0+71478032,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-46.warc:0+71297108,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-47.warc:0+17874268,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-00.warc:0+71765991,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-01.warc:0+74325230,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-02.warc:0+71481758,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-03.warc:0+70300264,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-04.warc:0+71900572,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-05.warc:0+70076696,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-06.warc:0+69665155,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-07.warc:0+72821065,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-08.warc:0+71360606,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-09.warc:0+69305369,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-10.warc:0+70965602,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-11.warc:0+68998798,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-12.warc:0+71996438,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-13.warc:0+70149815,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-14.warc:0+68159520,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-15.warc:0+68952033,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-16.warc:0+71449137,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-17.warc:0+70274554,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-18.warc:0+72490474,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-19.warc:0+68806265,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-20.warc:0+71971635,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-21.warc:0+69551306,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-22.warc:0+71163055,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-23.warc:0+70197722,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-24.warc:0+72057552,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-25.warc:0+71602169,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-26.warc:0+72302647,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-27.warc:0+73937303,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-28.warc:0+70610457,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-29.warc:0+67990114,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-30.warc:0+71931821,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-31.warc:0+69071530,/mnt/cw12/cw-data/ClueWeb12_16/1600tw/1600tw-32.warc:0+65572726,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-14.warc:0+63887220,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-15.warc:0+70933373,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-16.warc:0+70378051,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-17.warc:0+65238211,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-18.warc:0+65180814,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-19.warc:0+64885417,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-20.warc:0+64907335,/mnt/cw12/cw-data/ClueWeb12_16/1600wb/1600wb-21.warc:0+68197141
2014-07-10 23:21:59,134 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:396 as TID 397 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:21:59,134 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:396 as 7816 bytes in 0 ms
2014-07-10 23:21:59,137 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 17 in 9482775 ms on dco-node135-mgt.dco.ethz.ch (progress: 141/497)
2014-07-10 23:21:59,137 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 17)
2014-07-10 23:22:10,453 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:397 as TID 398 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:22:10,454 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:397 as 7367 bytes in 0 ms
2014-07-10 23:22:10,456 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 13 in 9494099 ms on dco-node122-mgt.dco.ethz.ch (progress: 142/497)
2014-07-10 23:22:10,456 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 13)
2014-07-10 23:22:16,613 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:398 as TID 399 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:22:16,613 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:398 as 7293 bytes in 0 ms
2014-07-10 23:22:16,616 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 250)
2014-07-10 23:22:16,616 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 250 in 9500121 ms on dco-node128-mgt.dco.ethz.ch (progress: 143/497)
2014-07-10 23:22:30,791 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:399 as TID 400 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:22:30,791 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:399 as 7441 bytes in 0 ms
2014-07-10 23:22:30,794 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 1 in 9514451 ms on dco-node135-mgt.dco.ethz.ch (progress: 144/497)
2014-07-10 23:22:30,794 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 1)
2014-07-10 23:23:01,830 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:400 as TID 401 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:23:01,830 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:400 as 6849 bytes in 0 ms
2014-07-10 23:23:01,833 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 155)
2014-07-10 23:23:01,833 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 155 in 9545382 ms on dco-node124-mgt.dco.ethz.ch (progress: 145/497)
2014-07-10 23:23:43,053 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:401 as TID 402 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:23:43,054 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:401 as 6775 bytes in 0 ms
2014-07-10 23:23:43,055 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 169 in 9586599 ms on dco-node126-mgt.dco.ethz.ch (progress: 146/497)
2014-07-10 23:23:43,055 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 169)
2014-07-10 23:23:47,790 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:402 as TID 403 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:23:47,790 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:402 as 6698 bytes in 0 ms
2014-07-10 23:23:47,793 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 183)
2014-07-10 23:23:47,793 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 183 in 9591330 ms on dco-node125-mgt.dco.ethz.ch (progress: 147/497)
2014-07-10 23:24:11,550 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:403 as TID 404 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:11,550 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:403 as 6550 bytes in 0 ms
2014-07-10 23:24:11,552 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 65 in 9615154 ms on dco-node135-mgt.dco.ethz.ch (progress: 148/497)
2014-07-10 23:24:11,552 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 65)
2014-07-10 23:24:17,085 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:404 as TID 405 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:17,086 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:404 as 6624 bytes in 1 ms
2014-07-10 23:24:17,088 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 47)
2014-07-10 23:24:17,088 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 47 in 9620703 ms on dco-node127-mgt.dco.ethz.ch (progress: 149/497)
2014-07-10 23:24:18,090 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:405 as TID 406 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:18,090 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:405 as 6698 bytes in 0 ms
2014-07-10 23:24:18,093 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 97 in 9621675 ms on dco-node135-mgt.dco.ethz.ch (progress: 150/497)
2014-07-10 23:24:18,093 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 97)
2014-07-10 23:24:19,898 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:406 as TID 407 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:19,898 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:406 as 6550 bytes in 0 ms
2014-07-10 23:24:19,900 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 106 in 9623476 ms on dco-node128-mgt.dco.ethz.ch (progress: 151/497)
2014-07-10 23:24:19,900 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 106)
2014-07-10 23:24:21,543 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:407 as TID 408 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:21,543 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:407 as 6474 bytes in 0 ms
2014-07-10 23:24:21,546 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 93 in 9625129 ms on dco-node122-mgt.dco.ethz.ch (progress: 152/497)
2014-07-10 23:24:21,546 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 93)
2014-07-10 23:24:25,462 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:408 as TID 409 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:25,463 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:408 as 6474 bytes in 0 ms
2014-07-10 23:24:25,465 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 202 in 9628993 ms on dco-node128-mgt.dco.ethz.ch (progress: 153/497)
2014-07-10 23:24:25,465 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 202)
2014-07-10 23:24:27,589 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:409 as TID 410 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:27,590 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:409 as 6400 bytes in 1 ms
2014-07-10 23:24:27,592 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 203 in 9631119 ms on dco-node124-mgt.dco.ethz.ch (progress: 154/497)
2014-07-10 23:24:27,592 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 203)
2014-07-10 23:24:32,741 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:410 as TID 411 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:32,741 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:410 as 6474 bytes in 0 ms
2014-07-10 23:24:32,743 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 45 in 9636359 ms on dco-node122-mgt.dco.ethz.ch (progress: 155/497)
2014-07-10 23:24:32,743 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 45)
2014-07-10 23:24:47,490 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:411 as TID 412 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:47,497 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:411 as 6400 bytes in 1 ms
2014-07-10 23:24:47,499 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 152 in 9651050 ms on dco-node132-mgt.dco.ethz.ch (progress: 156/497)
2014-07-10 23:24:47,499 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 152)
2014-07-10 23:24:50,763 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:412 as TID 413 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:24:50,763 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:412 as 6474 bytes in 0 ms
2014-07-10 23:24:50,765 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 229 in 9654281 ms on dco-node134-mgt.dco.ethz.ch (progress: 157/497)
2014-07-10 23:24:50,765 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 229)
2014-07-10 23:25:04,954 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:413 as TID 414 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:25:04,955 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:413 as 6550 bytes in 0 ms
2014-07-10 23:25:04,956 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 248 in 9668464 ms on dco-node132-mgt.dco.ethz.ch (progress: 158/497)
2014-07-10 23:25:04,956 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 248)
2014-07-10 23:25:13,523 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:414 as TID 415 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:25:13,531 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:414 as 6624 bytes in 1 ms
2014-07-10 23:25:13,533 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 179)
2014-07-10 23:25:13,533 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 179 in 9677072 ms on dco-node131-mgt.dco.ethz.ch (progress: 159/497)
2014-07-10 23:25:19,141 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:415 as TID 416 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:25:19,141 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:415 as 6550 bytes in 0 ms
2014-07-10 23:25:19,143 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 238 in 9682655 ms on dco-node136-mgt.dco.ethz.ch (progress: 160/497)
2014-07-10 23:25:19,143 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 238)
2014-07-10 23:25:29,982 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:416 as TID 417 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:25:29,983 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:416 as 6624 bytes in 1 ms
2014-07-10 23:25:29,985 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 226 in 9693502 ms on dco-node123-mgt.dco.ethz.ch (progress: 161/497)
2014-07-10 23:25:29,985 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 226)
2014-07-10 23:25:43,247 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:417 as TID 418 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:25:43,247 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:417 as 6775 bytes in 0 ms
2014-07-10 23:25:43,250 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 181)
2014-07-10 23:25:43,250 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 181 in 9706787 ms on dco-node134-mgt.dco.ethz.ch (progress: 162/497)
2014-07-10 23:26:10,140 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:418 as TID 419 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:26:10,141 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:418 as 6698 bytes in 0 ms
2014-07-10 23:26:10,144 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 254 in 9733647 ms on dco-node136-mgt.dco.ethz.ch (progress: 163/497)
2014-07-10 23:26:10,144 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 254)
2014-07-10 23:26:26,256 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:419 as TID 420 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:26:26,257 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:419 as 6624 bytes in 1 ms
2014-07-10 23:26:26,259 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 158 in 9749807 ms on dco-node136-mgt.dco.ethz.ch (progress: 164/497)
2014-07-10 23:26:26,259 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 158)
2014-07-10 23:26:58,516 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:420 as TID 421 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:26:58,517 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:420 as 6400 bytes in 0 ms
2014-07-10 23:26:58,519 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 249 in 9782026 ms on dco-node126-mgt.dco.ethz.ch (progress: 165/497)
2014-07-10 23:26:58,519 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 249)
2014-07-10 23:27:20,792 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:421 as TID 422 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:27:20,793 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:421 as 6104 bytes in 0 ms
2014-07-10 23:27:20,795 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 29 in 9804423 ms on dco-node122-mgt.dco.ethz.ch (progress: 166/497)
2014-07-10 23:27:20,795 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 29)
2014-07-10 23:27:22,642 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:422 as TID 423 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:27:22,643 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:422 as 6624 bytes in 1 ms
2014-07-10 23:27:22,645 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 222 in 9806164 ms on dco-node136-mgt.dco.ethz.ch (progress: 167/497)
2014-07-10 23:27:22,645 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 222)
2014-07-10 23:27:45,418 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:423 as TID 424 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:27:45,419 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:423 as 6624 bytes in 0 ms
2014-07-10 23:27:45,421 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 61 in 9829026 ms on dco-node122-mgt.dco.ethz.ch (progress: 168/497)
2014-07-10 23:27:45,421 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 61)
2014-07-10 23:27:50,352 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:424 as TID 425 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:27:50,352 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:424 as 6698 bytes in 0 ms
2014-07-10 23:27:50,354 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 49 in 9833967 ms on dco-node135-mgt.dco.ethz.ch (progress: 169/497)
2014-07-10 23:27:50,354 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 49)
2014-07-10 23:28:00,592 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:425 as TID 426 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:28:00,593 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:425 as 6474 bytes in 1 ms
2014-07-10 23:28:00,595 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 144 in 9844150 ms on dco-node133-mgt.dco.ethz.ch (progress: 170/497)
2014-07-10 23:28:00,595 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 144)
2014-07-10 23:28:02,801 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:426 as TID 427 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:28:02,801 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:426 as 6624 bytes in 0 ms
2014-07-10 23:28:02,803 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 141 in 9846360 ms on dco-node122-mgt.dco.ethz.ch (progress: 171/497)
2014-07-10 23:28:02,803 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 141)
2014-07-10 23:28:04,577 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:427 as TID 428 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:28:04,577 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:427 as 6698 bytes in 0 ms
2014-07-10 23:28:04,579 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 251 in 9848085 ms on dco-node124-mgt.dco.ethz.ch (progress: 172/497)
2014-07-10 23:28:04,579 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 251)
2014-07-10 23:28:24,282 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:428 as TID 429 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:28:24,282 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:428 as 6400 bytes in 0 ms
2014-07-10 23:28:24,284 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 227 in 9867802 ms on dco-node131-mgt.dco.ethz.ch (progress: 173/497)
2014-07-10 23:28:24,284 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 227)
2014-07-10 23:28:36,693 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:429 as TID 430 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:28:36,694 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:429 as 6624 bytes in 0 ms
2014-07-10 23:28:36,695 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 247 in 9880204 ms on dco-node125-mgt.dco.ethz.ch (progress: 174/497)
2014-07-10 23:28:36,695 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 247)
2014-07-10 23:28:49,648 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:430 as TID 431 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:28:49,648 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:430 as 6698 bytes in 0 ms
2014-07-10 23:28:49,650 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 31 in 9893277 ms on dco-node127-mgt.dco.ethz.ch (progress: 175/497)
2014-07-10 23:28:49,650 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 31)
2014-07-10 23:28:56,904 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:431 as TID 432 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:28:56,905 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:431 as 6550 bytes in 1 ms
2014-07-10 23:28:56,907 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 33 in 9900532 ms on dco-node135-mgt.dco.ethz.ch (progress: 176/497)
2014-07-10 23:28:56,907 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 33)
2014-07-10 23:29:29,527 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:432 as TID 433 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:29:29,528 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:432 as 6698 bytes in 1 ms
2014-07-10 23:29:29,530 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 215 in 9933052 ms on dco-node125-mgt.dco.ethz.ch (progress: 177/497)
2014-07-10 23:29:29,530 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 215)
2014-07-10 23:29:31,160 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:433 as TID 434 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:29:31,163 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:433 as 6624 bytes in 0 ms
2014-07-10 23:29:31,165 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 81 in 9934756 ms on dco-node135-mgt.dco.ethz.ch (progress: 178/497)
2014-07-10 23:29:31,165 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 81)
2014-07-10 23:29:57,170 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:434 as TID 435 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:29:57,170 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:434 as 7515 bytes in 0 ms
2014-07-10 23:29:57,173 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 205)
2014-07-10 23:29:57,173 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 205 in 9960699 ms on dco-node122-mgt.dco.ethz.ch (progress: 179/497)
2014-07-10 23:30:18,460 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:435 as TID 436 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:30:18,460 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:435 as 7367 bytes in 0 ms
2014-07-10 23:30:18,462 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 146 in 9982016 ms on dco-node123-mgt.dco.ethz.ch (progress: 180/497)
2014-07-10 23:30:18,462 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 146)
2014-07-10 23:30:40,383 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:436 as TID 437 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:30:40,384 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:436 as 7441 bytes in 0 ms
2014-07-10 23:30:40,386 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 224 in 10003904 ms on dco-node133-mgt.dco.ethz.ch (progress: 181/497)
2014-07-10 23:30:40,386 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 224)
2014-07-10 23:30:45,601 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:437 as TID 438 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:30:45,602 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:437 as 7145 bytes in 0 ms
2014-07-10 23:30:45,604 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 228 in 10009120 ms on dco-node130-mgt.dco.ethz.ch (progress: 182/497)
2014-07-10 23:30:45,604 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 228)
2014-07-10 23:30:49,399 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:438 as TID 439 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:30:49,399 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:438 as 6849 bytes in 0 ms
2014-07-10 23:30:49,402 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 79 in 10012994 ms on dco-node127-mgt.dco.ethz.ch (progress: 183/497)
2014-07-10 23:30:49,402 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 79)
2014-07-10 23:30:51,219 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:439 as TID 440 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:30:51,220 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:439 as 7071 bytes in 1 ms
2014-07-10 23:30:51,222 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 77 in 10014816 ms on dco-node122-mgt.dco.ethz.ch (progress: 184/497)
2014-07-10 23:30:51,222 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 77)
2014-07-10 23:30:54,284 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:440 as TID 441 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:30:54,285 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:440 as 7145 bytes in 0 ms
2014-07-10 23:30:54,287 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 112 in 10017860 ms on dco-node133-mgt.dco.ethz.ch (progress: 185/497)
2014-07-10 23:30:54,287 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 112)
2014-07-10 23:31:53,228 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:441 as TID 442 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:31:53,229 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:441 as 6698 bytes in 1 ms
2014-07-10 23:31:53,231 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 148 in 10076784 ms on dco-node130-mgt.dco.ethz.ch (progress: 186/497)
2014-07-10 23:31:53,231 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 148)
2014-07-10 23:31:55,054 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:442 as TID 443 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:31:55,055 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:442 as 6326 bytes in 1 ms
2014-07-10 23:31:55,057 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 209 in 10078581 ms on dco-node135-mgt.dco.ethz.ch (progress: 187/497)
2014-07-10 23:31:55,057 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 209)
2014-07-10 23:31:55,692 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:443 as TID 444 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:31:55,693 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:443 as 6326 bytes in 0 ms
2014-07-10 23:31:55,720 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 189 in 10079254 ms on dco-node122-mgt.dco.ethz.ch (progress: 188/497)
2014-07-10 23:31:55,720 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 189)
2014-07-10 23:31:57,750 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 140 is 535
2014-07-10 23:31:57,751 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 140 directly to driver
2014-07-10 23:31:57,751 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 140
2014-07-10 23:31:57,753 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:444 as TID 445 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:31:57,753 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:444 as 6326 bytes in 0 ms
2014-07-10 23:31:57,756 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 140 in 10081313 ms on dco-node121-mgt.dco.ethz.ch (progress: 189/497)
2014-07-10 23:31:57,756 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 140)
2014-07-10 23:31:57,755 [sparkExecutor-akka.actor.default-dispatcher-25] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 445
2014-07-10 23:31:57,756 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 445
2014-07-10 23:31:57,758 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:31:57,759 [Executor task launch worker-8] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-99.warc:0+68804139,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-00.warc:0+63576590,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-01.warc:0+69771233,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-02.warc:0+70235997,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-03.warc:0+71339964,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-04.warc:0+50648603,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-05.warc:0+53489372,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-06.warc:0+55048655,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-07.warc:0+53308814,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-08.warc:0+63102696,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-09.warc:0+72480637,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-10.warc:0+68945200,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-11.warc:0+68038613,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-12.warc:0+69253327,/mnt/cw12/cw-data/ClueWeb12_17/1715wb/1715wb-13.warc:0+66932050,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-14.warc:0+62093853,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-15.warc:0+60032102,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-16.warc:0+68023774,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-17.warc:0+68209409,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-18.warc:0+62264499,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-19.warc:0+56243904,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-20.warc:0+70922083,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-21.warc:0+72455598,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-22.warc:0+73774604,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-23.warc:0+71512546,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-24.warc:0+72554980,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-25.warc:0+73537767,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-26.warc:0+72674883,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-27.warc:0+71594138,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-28.warc:0+71870698,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-29.warc:0+69509033,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-30.warc:0+67030386,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-31.warc:0+71520176,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-32.warc:0+65599102,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-33.warc:0+67326867,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-34.warc:0+69590909,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-35.warc:0+70551395,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-36.warc:0+57546100,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-37.warc:0+71399261,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-38.warc:0+64637275,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-39.warc:0+61825169,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-40.warc:0+71218638,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-41.warc:0+70135297,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-42.warc:0+67314127,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-43.warc:0+68420886,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-44.warc:0+62095298,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-45.warc:0+72276379,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-46.warc:0+58343768,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-47.warc:0+60987042,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-48.warc:0+73028756,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-49.warc:0+60544886,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-50.warc:0+57427128,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-51.warc:0+71494332,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-52.warc:0+45075068,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-53.warc:0+65985454,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-54.warc:0+67596256,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-55.warc:0+68961906,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-56.warc:0+70279635,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-57.warc:0+66452867,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-58.warc:0+68817554,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-59.warc:0+64951464,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-60.warc:0+64843732,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-61.warc:0+58281033,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-62.warc:0+63316930,/mnt/cw12/cw-data/ClueWeb12_17/1716wb/1716wb-63.warc:0+69402458
2014-07-10 23:32:01,503 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:445 as TID 446 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:32:01,503 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:445 as 6326 bytes in 0 ms
2014-07-10 23:32:01,506 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 206 in 10085032 ms on dco-node136-mgt.dco.ethz.ch (progress: 190/497)
2014-07-10 23:32:01,506 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 206)
2014-07-10 23:32:02,603 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:446 as TID 447 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:32:02,603 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:446 as 6178 bytes in 0 ms
2014-07-10 23:32:02,606 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 168)
2014-07-10 23:32:02,606 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 168 in 10086150 ms on dco-node132-mgt.dco.ethz.ch (progress: 191/497)
2014-07-10 23:32:52,123 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:447 as TID 448 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:32:52,123 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:447 as 6252 bytes in 0 ms
2014-07-10 23:32:52,126 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 15 in 10135767 ms on dco-node127-mgt.dco.ethz.ch (progress: 192/497)
2014-07-10 23:32:52,126 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 15)
2014-07-10 23:32:53,241 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:448 as TID 449 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:32:53,242 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:448 as 6252 bytes in 0 ms
2014-07-10 23:32:53,244 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 95 in 10136827 ms on dco-node127-mgt.dco.ethz.ch (progress: 193/497)
2014-07-10 23:32:53,244 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 95)
2014-07-10 23:33:14,670 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:449 as TID 450 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:33:14,671 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:449 as 6178 bytes in 0 ms
2014-07-10 23:33:14,673 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 237 in 10158185 ms on dco-node122-mgt.dco.ethz.ch (progress: 194/497)
2014-07-10 23:33:14,673 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 237)
2014-07-10 23:34:03,179 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:450 as TID 451 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:34:03,180 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:450 as 6252 bytes in 1 ms
2014-07-10 23:34:03,182 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 173 in 10206724 ms on dco-node122-mgt.dco.ethz.ch (progress: 195/497)
2014-07-10 23:34:03,182 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 173)
2014-07-10 23:34:44,389 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:451 as TID 452 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:34:44,390 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:451 as 6178 bytes in 0 ms
2014-07-10 23:34:44,392 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 114 in 10247964 ms on dco-node123-mgt.dco.ethz.ch (progress: 196/497)
2014-07-10 23:34:44,392 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 114)
2014-07-10 23:34:49,937 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:452 as TID 453 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:34:49,938 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:452 as 6030 bytes in 1 ms
2014-07-10 23:34:49,940 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 147 in 10253494 ms on dco-node131-mgt.dco.ethz.ch (progress: 197/497)
2014-07-10 23:34:49,940 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 147)
2014-07-10 23:34:50,749 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:453 as TID 454 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:34:50,749 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:453 as 6104 bytes in 0 ms
2014-07-10 23:34:50,751 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 63 in 10254354 ms on dco-node127-mgt.dco.ethz.ch (progress: 198/497)
2014-07-10 23:34:50,751 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 63)
2014-07-10 23:34:55,389 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:454 as TID 455 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:34:55,390 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:454 as 6030 bytes in 1 ms
2014-07-10 23:34:55,392 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 231 in 10258907 ms on dco-node125-mgt.dco.ethz.ch (progress: 199/497)
2014-07-10 23:34:55,392 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 231)
2014-07-10 23:34:58,213 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:455 as TID 456 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:34:58,214 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:455 as 6030 bytes in 0 ms
2014-07-10 23:34:58,216 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 161 in 10261763 ms on dco-node135-mgt.dco.ethz.ch (progress: 200/497)
2014-07-10 23:34:58,216 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 161)
2014-07-10 23:35:03,005 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:456 as TID 457 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:35:03,005 [spark-akka.actor.default-dispatcher-36] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:456 as 6030 bytes in 0 ms
2014-07-10 23:35:03,008 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 107 in 10266584 ms on dco-node124-mgt.dco.ethz.ch (progress: 201/497)
2014-07-10 23:35:03,008 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 107)
2014-07-10 23:35:15,857 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:457 as TID 458 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:35:15,857 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:457 as 6252 bytes in 0 ms
2014-07-10 23:35:15,859 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 150 in 10279411 ms on dco-node129-mgt.dco.ethz.ch (progress: 202/497)
2014-07-10 23:35:15,859 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 150)
2014-07-10 23:36:09,948 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:458 as TID 459 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:36:09,948 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:458 as 6178 bytes in 0 ms
2014-07-10 23:36:09,950 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 221 in 10333469 ms on dco-node122-mgt.dco.ethz.ch (progress: 203/497)
2014-07-10 23:36:09,951 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 221)
2014-07-10 23:36:14,230 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:459 as TID 460 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:36:14,230 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:459 as 6030 bytes in 0 ms
2014-07-10 23:36:14,233 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 157 in 10337782 ms on dco-node122-mgt.dco.ethz.ch (progress: 204/497)
2014-07-10 23:36:14,233 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 157)
2014-07-10 23:37:20,224 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:460 as TID 461 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:37:20,225 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:460 as 6252 bytes in 0 ms
2014-07-10 23:37:20,227 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 241 in 10403737 ms on dco-node135-mgt.dco.ethz.ch (progress: 205/497)
2014-07-10 23:37:20,227 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 241)
2014-07-10 23:37:55,599 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:461 as TID 462 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:37:55,599 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:461 as 6252 bytes in 0 ms
2014-07-10 23:37:55,601 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 255 in 10439105 ms on dco-node127-mgt.dco.ethz.ch (progress: 206/497)
2014-07-10 23:37:55,601 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 255)
2014-07-10 23:38:23,206 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:462 as TID 463 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:38:23,207 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:462 as 6252 bytes in 1 ms
2014-07-10 23:38:23,209 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 253 in 10466714 ms on dco-node122-mgt.dco.ethz.ch (progress: 207/497)
2014-07-10 23:38:23,209 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 253)
2014-07-10 23:38:47,098 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:463 as TID 464 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:38:47,098 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:463 as 6104 bytes in 0 ms
2014-07-10 23:38:47,100 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 191 in 10490633 ms on dco-node127-mgt.dco.ethz.ch (progress: 208/497)
2014-07-10 23:38:47,100 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 191)
2014-07-10 23:38:53,681 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:464 as TID 465 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:38:53,681 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:464 as 6178 bytes in 0 ms
2014-07-10 23:38:53,683 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 175 in 10497224 ms on dco-node127-mgt.dco.ethz.ch (progress: 209/497)
2014-07-10 23:38:53,683 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 175)
2014-07-10 23:38:58,640 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:465 as TID 466 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:38:58,640 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:465 as 6104 bytes in 0 ms
2014-07-10 23:38:58,643 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 159 in 10502191 ms on dco-node127-mgt.dco.ethz.ch (progress: 210/497)
2014-07-10 23:38:58,643 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 159)
2014-07-10 23:39:18,481 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:466 as TID 467 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:39:18,482 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:466 as 6104 bytes in 0 ms
2014-07-10 23:39:18,484 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 116 in 10522055 ms on dco-node130-mgt.dco.ethz.ch (progress: 211/497)
2014-07-10 23:39:18,484 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 116)
2014-07-10 23:39:48,859 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:467 as TID 468 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:39:48,860 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:467 as 6104 bytes in 1 ms
2014-07-10 23:39:48,862 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 167 in 10552406 ms on dco-node125-mgt.dco.ethz.ch (progress: 212/497)
2014-07-10 23:39:48,862 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 167)
2014-07-10 23:40:15,659 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:468 as TID 469 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:40:15,660 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:468 as 6104 bytes in 1 ms
2014-07-10 23:40:15,662 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 239)
2014-07-10 23:40:15,662 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 239 in 10579173 ms on dco-node127-mgt.dco.ethz.ch (progress: 213/497)
2014-07-10 23:40:24,901 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:469 as TID 470 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:40:24,902 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:469 as 6030 bytes in 1 ms
2014-07-10 23:40:24,904 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 200)
2014-07-10 23:40:24,904 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 200 in 10588433 ms on dco-node132-mgt.dco.ethz.ch (progress: 214/497)
2014-07-10 23:40:31,716 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Serialized size of result for 108 is 535
2014-07-10 23:40:31,716 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Sending result for 108 directly to driver
2014-07-10 23:40:31,716 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Finished task ID 108
2014-07-10 23:40:31,718 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:470 as TID 471 on executor 9: dco-node121-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:40:31,719 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:470 as 6030 bytes in 1 ms
2014-07-10 23:40:31,720 [sparkExecutor-akka.actor.default-dispatcher-24] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 471
2014-07-10 23:40:31,721 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 108)
2014-07-10 23:40:31,721 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 108 in 10595296 ms on dco-node121-mgt.dco.ethz.ch (progress: 215/497)
2014-07-10 23:40:31,721 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Running task ID 471
2014-07-10 23:40:31,723 [Executor task launch worker-6] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-10 23:40:31,725 [Executor task launch worker-6] INFO  org.apache.spark.rdd.WholeTextFileRDD - Input split: Paths:/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-17.warc:0+73443978,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-18.warc:0+69968567,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-19.warc:0+69183631,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-20.warc:0+69263653,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-21.warc:0+67584168,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-22.warc:0+69847895,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-23.warc:0+70049302,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-24.warc:0+69527603,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-25.warc:0+76414425,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-26.warc:0+77880871,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-27.warc:0+72041934,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-28.warc:0+70258441,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-29.warc:0+71801382,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-30.warc:0+72940566,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-31.warc:0+73165638,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-32.warc:0+70672078,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-33.warc:0+72062468,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-34.warc:0+69764070,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-35.warc:0+67960608,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-36.warc:0+69721486,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-37.warc:0+65637321,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-38.warc:0+67602365,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-39.warc:0+72318473,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-40.warc:0+71752572,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-41.warc:0+70672662,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-42.warc:0+71491402,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-43.warc:0+74122393,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-44.warc:0+70491219,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-45.warc:0+72819300,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-46.warc:0+72577138,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-47.warc:0+70807278,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-48.warc:0+69718141,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-49.warc:0+71009687,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-50.warc:0+70906764,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-51.warc:0+70810225,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-52.warc:0+69289076,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-53.warc:0+70334678,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-54.warc:0+71669363,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-55.warc:0+70817984,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-56.warc:0+70448628,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-57.warc:0+70809883,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-58.warc:0+62095706,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-59.warc:0+65581331,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-60.warc:0+69294062,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-61.warc:0+72178526,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-62.warc:0+68770134,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-63.warc:0+67722020,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-64.warc:0+70020191,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-65.warc:0+69711713,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-66.warc:0+71928797,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-67.warc:0+69467642,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-68.warc:0+72291477,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-69.warc:0+71651821,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-70.warc:0+71390990,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-71.warc:0+71018265,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-72.warc:0+81294297,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-73.warc:0+74124590,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-74.warc:0+71776687,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-75.warc:0+66157319,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-76.warc:0+60640921,/mnt/cw12/cw-data/ClueWeb12_18/1814wb/1814wb-77.warc:0+78952031
2014-07-10 23:40:32,144 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:471 as TID 472 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:40:32,144 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:471 as 6030 bytes in 0 ms
2014-07-10 23:40:32,146 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 193 in 10595678 ms on dco-node135-mgt.dco.ethz.ch (progress: 216/497)
2014-07-10 23:40:32,146 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 193)
2014-07-10 23:41:47,636 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:472 as TID 473 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:41:47,637 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:472 as 6030 bytes in 1 ms
2014-07-10 23:41:47,639 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 177 in 10671179 ms on dco-node135-mgt.dco.ethz.ch (progress: 217/497)
2014-07-10 23:41:47,639 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 177)
2014-07-10 23:42:28,654 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:473 as TID 474 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:42:28,654 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:473 as 6104 bytes in 0 ms
2014-07-10 23:42:28,657 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 117 in 10712226 ms on dco-node134-mgt.dco.ethz.ch (progress: 218/497)
2014-07-10 23:42:28,657 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 117)
2014-07-10 23:42:59,961 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:474 as TID 475 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:42:59,962 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:474 as 6030 bytes in 0 ms
2014-07-10 23:42:59,964 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 110)
2014-07-10 23:42:59,964 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 110 in 10743538 ms on dco-node136-mgt.dco.ethz.ch (progress: 219/497)
2014-07-10 23:43:35,086 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:475 as TID 476 on executor 2: dco-node125-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:43:35,086 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:475 as 6104 bytes in 0 ms
2014-07-10 23:43:35,089 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 151 in 10778641 ms on dco-node125-mgt.dco.ethz.ch (progress: 220/497)
2014-07-10 23:43:35,089 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 151)
2014-07-10 23:43:40,187 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:476 as TID 477 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:43:40,187 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:476 as 5956 bytes in 0 ms
2014-07-10 23:43:40,190 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 138)
2014-07-10 23:43:40,190 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 138 in 10783747 ms on dco-node128-mgt.dco.ethz.ch (progress: 221/497)
2014-07-10 23:43:43,486 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:477 as TID 478 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:43:43,487 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:477 as 6698 bytes in 0 ms
2014-07-10 23:43:43,489 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 142)
2014-07-10 23:43:43,489 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 142 in 10787045 ms on dco-node136-mgt.dco.ethz.ch (progress: 222/497)
2014-07-10 23:44:13,596 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:478 as TID 479 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:44:13,596 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:478 as 6400 bytes in 0 ms
2014-07-10 23:44:13,599 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 149 in 10817152 ms on dco-node134-mgt.dco.ethz.ch (progress: 223/497)
2014-07-10 23:44:13,599 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 149)
2014-07-10 23:44:45,012 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:479 as TID 480 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:44:45,012 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:479 as 6474 bytes in 0 ms
2014-07-10 23:44:45,014 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 136 in 10848573 ms on dco-node132-mgt.dco.ethz.ch (progress: 224/497)
2014-07-10 23:44:45,014 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 136)
2014-07-10 23:45:54,607 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:480 as TID 481 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:45:54,608 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:480 as 6252 bytes in 0 ms
2014-07-10 23:45:54,610 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 207 in 10918135 ms on dco-node127-mgt.dco.ethz.ch (progress: 225/497)
2014-07-10 23:45:54,610 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 207)
2014-07-10 23:46:33,222 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:481 as TID 482 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:46:33,223 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:481 as 6178 bytes in 1 ms
2014-07-10 23:46:33,225 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 139 in 10956782 ms on dco-node124-mgt.dco.ethz.ch (progress: 226/497)
2014-07-10 23:46:33,225 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 139)
2014-07-10 23:50:19,917 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:482 as TID 483 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:50:19,917 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:482 as 6104 bytes in 0 ms
2014-07-10 23:50:19,920 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 111 in 11183493 ms on dco-node127-mgt.dco.ethz.ch (progress: 227/497)
2014-07-10 23:50:19,920 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 111)
2014-07-10 23:50:29,476 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:483 as TID 484 on executor 8: dco-node130-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:50:29,477 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:483 as 6030 bytes in 1 ms
2014-07-10 23:50:29,478 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 132 in 11193040 ms on dco-node130-mgt.dco.ethz.ch (progress: 228/497)
2014-07-10 23:50:29,478 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 132)
2014-07-10 23:51:11,377 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:484 as TID 485 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:51:11,377 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:484 as 6104 bytes in 0 ms
2014-07-10 23:51:11,379 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 134)
2014-07-10 23:51:11,379 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 134 in 11234939 ms on dco-node129-mgt.dco.ethz.ch (progress: 229/497)
2014-07-10 23:51:21,518 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:485 as TID 486 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:51:21,518 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:485 as 6104 bytes in 0 ms
2014-07-10 23:51:21,520 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 198 in 11245049 ms on dco-node129-mgt.dco.ethz.ch (progress: 230/497)
2014-07-10 23:51:21,521 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 198)
2014-07-10 23:53:02,242 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:486 as TID 487 on executor 5: dco-node133-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:53:02,243 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:486 as 6104 bytes in 0 ms
2014-07-10 23:53:02,245 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 128 in 11345808 ms on dco-node133-mgt.dco.ethz.ch (progress: 231/497)
2014-07-10 23:53:02,245 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 128)
2014-07-10 23:53:40,709 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:487 as TID 488 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:53:40,709 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:487 as 6252 bytes in 0 ms
2014-07-10 23:53:40,711 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 223 in 11384229 ms on dco-node127-mgt.dco.ethz.ch (progress: 232/497)
2014-07-10 23:53:40,711 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 223)
2014-07-10 23:53:57,801 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:488 as TID 489 on executor 13: dco-node122-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:53:57,801 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:488 as 6326 bytes in 0 ms
2014-07-10 23:53:57,820 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 109 in 11401394 ms on dco-node122-mgt.dco.ethz.ch (progress: 233/497)
2014-07-10 23:53:57,820 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 109)
2014-07-10 23:54:28,536 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:489 as TID 490 on executor 6: dco-node134-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:54:28,536 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:489 as 6104 bytes in 0 ms
2014-07-10 23:54:28,538 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 133 in 11432099 ms on dco-node134-mgt.dco.ethz.ch (progress: 234/497)
2014-07-10 23:54:28,538 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 133)
2014-07-10 23:54:34,396 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:490 as TID 491 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:54:34,397 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:490 as 6030 bytes in 0 ms
2014-07-10 23:54:34,399 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 113 in 11437971 ms on dco-node135-mgt.dco.ethz.ch (progress: 235/497)
2014-07-10 23:54:34,399 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 113)
2014-07-10 23:55:05,344 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:491 as TID 492 on executor 0: dco-node131-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:55:05,345 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:491 as 6030 bytes in 1 ms
2014-07-10 23:55:05,347 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 131 in 11468909 ms on dco-node131-mgt.dco.ethz.ch (progress: 236/497)
2014-07-10 23:55:05,347 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 131)
2014-07-10 23:56:04,212 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:492 as TID 493 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:56:04,212 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:492 as 6030 bytes in 0 ms
2014-07-10 23:56:04,214 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 137 in 11527772 ms on dco-node126-mgt.dco.ethz.ch (progress: 237/497)
2014-07-10 23:56:04,214 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 137)
2014-07-10 23:56:18,513 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:493 as TID 494 on executor 7: dco-node127-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:56:18,514 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:493 as 6030 bytes in 0 ms
2014-07-10 23:56:18,516 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 127 in 11542080 ms on dco-node127-mgt.dco.ethz.ch (progress: 238/497)
2014-07-10 23:56:18,516 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 127)
2014-07-10 23:56:47,605 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:494 as TID 495 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:56:47,605 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:494 as 5956 bytes in 0 ms
2014-07-10 23:56:47,607 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 145 in 11571162 ms on dco-node135-mgt.dco.ethz.ch (progress: 239/497)
2014-07-10 23:56:47,608 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 145)
2014-07-10 23:57:21,773 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:495 as TID 496 on executor 15: dco-node129-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:57:21,773 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:495 as 5956 bytes in 0 ms
2014-07-10 23:57:21,775 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 118 in 11605345 ms on dco-node129-mgt.dco.ethz.ch (progress: 240/497)
2014-07-10 23:57:21,775 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 118)
2014-07-10 23:57:52,698 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:496 as TID 497 on executor 4: dco-node135-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-10 23:57:52,698 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:496 as 2460 bytes in 0 ms
2014-07-10 23:57:52,700 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 225 in 11636217 ms on dco-node135-mgt.dco.ethz.ch (progress: 241/497)
2014-07-10 23:57:52,700 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 225)
2014-07-10 23:59:16,731 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 121 in 11720298 ms on dco-node126-mgt.dco.ethz.ch (progress: 242/497)
2014-07-10 23:59:16,731 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 121)
2014-07-10 23:59:31,774 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 122 in 11735341 ms on dco-node128-mgt.dco.ethz.ch (progress: 243/497)
2014-07-10 23:59:31,774 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 122)
2014-07-11 00:01:20,692 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 130 in 11844254 ms on dco-node123-mgt.dco.ethz.ch (progress: 244/497)
2014-07-11 00:01:20,692 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 130)
2014-07-11 00:02:31,440 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 126 in 11915004 ms on dco-node136-mgt.dco.ethz.ch (progress: 245/497)
2014-07-11 00:02:31,440 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 126)
2014-07-11 00:02:32,582 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 199 in 11916110 ms on dco-node125-mgt.dco.ethz.ch (progress: 246/497)
2014-07-11 00:02:32,582 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 199)
2014-07-11 00:07:56,552 [Executor task launch worker-7] ERROR WarcFileProcessor - Exception processing record: clueweb12-0510wb-18-30603
2014-07-11 00:08:00,310 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 197 in 12243840 ms on dco-node134-mgt.dco.ethz.ch (progress: 247/497)
2014-07-11 00:08:00,310 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 197)
2014-07-11 00:08:09,853 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 120 in 12253421 ms on dco-node132-mgt.dco.ethz.ch (progress: 248/497)
2014-07-11 00:08:09,853 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 120)
2014-07-11 00:08:36,510 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 135 in 12280068 ms on dco-node125-mgt.dco.ethz.ch (progress: 249/497)
2014-07-11 00:08:36,510 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 135)
2014-07-11 00:18:29,092 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 143 in 12872649 ms on dco-node127-mgt.dco.ethz.ch (progress: 250/497)
2014-07-11 00:18:29,093 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 143)
2014-07-11 00:18:57,667 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 123 in 12901234 ms on dco-node124-mgt.dco.ethz.ch (progress: 251/497)
2014-07-11 00:18:57,667 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 123)
2014-07-11 00:22:11,594 [spark-akka.actor.default-dispatcher-42] WARN  org.apache.spark.storage.BlockManagerMasterActor - Removing BlockManager BlockManagerId(6, dco-node134-mgt.dco.ethz.ch, 47137, 0) with no recent heart beats: 99376ms exceeds 45000ms
2014-07-11 00:22:58,760 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:47137 with 40.3 GB RAM
2014-07-11 00:23:00,610 [Result resolver thread-0] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 413 (task 0.0:412)
2014-07-11 00:23:00,618 [Result resolver thread-0] WARN  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException
org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1347)
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updatePipeline(ClientNamenodeProtocolTranslatorPB.java:791)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1047)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:823)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:475)
2014-07-11 00:23:00,619 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:412 as TID 498 on executor 1: dco-node126-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-11 00:23:00,620 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:412 as 6474 bytes in 1 ms
2014-07-11 00:23:42,100 [Result resolver thread-1] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 321 (task 0.0:320)
2014-07-11 00:23:42,101 [Result resolver thread-1] WARN  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException
org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1347)
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updatePipeline(ClientNamenodeProtocolTranslatorPB.java:791)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1047)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:823)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:475)
2014-07-11 00:23:42,102 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:320 as TID 499 on executor 3: dco-node123-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-11 00:23:42,102 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:320 as 6104 bytes in 0 ms
2014-07-11 00:25:11,594 [spark-akka.actor.default-dispatcher-42] WARN  org.apache.spark.storage.BlockManagerMasterActor - Removing BlockManager BlockManagerId(6, dco-node134-mgt.dco.ethz.ch, 47137, 0) with no recent heart beats: 90334ms exceeds 45000ms
2014-07-11 00:25:53,475 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:47137 with 40.3 GB RAM
2014-07-11 00:25:57,163 [Result resolver thread-2] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 418 (task 0.0:417)
2014-07-11 00:25:57,164 [Result resolver thread-2] WARN  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException
org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1347)
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updatePipeline(ClientNamenodeProtocolTranslatorPB.java:791)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1047)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:823)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:475)
2014-07-11 00:25:57,164 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:417 as TID 500 on executor 11: dco-node124-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-11 00:25:57,165 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:417 as 6775 bytes in 0 ms
2014-07-11 00:26:00,999 [Result resolver thread-3] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 298 (task 0.0:297)
2014-07-11 00:26:01,002 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
 [duplicate 1]
2014-07-11 00:26:01,003 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:297 as TID 501 on executor 10: dco-node128-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-11 00:26:01,003 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:297 as 6400 bytes in 0 ms
2014-07-11 00:26:06,573 [Result resolver thread-0] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 313 (task 0.0:312)
2014-07-11 00:26:06,574 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)
 [duplicate 2]
2014-07-11 00:26:06,575 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:312 as TID 502 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-11 00:26:06,575 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:312 as 6326 bytes in 0 ms
2014-07-11 00:28:13,481 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 124 is 535
2014-07-11 00:28:13,481 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 124 directly to driver
2014-07-11 00:28:13,481 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 124
2014-07-11 00:28:13,486 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 124 in 13457052 ms on dco-node121-mgt.dco.ethz.ch (progress: 252/497)
2014-07-11 00:28:13,486 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 124)
2014-07-11 00:28:57,139 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 125)
2014-07-11 00:28:57,139 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 125 in 13500704 ms on dco-node122-mgt.dco.ethz.ch (progress: 253/497)
2014-07-11 00:29:44,240 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 129 in 13547802 ms on dco-node135-mgt.dco.ethz.ch (progress: 254/497)
2014-07-11 00:29:44,240 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 129)
2014-07-11 00:30:10,072 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 119 in 13573640 ms on dco-node125-mgt.dco.ethz.ch (progress: 255/497)
2014-07-11 00:30:10,072 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 119)
2014-07-11 00:31:31,951 [Result resolver thread-1] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 256 (task 0.0:256)
2014-07-11 00:31:31,951 [Result resolver thread-1] WARN  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException
org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1347)
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updatePipeline(ClientNamenodeProtocolTranslatorPB.java:791)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1047)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:823)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:475)
2014-07-11 00:31:31,952 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:256 as TID 503 on executor 12: dco-node132-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-11 00:31:31,953 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:256 as 6474 bytes in 1 ms
2014-07-11 00:34:15,018 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 497 in 2182317 ms on dco-node135-mgt.dco.ethz.ch (progress: 256/497)
2014-07-11 00:34:15,018 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 496)
2014-07-11 00:41:47,316 [Executor task launch worker-11] ERROR WarcFileProcessor - Exception processing record: clueweb12-1303wb-55-15506
2014-07-11 00:50:40,546 [Executor task launch worker-11] ERROR WarcFileProcessor - Exception processing record: clueweb12-1303wb-58-23363
2014-07-11 00:50:42,211 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 257 in 8251286 ms on dco-node126-mgt.dco.ethz.ch (progress: 257/497)
2014-07-11 00:50:42,211 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 5)
2014-07-11 01:00:21,908 [Executor task launch worker-8] ERROR WarcFileProcessor - Exception processing record: clueweb12-1716wb-31-05136
2014-07-11 01:03:05,113 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 301 in 7072813 ms on dco-node134-mgt.dco.ethz.ch (progress: 258/497)
2014-07-11 01:03:05,113 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 300)
2014-07-11 01:07:56,008 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 315 in 7251545 ms on dco-node134-mgt.dco.ethz.ch (progress: 259/497)
2014-07-11 01:07:56,008 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 314)
2014-07-11 01:10:36,880 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Serialized size of result for 365 is 535
2014-07-11 01:10:36,881 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Sending result for 365 directly to driver
2014-07-11 01:10:36,881 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Finished task ID 365
2014-07-11 01:10:36,884 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 365 in 6946040 ms on dco-node121-mgt.dco.ethz.ch (progress: 260/497)
2014-07-11 01:10:36,884 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 364)
2014-07-11 01:11:23,435 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 352 in 7082934 ms on dco-node134-mgt.dco.ethz.ch (progress: 261/497)
2014-07-11 01:11:23,435 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 351)
2014-07-11 01:11:50,577 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 323 in 7419370 ms on dco-node134-mgt.dco.ethz.ch (progress: 262/497)
2014-07-11 01:11:50,578 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 322)
2014-07-11 01:12:59,772 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 260 in 8522578 ms on dco-node129-mgt.dco.ethz.ch (progress: 263/497)
2014-07-11 01:12:59,772 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 259)
2014-07-11 01:13:06,918 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 268 in 8108954 ms on dco-node128-mgt.dco.ethz.ch (progress: 264/497)
2014-07-11 01:13:06,918 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 267)
2014-07-11 01:14:18,021 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 325 in 7554475 ms on dco-node134-mgt.dco.ethz.ch (progress: 265/497)
2014-07-11 01:14:18,021 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 324)
2014-07-11 01:15:49,056 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 258 in 8941217 ms on dco-node133-mgt.dco.ethz.ch (progress: 266/497)
2014-07-11 01:15:49,056 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 257)
2014-07-11 01:15:58,697 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 263 in 8467379 ms on dco-node133-mgt.dco.ethz.ch (progress: 267/497)
2014-07-11 01:15:58,697 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 262)
2014-07-11 01:16:04,840 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 269 in 8213872 ms on dco-node128-mgt.dco.ethz.ch (progress: 268/497)
2014-07-11 01:16:04,840 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 268)
2014-07-11 01:17:02,075 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 474 in 5673419 ms on dco-node134-mgt.dco.ethz.ch (progress: 269/497)
2014-07-11 01:17:02,075 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 473)
2014-07-11 01:17:11,858 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 262 in 8561725 ms on dco-node130-mgt.dco.ethz.ch (progress: 270/497)
2014-07-11 01:17:11,858 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 261)
2014-07-11 01:17:28,823 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 479 in 5595225 ms on dco-node134-mgt.dco.ethz.ch (progress: 271/497)
2014-07-11 01:17:28,823 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 478)
2014-07-11 01:17:50,035 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 264 in 8575340 ms on dco-node131-mgt.dco.ethz.ch (progress: 272/497)
2014-07-11 01:17:50,036 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 263)
2014-07-11 01:17:57,140 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 290 in 8041418 ms on dco-node128-mgt.dco.ethz.ch (progress: 273/497)
2014-07-11 01:17:57,140 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 289)
2014-07-11 01:18:33,249 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 265 in 8501734 ms on dco-node130-mgt.dco.ethz.ch (progress: 274/497)
2014-07-11 01:18:33,249 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 264)
2014-07-11 01:18:56,714 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 261 in 8667146 ms on dco-node123-mgt.dco.ethz.ch (progress: 275/497)
2014-07-11 01:18:56,714 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 260)
2014-07-11 01:19:02,943 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 291 in 8100680 ms on dco-node130-mgt.dco.ethz.ch (progress: 276/497)
2014-07-11 01:19:02,943 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 290)
2014-07-11 01:19:22,568 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 281 in 8224941 ms on dco-node128-mgt.dco.ethz.ch (progress: 277/497)
2014-07-11 01:19:22,568 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 280)
2014-07-11 01:19:42,942 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 292 in 8135818 ms on dco-node126-mgt.dco.ethz.ch (progress: 278/497)
2014-07-11 01:19:42,942 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 291)
2014-07-11 01:20:10,132 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 490 in 5141594 ms on dco-node134-mgt.dco.ethz.ch (progress: 279/497)
2014-07-11 01:20:10,132 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 489)
2014-07-11 01:20:17,816 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 274 in 8363238 ms on dco-node128-mgt.dco.ethz.ch (progress: 280/497)
2014-07-11 01:20:17,816 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 273)
2014-07-11 01:20:46,164 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Serialized size of result for 375 is 535
2014-07-11 01:20:46,164 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Sending result for 375 directly to driver
2014-07-11 01:20:46,164 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task ID 375
2014-07-11 01:20:46,168 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 375 in 7439412 ms on dco-node121-mgt.dco.ethz.ch (progress: 281/497)
2014-07-11 01:20:46,168 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 374)
2014-07-11 01:21:38,392 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 303 in 8172386 ms on dco-node126-mgt.dco.ethz.ch (progress: 282/497)
2014-07-11 01:21:38,392 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 302)
2014-07-11 01:22:00,476 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 259 in 9087018 ms on dco-node132-mgt.dco.ethz.ch (progress: 283/497)
2014-07-11 01:22:00,477 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 258)
2014-07-11 01:22:07,674 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Serialized size of result for 354 is 535
2014-07-11 01:22:07,674 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Sending result for 354 directly to driver
2014-07-11 01:22:07,674 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Finished task ID 354
2014-07-11 01:22:07,678 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 354 in 7707674 ms on dco-node121-mgt.dco.ethz.ch (progress: 284/497)
2014-07-11 01:22:07,678 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 353)
2014-07-11 01:22:26,961 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 279 in 8458013 ms on dco-node123-mgt.dco.ethz.ch (progress: 285/497)
2014-07-11 01:22:26,961 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 278)
2014-07-11 01:22:40,836 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 282 in 8408330 ms on dco-node133-mgt.dco.ethz.ch (progress: 286/497)
2014-07-11 01:22:40,836 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 281)
2014-07-11 01:22:54,661 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 295 in 8316447 ms on dco-node123-mgt.dco.ethz.ch (progress: 287/497)
2014-07-11 01:22:54,661 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 294)
2014-07-11 01:22:57,184 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 283 in 8416821 ms on dco-node123-mgt.dco.ethz.ch (progress: 288/497)
2014-07-11 01:22:57,184 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 282)
2014-07-11 01:23:19,386 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 287 in 8398796 ms on dco-node130-mgt.dco.ethz.ch (progress: 289/497)
2014-07-11 01:23:19,387 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 286)
2014-07-11 01:24:21,253 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 349 in 7874732 ms on dco-node134-mgt.dco.ethz.ch (progress: 290/497)
2014-07-11 01:24:21,253 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 348)
2014-07-11 01:25:10,321 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 277 in 8641649 ms on dco-node131-mgt.dco.ethz.ch (progress: 291/497)
2014-07-11 01:25:10,321 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 276)
2014-07-11 01:25:13,688 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 300 in 8417683 ms on dco-node128-mgt.dco.ethz.ch (progress: 292/497)
2014-07-11 01:25:13,688 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 299)
2014-07-11 01:25:14,354 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 273 in 8692725 ms on dco-node126-mgt.dco.ethz.ch (progress: 293/497)
2014-07-11 01:25:14,354 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 272)
2014-07-11 01:25:46,055 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 286 in 8548417 ms on dco-node133-mgt.dco.ethz.ch (progress: 294/497)
2014-07-11 01:25:46,055 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 285)
2014-07-11 01:26:12,097 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 276 in 8712836 ms on dco-node130-mgt.dco.ethz.ch (progress: 295/497)
2014-07-11 01:26:12,097 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 275)
2014-07-11 01:27:08,556 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 331 in 8248982 ms on dco-node130-mgt.dco.ethz.ch (progress: 296/497)
2014-07-11 01:27:08,556 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 330)
2014-07-11 01:27:10,131 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 267 in 8953004 ms on dco-node129-mgt.dco.ethz.ch (progress: 297/497)
2014-07-11 01:27:10,131 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 266)
2014-07-11 01:27:10,473 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 299 in 8546342 ms on dco-node123-mgt.dco.ethz.ch (progress: 298/497)
2014-07-11 01:27:10,473 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 298)
2014-07-11 01:27:21,690 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 306 in 8496649 ms on dco-node133-mgt.dco.ethz.ch (progress: 299/497)
2014-07-11 01:27:21,690 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 305)
2014-07-11 01:27:38,298 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 288 in 8641282 ms on dco-node131-mgt.dco.ethz.ch (progress: 300/497)
2014-07-11 01:27:38,298 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 287)
2014-07-11 01:27:39,649 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 293 in 8608402 ms on dco-node129-mgt.dco.ethz.ch (progress: 301/497)
2014-07-11 01:27:39,649 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 292)
2014-07-11 01:27:41,229 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 318 in 8395797 ms on dco-node128-mgt.dco.ethz.ch (progress: 302/497)
2014-07-11 01:27:41,229 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 317)
2014-07-11 01:27:50,759 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 302 is 535
2014-07-11 01:27:50,759 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 302 directly to driver
2014-07-11 01:27:50,759 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 302
2014-07-11 01:27:50,762 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 302 in 8549761 ms on dco-node121-mgt.dco.ethz.ch (progress: 303/497)
2014-07-11 01:27:50,762 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 301)
2014-07-11 01:28:28,937 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Serialized size of result for 387 is 535
2014-07-11 01:28:28,937 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Sending result for 387 directly to driver
2014-07-11 01:28:28,937 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Finished task ID 387
2014-07-11 01:28:28,941 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 387 in 7751584 ms on dco-node121-mgt.dco.ethz.ch (progress: 304/497)
2014-07-11 01:28:28,941 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 386)
2014-07-11 01:28:38,352 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Serialized size of result for 384 is 535
2014-07-11 01:28:38,353 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Sending result for 384 directly to driver
2014-07-11 01:28:38,353 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task ID 384
2014-07-11 01:28:38,357 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 384 in 7786716 ms on dco-node121-mgt.dco.ethz.ch (progress: 305/497)
2014-07-11 01:28:38,357 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 383)
2014-07-11 01:28:52,398 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 296 in 8668409 ms on dco-node123-mgt.dco.ethz.ch (progress: 306/497)
2014-07-11 01:28:52,398 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 295)
2014-07-11 01:28:58,249 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 284 in 8772218 ms on dco-node132-mgt.dco.ethz.ch (progress: 307/497)
2014-07-11 01:28:58,250 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 283)
2014-07-11 01:29:20,316 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 306)
2014-07-11 01:29:20,316 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 307 in 8598042 ms on dco-node133-mgt.dco.ethz.ch (progress: 308/497)
2014-07-11 01:29:36,000 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 369 in 8019596 ms on dco-node133-mgt.dco.ethz.ch (progress: 309/497)
2014-07-11 01:29:36,000 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 368)
2014-07-11 01:29:36,815 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 324 in 8484644 ms on dco-node130-mgt.dco.ethz.ch (progress: 310/497)
2014-07-11 01:29:36,815 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 323)
2014-07-11 01:29:37,983 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 310 in 8583068 ms on dco-node126-mgt.dco.ethz.ch (progress: 311/497)
2014-07-11 01:29:37,983 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 309)
2014-07-11 01:29:40,683 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 288)
2014-07-11 01:29:40,683 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 289 in 8760411 ms on dco-node131-mgt.dco.ethz.ch (progress: 312/497)
2014-07-11 01:29:41,953 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 265)
2014-07-11 01:29:41,953 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 266 in 9125498 ms on dco-node124-mgt.dco.ethz.ch (progress: 313/497)
2014-07-11 01:29:49,163 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Serialized size of result for 383 is 535
2014-07-11 01:29:49,163 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Sending result for 383 directly to driver
2014-07-11 01:29:49,163 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Finished task ID 383
2014-07-11 01:29:49,166 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 383 in 7870412 ms on dco-node121-mgt.dco.ethz.ch (progress: 314/497)
2014-07-11 01:29:49,166 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 382)
2014-07-11 01:30:16,416 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 330 in 8446584 ms on dco-node133-mgt.dco.ethz.ch (progress: 315/497)
2014-07-11 01:30:16,416 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 329)
2014-07-11 01:30:23,523 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 311)
2014-07-11 01:30:23,523 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 312 in 8605134 ms on dco-node130-mgt.dco.ethz.ch (progress: 316/497)
2014-07-11 01:30:43,767 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 269)
2014-07-11 01:30:43,767 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 270 in 9072539 ms on dco-node132-mgt.dco.ethz.ch (progress: 317/497)
2014-07-11 01:31:05,316 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 274)
2014-07-11 01:31:05,316 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 275 in 9006248 ms on dco-node132-mgt.dco.ethz.ch (progress: 318/497)
2014-07-11 01:31:12,825 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 272 in 9070631 ms on dco-node131-mgt.dco.ethz.ch (progress: 319/497)
2014-07-11 01:31:12,825 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 271)
2014-07-11 01:31:30,672 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 382 in 7991566 ms on dco-node128-mgt.dco.ethz.ch (progress: 320/497)
2014-07-11 01:31:30,672 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 381)
2014-07-11 01:31:55,368 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 284)
2014-07-11 01:31:55,368 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 285 in 8921180 ms on dco-node132-mgt.dco.ethz.ch (progress: 321/497)
2014-07-11 01:32:00,804 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Serialized size of result for 314 is 535
2014-07-11 01:32:00,805 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Sending result for 314 directly to driver
2014-07-11 01:32:00,805 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Finished task ID 314
2014-07-11 01:32:00,808 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 314 in 8696725 ms on dco-node121-mgt.dco.ethz.ch (progress: 322/497)
2014-07-11 01:32:00,808 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 313)
2014-07-11 01:32:03,536 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 278 in 9044298 ms on dco-node124-mgt.dco.ethz.ch (progress: 323/497)
2014-07-11 01:32:03,536 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 277)
2014-07-11 01:32:19,822 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Serialized size of result for 280 is 535
2014-07-11 01:32:19,822 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Sending result for 280 directly to driver
2014-07-11 01:32:19,822 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Finished task ID 280
2014-07-11 01:32:19,826 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 280 in 9048731 ms on dco-node121-mgt.dco.ethz.ch (progress: 324/497)
2014-07-11 01:32:19,826 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 279)
2014-07-11 01:32:23,884 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 294 in 8888845 ms on dco-node124-mgt.dco.ethz.ch (progress: 325/497)
2014-07-11 01:32:23,884 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 293)
2014-07-11 01:32:26,225 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 329 in 8577075 ms on dco-node123-mgt.dco.ethz.ch (progress: 326/497)
2014-07-11 01:32:26,225 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 328)
2014-07-11 01:32:39,918 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 360 in 8307843 ms on dco-node126-mgt.dco.ethz.ch (progress: 327/497)
2014-07-11 01:32:39,918 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 359)
2014-07-11 01:32:46,960 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 376 in 8159379 ms on dco-node128-mgt.dco.ethz.ch (progress: 328/497)
2014-07-11 01:32:46,960 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 375)
2014-07-11 01:32:57,177 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 271 in 9201682 ms on dco-node131-mgt.dco.ethz.ch (progress: 329/497)
2014-07-11 01:32:57,177 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 270)
2014-07-11 01:33:15,189 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Serialized size of result for 311 is 535
2014-07-11 01:33:15,189 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Sending result for 311 directly to driver
2014-07-11 01:33:15,189 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Finished task ID 311
2014-07-11 01:33:15,193 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 311 in 8785010 ms on dco-node121-mgt.dco.ethz.ch (progress: 330/497)
2014-07-11 01:33:15,193 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 310)
2014-07-11 01:33:34,076 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 332 in 8633251 ms on dco-node126-mgt.dco.ethz.ch (progress: 331/497)
2014-07-11 01:33:34,076 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 331)
2014-07-11 01:33:36,611 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 297 in 8950480 ms on dco-node129-mgt.dco.ethz.ch (progress: 332/497)
2014-07-11 01:33:36,611 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 296)
2014-07-11 01:33:45,785 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 364 in 8345200 ms on dco-node126-mgt.dco.ethz.ch (progress: 333/497)
2014-07-11 01:33:45,785 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 363)
2014-07-11 01:34:12,839 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 328 is 535
2014-07-11 01:34:12,839 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 328 directly to driver
2014-07-11 01:34:12,839 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 328
2014-07-11 01:34:12,843 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 328 in 8690940 ms on dco-node121-mgt.dco.ethz.ch (progress: 334/497)
2014-07-11 01:34:12,843 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 327)
2014-07-11 01:34:17,780 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 319 in 8792317 ms on dco-node133-mgt.dco.ethz.ch (progress: 335/497)
2014-07-11 01:34:17,780 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 318)
2014-07-11 01:34:24,879 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 381 in 8201931 ms on dco-node126-mgt.dco.ethz.ch (progress: 336/497)
2014-07-11 01:34:24,879 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 380)
2014-07-11 01:34:35,454 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 368 in 8341433 ms on dco-node131-mgt.dco.ethz.ch (progress: 337/497)
2014-07-11 01:34:35,454 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 367)
2014-07-11 01:34:42,970 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 355 in 8462419 ms on dco-node123-mgt.dco.ethz.ch (progress: 338/497)
2014-07-11 01:34:42,970 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 354)
2014-07-11 01:35:08,969 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 326 in 8802370 ms on dco-node131-mgt.dco.ethz.ch (progress: 339/497)
2014-07-11 01:35:08,969 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 325)
2014-07-11 01:35:31,627 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 321)
2014-07-11 01:35:31,627 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 322 in 8846495 ms on dco-node132-mgt.dco.ethz.ch (progress: 340/497)
2014-07-11 01:35:37,802 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 409 in 7872339 ms on dco-node128-mgt.dco.ethz.ch (progress: 341/497)
2014-07-11 01:35:37,802 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 408)
2014-07-11 01:36:06,804 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 316 in 8937514 ms on dco-node133-mgt.dco.ethz.ch (progress: 342/497)
2014-07-11 01:36:06,804 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 315)
2014-07-11 01:36:09,521 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 304 in 9034398 ms on dco-node124-mgt.dco.ethz.ch (progress: 343/497)
2014-07-11 01:36:09,521 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 303)
2014-07-11 01:36:15,021 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 345 in 8621419 ms on dco-node132-mgt.dco.ethz.ch (progress: 344/497)
2014-07-11 01:36:15,021 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 344)
2014-07-11 01:36:28,689 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 307)
2014-07-11 01:36:28,689 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 308 in 9007101 ms on dco-node129-mgt.dco.ethz.ch (progress: 345/497)
2014-07-11 01:36:37,212 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 344 in 8650596 ms on dco-node133-mgt.dco.ethz.ch (progress: 346/497)
2014-07-11 01:36:37,212 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 343)
2014-07-11 01:37:16,219 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 309 in 9046195 ms on dco-node132-mgt.dco.ethz.ch (progress: 347/497)
2014-07-11 01:37:16,219 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 308)
2014-07-11 01:37:17,850 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Serialized size of result for 396 is 535
2014-07-11 01:37:17,850 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Sending result for 396 directly to driver
2014-07-11 01:37:17,850 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Finished task ID 396
2014-07-11 01:37:17,853 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 396 in 8120065 ms on dco-node121-mgt.dco.ethz.ch (progress: 348/497)
2014-07-11 01:37:17,853 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 395)
2014-07-11 01:37:20,913 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 388 in 8269739 ms on dco-node123-mgt.dco.ethz.ch (progress: 349/497)
2014-07-11 01:37:20,913 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 387)
2014-07-11 01:37:23,037 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 389 in 8256074 ms on dco-node123-mgt.dco.ethz.ch (progress: 350/497)
2014-07-11 01:37:23,037 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 388)
2014-07-11 01:37:29,955 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 326)
2014-07-11 01:37:29,955 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 327 in 8919641 ms on dco-node129-mgt.dco.ethz.ch (progress: 351/497)
2014-07-11 01:37:38,721 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 407 in 7998823 ms on dco-node128-mgt.dco.ethz.ch (progress: 352/497)
2014-07-11 01:37:38,721 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 406)
2014-07-11 01:37:43,112 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 380 in 8404447 ms on dco-node131-mgt.dco.ethz.ch (progress: 353/497)
2014-07-11 01:37:43,112 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 379)
2014-07-11 01:37:58,388 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 378 in 8463966 ms on dco-node131-mgt.dco.ethz.ch (progress: 354/497)
2014-07-11 01:37:58,388 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 377)
2014-07-11 01:38:00,673 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 305 in 9138967 ms on dco-node124-mgt.dco.ethz.ch (progress: 355/497)
2014-07-11 01:38:00,673 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 304)
2014-07-11 01:38:10,639 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 316)
2014-07-11 01:38:10,639 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 317 in 9039289 ms on dco-node129-mgt.dco.ethz.ch (progress: 356/497)
2014-07-11 01:38:25,981 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 356 in 8677888 ms on dco-node129-mgt.dco.ethz.ch (progress: 357/497)
2014-07-11 01:38:25,981 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 355)
2014-07-11 01:38:30,356 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 398)
2014-07-11 01:38:30,356 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 399 in 8173743 ms on dco-node128-mgt.dco.ethz.ch (progress: 358/497)
2014-07-11 01:38:30,786 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 379 in 8470052 ms on dco-node125-mgt.dco.ethz.ch (progress: 359/497)
2014-07-11 01:38:30,786 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 378)
2014-07-11 01:38:33,762 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 426 in 7833169 ms on dco-node133-mgt.dco.ethz.ch (progress: 360/497)
2014-07-11 01:38:33,762 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 425)
2014-07-11 01:38:36,852 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 336)
2014-07-11 01:38:36,852 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 337 in 8874019 ms on dco-node133-mgt.dco.ethz.ch (progress: 361/497)
2014-07-11 01:38:47,936 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 391 in 8305367 ms on dco-node126-mgt.dco.ethz.ch (progress: 362/497)
2014-07-11 01:38:47,936 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 390)
2014-07-11 01:39:06,178 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 336 in 8940321 ms on dco-node128-mgt.dco.ethz.ch (progress: 363/497)
2014-07-11 01:39:06,178 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 335)
2014-07-11 01:39:10,929 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 319)
2014-07-11 01:39:10,929 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 320 in 9076772 ms on dco-node132-mgt.dco.ethz.ch (progress: 364/497)
2014-07-11 01:39:18,545 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 441 in 7704260 ms on dco-node133-mgt.dco.ethz.ch (progress: 365/497)
2014-07-11 01:39:18,545 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 440)
2014-07-11 01:39:28,346 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 347 in 8803231 ms on dco-node130-mgt.dco.ethz.ch (progress: 366/497)
2014-07-11 01:39:28,346 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 346)
2014-07-11 01:39:31,525 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 445 is 535
2014-07-11 01:39:31,525 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 445 directly to driver
2014-07-11 01:39:31,526 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 445
2014-07-11 01:39:31,530 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 445 in 7653775 ms on dco-node121-mgt.dco.ethz.ch (progress: 367/497)
2014-07-11 01:39:31,530 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 444)
2014-07-11 01:39:33,468 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 362)
2014-07-11 01:39:33,468 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 363 in 8709690 ms on dco-node131-mgt.dco.ethz.ch (progress: 368/497)
2014-07-11 01:39:44,076 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 421 in 7965558 ms on dco-node126-mgt.dco.ethz.ch (progress: 369/497)
2014-07-11 01:39:44,076 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 420)
2014-07-11 01:40:17,570 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 335 in 9015035 ms on dco-node128-mgt.dco.ethz.ch (progress: 370/497)
2014-07-11 01:40:17,570 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 334)
2014-07-11 01:40:22,862 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 402 in 8199807 ms on dco-node126-mgt.dco.ethz.ch (progress: 371/497)
2014-07-11 01:40:22,862 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 401)
2014-07-11 01:40:22,870 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 437 in 7782486 ms on dco-node133-mgt.dco.ethz.ch (progress: 372/497)
2014-07-11 01:40:22,870 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 436)
2014-07-11 01:40:35,194 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 451)
2014-07-11 01:40:35,194 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 452 in 7550803 ms on dco-node123-mgt.dco.ethz.ch (progress: 373/497)
2014-07-11 01:40:40,729 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 353 in 8828196 ms on dco-node129-mgt.dco.ethz.ch (progress: 374/497)
2014-07-11 01:40:40,729 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 352)
2014-07-11 01:40:48,275 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Serialized size of result for 471 is 535
2014-07-11 01:40:48,276 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Sending result for 471 directly to driver
2014-07-11 01:40:48,276 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Finished task ID 471
2014-07-11 01:40:48,279 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 471 in 7216560 ms on dco-node121-mgt.dco.ethz.ch (progress: 375/497)
2014-07-11 01:40:48,279 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 470)
2014-07-11 01:40:48,554 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 477 in 7028366 ms on dco-node128-mgt.dco.ethz.ch (progress: 376/497)
2014-07-11 01:40:48,554 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 476)
2014-07-11 01:40:59,920 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 370 in 8699208 ms on dco-node132-mgt.dco.ethz.ch (progress: 377/497)
2014-07-11 01:40:59,920 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 369)
2014-07-11 01:41:00,079 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 393)
2014-07-11 01:41:00,079 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 394 in 8351258 ms on dco-node126-mgt.dco.ethz.ch (progress: 378/497)
2014-07-11 01:41:09,786 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 358 in 8828659 ms on dco-node125-mgt.dco.ethz.ch (progress: 379/497)
2014-07-11 01:41:09,786 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 357)
2014-07-11 01:41:18,520 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 333 in 9093187 ms on dco-node124-mgt.dco.ethz.ch (progress: 380/497)
2014-07-11 01:41:18,520 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 332)
2014-07-11 01:41:21,329 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 346 in 8925128 ms on dco-node130-mgt.dco.ethz.ch (progress: 381/497)
2014-07-11 01:41:21,329 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 345)
2014-07-11 01:41:21,425 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Serialized size of result for 395 is 535
2014-07-11 01:41:21,425 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Sending result for 395 directly to driver
2014-07-11 01:41:21,426 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Finished task ID 395
2014-07-11 01:41:21,429 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 395 in 8366006 ms on dco-node121-mgt.dco.ethz.ch (progress: 382/497)
2014-07-11 01:41:21,429 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 394)
2014-07-11 01:41:37,916 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 371 in 8730524 ms on dco-node136-mgt.dco.ethz.ch (progress: 383/497)
2014-07-11 01:41:37,916 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 370)
2014-07-11 01:41:39,515 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 362 in 8845086 ms on dco-node124-mgt.dco.ethz.ch (progress: 384/497)
2014-07-11 01:41:39,515 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 361)
2014-07-11 01:41:41,788 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 357 in 8865093 ms on dco-node129-mgt.dco.ethz.ch (progress: 385/497)
2014-07-11 01:41:41,789 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 356)
2014-07-11 01:41:45,291 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 337)
2014-07-11 01:41:45,291 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 338 in 9045797 ms on dco-node131-mgt.dco.ethz.ch (progress: 386/497)
2014-07-11 01:41:46,571 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 359 in 8858082 ms on dco-node125-mgt.dco.ethz.ch (progress: 387/497)
2014-07-11 01:41:46,571 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 358)
2014-07-11 01:41:49,511 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 367 in 8792714 ms on dco-node125-mgt.dco.ethz.ch (progress: 388/497)
2014-07-11 01:41:49,511 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 366)
2014-07-11 01:41:52,146 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 467 in 7353663 ms on dco-node130-mgt.dco.ethz.ch (progress: 389/497)
2014-07-11 01:41:52,146 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 466)
2014-07-11 01:41:55,197 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 417 in 8185213 ms on dco-node123-mgt.dco.ethz.ch (progress: 390/497)
2014-07-11 01:41:55,197 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 416)
2014-07-11 01:42:11,131 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 386 in 8578018 ms on dco-node130-mgt.dco.ethz.ch (progress: 391/497)
2014-07-11 01:42:11,131 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 385)
2014-07-11 01:42:15,561 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 343 in 8996135 ms on dco-node123-mgt.dco.ethz.ch (progress: 392/497)
2014-07-11 01:42:15,561 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 342)
2014-07-11 01:42:16,361 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 415 in 8222837 ms on dco-node131-mgt.dco.ethz.ch (progress: 393/497)
2014-07-11 01:42:16,361 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 414)
2014-07-11 01:42:23,679 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 438 in 7898077 ms on dco-node130-mgt.dco.ethz.ch (progress: 394/497)
2014-07-11 01:42:23,680 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 437)
2014-07-11 01:42:32,130 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 442 in 7838900 ms on dco-node130-mgt.dco.ethz.ch (progress: 395/497)
2014-07-11 01:42:32,130 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 441)
2014-07-11 01:42:35,161 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 334 in 9158220 ms on dco-node126-mgt.dco.ethz.ch (progress: 396/497)
2014-07-11 01:42:35,161 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 333)
2014-07-11 01:42:35,945 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 377 in 8747265 ms on dco-node129-mgt.dco.ethz.ch (progress: 397/497)
2014-07-11 01:42:35,945 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 376)
2014-07-11 01:42:45,113 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 340 in 9064145 ms on dco-node130-mgt.dco.ethz.ch (progress: 398/497)
2014-07-11 01:42:45,113 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 339)
2014-07-11 01:42:46,397 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 436 in 7947935 ms on dco-node123-mgt.dco.ethz.ch (progress: 399/497)
2014-07-11 01:42:46,397 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 435)
2014-07-11 01:42:55,471 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 486)
2014-07-11 01:42:55,471 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 487 in 6593228 ms on dco-node133-mgt.dco.ethz.ch (progress: 400/497)
2014-07-11 01:42:56,930 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 453 in 7686992 ms on dco-node131-mgt.dco.ethz.ch (progress: 401/497)
2014-07-11 01:42:56,930 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 452)
2014-07-11 01:43:23,489 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 392 in 8542017 ms on dco-node125-mgt.dco.ethz.ch (progress: 402/497)
2014-07-11 01:43:23,489 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 391)
2014-07-11 01:43:41,913 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 414 in 8316957 ms on dco-node132-mgt.dco.ethz.ch (progress: 403/497)
2014-07-11 01:43:41,913 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 413)
2014-07-11 01:43:42,314 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 429 in 8118031 ms on dco-node131-mgt.dco.ethz.ch (progress: 404/497)
2014-07-11 01:43:42,314 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 428)
2014-07-11 01:43:45,098 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 447 in 7902494 ms on dco-node132-mgt.dco.ethz.ch (progress: 405/497)
2014-07-11 01:43:45,098 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 446)
2014-07-11 01:43:51,965 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 366 in 8922370 ms on dco-node124-mgt.dco.ethz.ch (progress: 406/497)
2014-07-11 01:43:51,965 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 365)
2014-07-11 01:43:53,722 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 484 in 6804244 ms on dco-node130-mgt.dco.ethz.ch (progress: 407/497)
2014-07-11 01:43:53,722 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 483)
2014-07-11 01:43:54,232 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 374 in 8828846 ms on dco-node136-mgt.dco.ethz.ch (progress: 408/497)
2014-07-11 01:43:54,232 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 373)
2014-07-11 01:44:07,099 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 373 in 8842944 ms on dco-node136-mgt.dco.ethz.ch (progress: 409/497)
2014-07-11 01:44:07,099 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 372)
2014-07-11 01:44:08,164 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 349)
2014-07-11 01:44:08,164 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 350 in 9053621 ms on dco-node123-mgt.dco.ethz.ch (progress: 410/497)
2014-07-11 01:44:20,114 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 339 in 9189288 ms on dco-node129-mgt.dco.ethz.ch (progress: 411/497)
2014-07-11 01:44:20,114 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 338)
2014-07-11 01:44:26,122 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 411)
2014-07-11 01:44:26,122 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 412 in 8378630 ms on dco-node132-mgt.dco.ethz.ch (progress: 412/497)
2014-07-11 01:44:31,082 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 410 in 8403491 ms on dco-node124-mgt.dco.ethz.ch (progress: 413/497)
2014-07-11 01:44:31,082 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 409)
2014-07-11 01:44:45,805 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 393 in 8603218 ms on dco-node124-mgt.dco.ethz.ch (progress: 414/497)
2014-07-11 01:44:45,805 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 392)
2014-07-11 01:44:47,666 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 470 in 7462763 ms on dco-node132-mgt.dco.ethz.ch (progress: 415/497)
2014-07-11 01:44:47,666 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 469)
2014-07-11 01:45:01,490 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 458 in 7785633 ms on dco-node129-mgt.dco.ethz.ch (progress: 416/497)
2014-07-11 01:45:01,490 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 457)
2014-07-11 01:45:11,555 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 390 in 8692828 ms on dco-node125-mgt.dco.ethz.ch (progress: 417/497)
2014-07-11 01:45:11,555 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 389)
2014-07-11 01:45:34,165 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 385 in 8793348 ms on dco-node125-mgt.dco.ethz.ch (progress: 418/497)
2014-07-11 01:45:34,165 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 384)
2014-07-11 01:45:36,966 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 361 in 9082871 ms on dco-node136-mgt.dco.ethz.ch (progress: 419/497)
2014-07-11 01:45:36,966 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 360)
2014-07-11 01:45:54,699 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 433 in 8185171 ms on dco-node125-mgt.dco.ethz.ch (progress: 420/497)
2014-07-11 01:45:54,699 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 432)
2014-07-11 01:45:58,416 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 501 in 4797412 ms on dco-node128-mgt.dco.ethz.ch (progress: 421/497)
2014-07-11 01:45:58,416 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 297)
2014-07-11 01:46:01,751 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 430 in 8245056 ms on dco-node125-mgt.dco.ethz.ch (progress: 422/497)
2014-07-11 01:46:01,751 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 429)
2014-07-11 01:46:03,225 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 341 in 9258541 ms on dco-node124-mgt.dco.ethz.ch (progress: 423/497)
2014-07-11 01:46:03,225 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 340)
2014-07-11 01:46:04,900 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 428 in 8280322 ms on dco-node124-mgt.dco.ethz.ch (progress: 424/497)
2014-07-11 01:46:04,900 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 427)
2014-07-11 01:46:06,117 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 480 in 7281104 ms on dco-node132-mgt.dco.ethz.ch (progress: 425/497)
2014-07-11 01:46:06,117 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 479)
2014-07-11 01:46:23,122 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 455 in 7887732 ms on dco-node125-mgt.dco.ethz.ch (progress: 426/497)
2014-07-11 01:46:23,122 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 454)
2014-07-11 01:46:24,450 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 468 in 7595589 ms on dco-node125-mgt.dco.ethz.ch (progress: 427/497)
2014-07-11 01:46:24,450 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 467)
2014-07-11 01:46:29,557 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 401 in 8607726 ms on dco-node124-mgt.dco.ethz.ch (progress: 428/497)
2014-07-11 01:46:29,557 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 400)
2014-07-11 01:46:29,641 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 493 in 6625428 ms on dco-node126-mgt.dco.ethz.ch (progress: 429/497)
2014-07-11 01:46:29,641 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 492)
2014-07-11 01:46:32,083 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 457 in 7889077 ms on dco-node124-mgt.dco.ethz.ch (progress: 430/497)
2014-07-11 01:46:32,083 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 456)
2014-07-11 01:46:50,340 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 351 in 9214144 ms on dco-node136-mgt.dco.ethz.ch (progress: 431/497)
2014-07-11 01:46:50,340 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 350)
2014-07-11 01:46:52,041 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 486 in 6930522 ms on dco-node129-mgt.dco.ethz.ch (progress: 432/497)
2014-07-11 01:46:52,041 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 485)
2014-07-11 01:47:05,574 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 499 in 5003471 ms on dco-node123-mgt.dco.ethz.ch (progress: 433/497)
2014-07-11 01:47:05,574 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 320)
2014-07-11 01:47:12,900 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 476 in 7417813 ms on dco-node125-mgt.dco.ethz.ch (progress: 434/497)
2014-07-11 01:47:12,900 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 475)
2014-07-11 01:47:14,258 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 372 in 9066095 ms on dco-node136-mgt.dco.ethz.ch (progress: 435/497)
2014-07-11 01:47:14,258 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 371)
2014-07-11 01:47:14,616 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 492 in 6729271 ms on dco-node131-mgt.dco.ethz.ch (progress: 436/497)
2014-07-11 01:47:14,616 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 491)
2014-07-11 01:47:26,959 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 403 in 8619168 ms on dco-node125-mgt.dco.ethz.ch (progress: 437/497)
2014-07-11 01:47:26,959 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 402)
2014-07-11 01:47:50,683 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 498 in 5090063 ms on dco-node126-mgt.dco.ethz.ch (progress: 438/497)
2014-07-11 01:47:50,683 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 412)
2014-07-11 01:48:11,594 [spark-akka.actor.default-dispatcher-42] WARN  org.apache.spark.storage.BlockManagerMasterActor - Removing BlockManager BlockManagerId(12, dco-node132-mgt.dco.ethz.ch, 52218, 0) with no recent heart beats: 69401ms exceeds 45000ms
2014-07-11 01:48:32,927 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 422 in 8472134 ms on dco-node122-mgt.dco.ethz.ch (progress: 439/497)
2014-07-11 01:48:32,927 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 421)
2014-07-11 01:48:38,084 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 484)
2014-07-11 01:48:38,084 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 485 in 7046707 ms on dco-node129-mgt.dco.ethz.ch (progress: 440/497)
2014-07-11 01:48:48,375 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 415)
2014-07-11 01:48:48,376 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 416 in 8609233 ms on dco-node136-mgt.dco.ethz.ch (progress: 441/497)
2014-07-11 01:48:52,391 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 342 in 9402041 ms on dco-node136-mgt.dco.ethz.ch (progress: 442/497)
2014-07-11 01:48:52,391 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 341)
2014-07-11 01:48:59,308 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 418)
2014-07-11 01:48:59,308 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 419 in 8569166 ms on dco-node136-mgt.dco.ethz.ch (progress: 443/497)
2014-07-11 01:49:21,844 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 404 in 8710292 ms on dco-node135-mgt.dco.ethz.ch (progress: 444/497)
2014-07-11 01:49:21,844 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 403)
2014-07-11 01:49:28,701 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 423 in 8526057 ms on dco-node136-mgt.dco.ethz.ch (progress: 445/497)
2014-07-11 01:49:28,701 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 422)
2014-07-11 01:49:33,277 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 482 in 7380054 ms on dco-node124-mgt.dco.ethz.ch (progress: 446/497)
2014-07-11 01:49:33,277 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 481)
2014-07-11 01:49:40,508 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 475 in 7600546 ms on dco-node136-mgt.dco.ethz.ch (progress: 447/497)
2014-07-11 01:49:40,508 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 474)
2014-07-11 01:49:47,135 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 496 in 6745360 ms on dco-node129-mgt.dco.ethz.ch (progress: 448/497)
2014-07-11 01:49:47,135 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 495)
2014-07-11 01:49:52,835 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node132-mgt.dco.ethz.ch:52218 with 40.3 GB RAM
2014-07-11 01:49:57,543 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 420 in 8611285 ms on dco-node136-mgt.dco.ethz.ch (progress: 449/497)
2014-07-11 01:49:57,543 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 419)
2014-07-11 01:50:03,251 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 446 in 8281747 ms on dco-node136-mgt.dco.ethz.ch (progress: 450/497)
2014-07-11 01:50:03,251 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 445)
2014-07-11 01:50:17,544 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 456 in 8119330 ms on dco-node135-mgt.dco.ethz.ch (progress: 451/497)
2014-07-11 01:50:17,544 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 455)
2014-07-11 01:50:35,070 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 432 in 8498164 ms on dco-node135-mgt.dco.ethz.ch (progress: 452/497)
2014-07-11 01:50:35,070 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 431)
2014-07-11 01:51:03,077 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 473 in 7755440 ms on dco-node135-mgt.dco.ethz.ch (progress: 453/497)
2014-07-11 01:51:03,077 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 472)
2014-07-11 01:51:03,926 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 434 in 8492765 ms on dco-node135-mgt.dco.ethz.ch (progress: 454/497)
2014-07-11 01:51:03,926 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 433)
2014-07-11 01:51:05,594 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 425 in 8595241 ms on dco-node135-mgt.dco.ethz.ch (progress: 455/497)
2014-07-11 01:51:05,594 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 424)
2014-07-11 01:51:10,168 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 472 in 7838024 ms on dco-node135-mgt.dco.ethz.ch (progress: 456/497)
2014-07-11 01:51:10,168 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 471)
2014-07-11 01:51:11,594 [spark-akka.actor.default-dispatcher-37] WARN  org.apache.spark.storage.BlockManagerMasterActor - Removing BlockManager BlockManagerId(12, dco-node132-mgt.dco.ethz.ch, 52218, 0) with no recent heart beats: 78651ms exceeds 45000ms
2014-07-11 01:51:12,145 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 406 in 8814054 ms on dco-node135-mgt.dco.ethz.ch (progress: 457/497)
2014-07-11 01:51:12,145 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 405)
2014-07-11 01:51:16,403 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 461 in 8036177 ms on dco-node135-mgt.dco.ethz.ch (progress: 458/497)
2014-07-11 01:51:16,403 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 460)
2014-07-11 01:51:19,278 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 454 in 8188528 ms on dco-node127-mgt.dco.ethz.ch (progress: 459/497)
2014-07-11 01:51:19,278 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 453)
2014-07-11 01:51:49,728 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 405 in 8852641 ms on dco-node127-mgt.dco.ethz.ch (progress: 460/497)
2014-07-11 01:51:49,728 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 404)
2014-07-11 01:51:58,219 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 443 in 8403164 ms on dco-node135-mgt.dco.ethz.ch (progress: 461/497)
2014-07-11 01:51:58,219 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 442)
2014-07-11 01:52:02,304 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 400 in 8971511 ms on dco-node135-mgt.dco.ethz.ch (progress: 462/497)
2014-07-11 01:52:02,304 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 399)
2014-07-11 01:52:08,713 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 491 in 7054315 ms on dco-node135-mgt.dco.ethz.ch (progress: 463/497)
2014-07-11 01:52:08,713 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 490)
2014-07-11 01:52:09,996 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 447)
2014-07-11 01:52:09,996 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 448 in 8357871 ms on dco-node127-mgt.dco.ethz.ch (progress: 464/497)
2014-07-11 01:52:20,336 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 411 in 8867595 ms on dco-node122-mgt.dco.ethz.ch (progress: 465/497)
2014-07-11 01:52:20,336 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 410)
2014-07-11 01:52:24,477 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 465)
2014-07-11 01:52:24,477 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 466 in 8005836 ms on dco-node127-mgt.dco.ethz.ch (progress: 466/497)
2014-07-11 01:52:31,854 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 348 in 9566067 ms on dco-node136-mgt.dco.ethz.ch (progress: 467/497)
2014-07-11 01:52:31,854 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 347)
2014-07-11 01:52:36,004 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 397 in 9036870 ms on dco-node135-mgt.dco.ethz.ch (progress: 468/497)
2014-07-11 01:52:36,004 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 396)
2014-07-11 01:52:53,254 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 464 in 8046154 ms on dco-node127-mgt.dco.ethz.ch (progress: 469/497)
2014-07-11 01:52:53,254 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 463)
2014-07-11 01:52:57,711 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 480)
2014-07-11 01:52:57,711 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 481 in 7623102 ms on dco-node127-mgt.dco.ethz.ch (progress: 470/497)
2014-07-11 01:53:11,695 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 460 in 8217463 ms on dco-node122-mgt.dco.ethz.ch (progress: 471/497)
2014-07-11 01:53:11,695 [spark-akka.actor.default-dispatcher-19] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 459)
2014-07-11 01:53:13,077 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 408 in 8931533 ms on dco-node122-mgt.dco.ethz.ch (progress: 472/497)
2014-07-11 01:53:13,077 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 407)
2014-07-11 01:53:31,302 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node132-mgt.dco.ethz.ch:52218 with 40.3 GB RAM
2014-07-11 01:53:38,632 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 444 in 8502938 ms on dco-node122-mgt.dco.ethz.ch (progress: 473/497)
2014-07-11 01:53:38,632 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 443)
2014-07-11 01:53:39,838 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 465 in 8086156 ms on dco-node127-mgt.dco.ethz.ch (progress: 474/497)
2014-07-11 01:53:39,838 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 464)
2014-07-11 01:53:46,922 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 450 in 8432250 ms on dco-node122-mgt.dco.ethz.ch (progress: 475/497)
2014-07-11 01:53:46,922 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 449)
2014-07-11 01:53:47,279 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 478 in 7803792 ms on dco-node136-mgt.dco.ethz.ch (progress: 476/497)
2014-07-11 01:53:47,279 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 477)
2014-07-11 01:53:49,070 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 431 in 8699420 ms on dco-node127-mgt.dco.ethz.ch (progress: 477/497)
2014-07-11 01:53:49,070 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 430)
2014-07-11 01:54:07,229 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 469 in 8031568 ms on dco-node127-mgt.dco.ethz.ch (progress: 478/497)
2014-07-11 01:54:07,229 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 468)
2014-07-11 01:54:10,547 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 495 in 7042940 ms on dco-node135-mgt.dco.ethz.ch (progress: 479/497)
2014-07-11 01:54:10,547 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 494)
2014-07-11 01:54:13,736 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 483 in 7433818 ms on dco-node127-mgt.dco.ethz.ch (progress: 480/497)
2014-07-11 01:54:13,736 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 482)
2014-07-11 01:54:14,281 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 449 in 8481038 ms on dco-node127-mgt.dco.ethz.ch (progress: 481/497)
2014-07-11 01:54:14,281 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 448)
2014-07-11 01:54:16,478 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 398 in 9126024 ms on dco-node122-mgt.dco.ethz.ch (progress: 482/497)
2014-07-11 01:54:16,478 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 397)
2014-07-11 01:54:17,795 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 458)
2014-07-11 01:54:17,795 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 459 in 8287846 ms on dco-node122-mgt.dco.ethz.ch (progress: 483/497)
2014-07-11 01:54:27,480 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 500 in 5310315 ms on dco-node124-mgt.dco.ethz.ch (progress: 484/497)
2014-07-11 01:54:27,480 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 417)
2014-07-11 01:54:31,114 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 439 in 8621713 ms on dco-node127-mgt.dco.ethz.ch (progress: 485/497)
2014-07-11 01:54:31,114 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 438)
2014-07-11 01:54:32,931 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 462 in 8197331 ms on dco-node127-mgt.dco.ethz.ch (progress: 486/497)
2014-07-11 01:54:32,931 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 461)
2014-07-11 01:54:37,879 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 427 in 8795078 ms on dco-node122-mgt.dco.ethz.ch (progress: 487/497)
2014-07-11 01:54:37,879 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 426)
2014-07-11 01:54:43,504 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 502 in 5316927 ms on dco-node136-mgt.dco.ethz.ch (progress: 488/497)
2014-07-11 01:54:43,504 [spark-akka.actor.default-dispatcher-40] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 312)
2014-07-11 01:55:16,316 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 494 in 7137800 ms on dco-node127-mgt.dco.ethz.ch (progress: 489/497)
2014-07-11 01:55:16,316 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 493)
2014-07-11 01:55:26,780 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 440 in 8675559 ms on dco-node122-mgt.dco.ethz.ch (progress: 490/497)
2014-07-11 01:55:26,780 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 439)
2014-07-11 01:55:44,564 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 451 in 8501383 ms on dco-node122-mgt.dco.ethz.ch (progress: 491/497)
2014-07-11 01:55:44,564 [spark-akka.actor.default-dispatcher-39] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 450)
2014-07-11 01:55:51,856 [Result resolver thread-2] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 424 in 8886437 ms on dco-node122-mgt.dco.ethz.ch (progress: 492/497)
2014-07-11 01:55:51,856 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 423)
2014-07-11 01:55:56,221 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 435 in 8759050 ms on dco-node122-mgt.dco.ethz.ch (progress: 493/497)
2014-07-11 01:55:56,221 [spark-akka.actor.default-dispatcher-41] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 434)
2014-07-11 01:56:13,480 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 488 in 7352771 ms on dco-node127-mgt.dco.ethz.ch (progress: 494/497)
2014-07-11 01:56:13,480 [spark-akka.actor.default-dispatcher-33] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 487)
2014-07-11 01:56:40,923 [Result resolver thread-1] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 463 in 8297716 ms on dco-node122-mgt.dco.ethz.ch (progress: 495/497)
2014-07-11 01:56:40,923 [spark-akka.actor.default-dispatcher-28] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 462)
2014-07-11 01:56:40,981 [Result resolver thread-2] WARN  org.apache.spark.scheduler.TaskSetManager - Lost TID 503 (task 0.0:256)
2014-07-11 01:56:40,982 [Result resolver thread-2] WARN  org.apache.spark.scheduler.TaskSetManager - Loss was due to org.apache.hadoop.ipc.RemoteException
org.apache.hadoop.ipc.RemoteException(java.lang.ArrayIndexOutOfBoundsException): 0
	at org.apache.hadoop.hdfs.server.blockmanagement.DatanodeManager.getDatanodeStorageInfos(DatanodeManager.java:473)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipelineInternal(FSNamesystem.java:6006)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.updatePipeline(FSNamesystem.java:5969)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.updatePipeline(NameNodeRpcServer.java:666)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.updatePipeline(ClientNamenodeProtocolServerSideTranslatorPB.java:889)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:585)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:928)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2013)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2009)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1548)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2007)

	at org.apache.hadoop.ipc.Client.call(Client.java:1347)
	at org.apache.hadoop.ipc.Client.call(Client.java:1300)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:206)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:186)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)
	at com.sun.proxy.$Proxy12.updatePipeline(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.updatePipeline(ClientNamenodeProtocolTranslatorPB.java:791)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.setupPipelineForAppendOrRecovery(DFSOutputStream.java:1047)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.processDatanodeError(DFSOutputStream.java:823)
	at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:475)
2014-07-11 01:56:40,982 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Starting task 0.0:256 as TID 504 on executor 14: dco-node136-mgt.dco.ethz.ch (PROCESS_LOCAL)
2014-07-11 01:56:40,982 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.TaskSetManager - Serialized task 0.0:256 as 6474 bytes in 0 ms
2014-07-11 01:56:53,930 [Result resolver thread-3] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 489 in 7376128 ms on dco-node122-mgt.dco.ethz.ch (progress: 496/497)
2014-07-11 01:56:53,930 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 488)
2014-07-11 02:13:27,653 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSetManager - Finished TID 504 in 1006670 ms on dco-node136-mgt.dco.ethz.ch (progress: 497/497)
2014-07-11 02:13:27,653 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Completed ResultTask(0, 256)
2014-07-11 02:13:27,656 [Result resolver thread-0] INFO  org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2014-07-11 02:13:27,657 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.scheduler.DAGScheduler - Stage 0 (foreach at HtmlToTextConversionApp.scala:57) finished in 19771.326 s
2014-07-11 02:13:27,678 [main] INFO  org.apache.spark.SparkContext - Job finished: foreach at HtmlToTextConversionApp.scala:57, took 19771.458784568 s
2014-07-11 02:13:28,325 [sparkExecutor-akka.actor.default-dispatcher-22] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - Driver Disassociated [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705] disassociated! Shutting down.
2014-07-11 02:13:28,326 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705 got disassociated, removing it.
2014-07-11 02:13:28,332 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140710203813-0000
2014-07-11 02:13:28,341 [sparkMaster-akka.actor.default-dispatcher-42] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A57966-17#2126083678] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-11 02:13:28,394 [sparkMaster-akka.actor.default-dispatcher-41] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:41705
]
2014-07-11 02:13:28,403 [sparkMaster-akka.actor.default-dispatcher-13] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:41705
]
2014-07-11 02:13:28,412 [sparkMaster-akka.actor.default-dispatcher-41] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:41705
]
2014-07-11 02:13:28,741 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-11 02:13:29,608 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-11 02:13:29,608 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-11 02:13:30,509 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705 got disassociated, removing it.
2014-07-11 02:13:30,510 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705 got disassociated, removing it.
2014-07-11 02:13:30,510 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705 got disassociated, removing it.
2014-07-11 02:13:30,510 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:41705 got disassociated, removing it.
2014-07-11 02:13:30,513 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/5
2014-07-11 02:13:30,514 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/10
2014-07-11 02:13:30,514 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/2
2014-07-11 02:13:30,514 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/3
2014-07-11 02:13:30,514 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/8
2014-07-11 02:13:30,514 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/15
2014-07-11 02:13:30,514 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/0
2014-07-11 02:13:30,514 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/4
2014-07-11 02:13:30,515 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/11
2014-07-11 02:13:30,515 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/13
2014-07-11 02:13:30,515 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/12
2014-07-11 02:13:30,515 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/7
2014-07-11 02:13:30,515 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/14
2014-07-11 02:13:30,515 [sparkMaster-akka.actor.default-dispatcher-39] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/6
2014-07-11 02:13:30,525 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140710203813-0000/9
2014-07-11 02:13:30,527 [ExecutorRunner for app-20140710203813-0000/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140710203813-0000/9 interrupted
2014-07-11 02:13:30,528 [ExecutorRunner for app-20140710203813-0000/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-11 02:13:30,529 [sparkMaster-akka.actor.default-dispatcher-38] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/9
2014-07-11 02:13:30,536 [sparkMaster-akka.actor.default-dispatcher-16] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140710203813-0000/1
2014-07-11 02:13:30,536 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140710203813-0000/9 finished with state KILLED
2014-07-11 02:13:32,618 [sparkWorker-akka.actor.default-dispatcher-4] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A47832-2#148573927] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-11 02:13:32,640 [sparkWorker-akka.actor.default-dispatcher-6] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:55092
]
2014-07-11 02:13:32,647 [sparkWorker-akka.actor.default-dispatcher-6] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:55092
]
2014-07-11 02:13:32,666 [sparkWorker-akka.actor.default-dispatcher-4] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55092]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:55092
]
2014-07-11 14:10:07,898 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Registering app Simple Application
2014-07-11 14:10:07,899 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Registered app Simple Application with ID app-20140711141007-0001
2014-07-11 14:10:07,900 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-11 14:10:07,901 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-11 14:10:07,902 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-11 14:10:07,902 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-11 14:10:07,902 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-11 14:10:07,902 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-11 14:10:07,902 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-11 14:10:07,902 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-11 14:10:07,902 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141007-0001/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-11 14:10:07,930 [sparkWorker-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140711141007-0001/9 for Simple Application
2014-07-11 14:10:07,948 [ExecutorRunner for app-20140711141007-0001/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-11 14:10:07,949 [ExecutorRunner for app-20140711141007-0001/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-11 14:10:09,123 [ExecutorRunner for app-20140711141007-0001/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms10240M" "-Xmx10240M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140711141007-0001"
2014-07-11 14:10:10,029 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-11 14:10:10,231 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-11 14:10:10,232 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-11 14:10:10,756 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-11 14:10:10,819 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-11 14:10:11,027 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]
2014-07-11 14:10:11,031 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]
2014-07-11 14:10:11,044 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552/user/CoarseGrainedScheduler
2014-07-11 14:10:11,049 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-11 14:10:11,218 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-11 14:10:11,399 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2014-07-11 14:10:11,419 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-11 14:10:11,420 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-11 14:10:11,443 [spark-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-11 14:10:11,451 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-11 14:10:11,469 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:52785]
2014-07-11 14:10:11,471 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:52785]
2014-07-11 14:10:11,489 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SparkEnv - Connecting to MapOutputTracker: akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552/user/MapOutputTracker
2014-07-11 14:10:11,533 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SparkEnv - Connecting to BlockManagerMaster: akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552/user/BlockManagerMaster
2014-07-11 14:10:11,593 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /disk3/spark_local_dirs/spark-local-20140711141011-11ce
2014-07-11 14:10:11,599 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 5.8 GB.
2014-07-11 14:10:11,632 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 60923 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,60923)
2014-07-11 14:10:11,639 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-11 14:10:11,661 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-11 14:10:11,688 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-944149a7-82c7-46b2-8219-3ad1261c1b1f
2014-07-11 14:10:11,695 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-11 14:10:11,790 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-11 14:10:11,812 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:33835
2014-07-11 14:10:33,141 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552 got disassociated, removing it.
2014-07-11 14:10:33,142 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140711141007-0001
2014-07-11 14:10:33,143 [sparkMaster-akka.actor.default-dispatcher-34] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A36962-21#181993124] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-11 14:10:33,153 [sparkMaster-akka.actor.default-dispatcher-20] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:37552
]
2014-07-11 14:10:33,161 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:37552
]
2014-07-11 14:10:33,169 [sparkMaster-akka.actor.default-dispatcher-16] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:37552
]
2014-07-11 14:10:33,180 [sparkExecutor-akka.actor.default-dispatcher-4] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - Driver Disassociated [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552] disassociated! Shutting down.
2014-07-11 14:10:33,202 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-11 14:10:33,202 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-11 14:10:33,274 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552 got disassociated, removing it.
2014-07-11 14:10:33,274 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552 got disassociated, removing it.
2014-07-11 14:10:33,274 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552 got disassociated, removing it.
2014-07-11 14:10:33,274 [sparkMaster-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:37552 got disassociated, removing it.
2014-07-11 14:10:33,279 [sparkWorker-akka.actor.default-dispatcher-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140711141007-0001/9
2014-07-11 14:10:33,279 [ExecutorRunner for app-20140711141007-0001/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140711141007-0001/9 interrupted
2014-07-11 14:10:33,279 [sparkWorker-akka.actor.default-dispatcher-6] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140711141007-0001/9 finished with state KILLED
2014-07-11 14:10:33,280 [ExecutorRunner for app-20140711141007-0001/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-11 14:10:33,281 [sparkMaster-akka.actor.default-dispatcher-26] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/3
2014-07-11 14:10:33,282 [sparkMaster-akka.actor.default-dispatcher-26] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/9
2014-07-11 14:10:33,283 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/5
2014-07-11 14:10:33,283 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/1
2014-07-11 14:10:33,283 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/4
2014-07-11 14:10:33,283 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/15
2014-07-11 14:10:33,283 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/8
2014-07-11 14:10:33,283 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/10
2014-07-11 14:10:33,284 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/11
2014-07-11 14:10:33,284 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/7
2014-07-11 14:10:33,284 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/14
2014-07-11 14:10:33,284 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/13
2014-07-11 14:10:33,284 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/0
2014-07-11 14:10:33,285 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/6
2014-07-11 14:10:33,285 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/12
2014-07-11 14:10:33,285 [sparkMaster-akka.actor.default-dispatcher-34] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141007-0001/2
2014-07-11 14:10:33,535 [sparkWorker-akka.actor.default-dispatcher-5] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A52399-6#720118058] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-11 14:10:33,545 [sparkWorker-akka.actor.default-dispatcher-4] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:53174
]
2014-07-11 14:10:33,553 [sparkWorker-akka.actor.default-dispatcher-4] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:53174
]
2014-07-11 14:10:33,561 [sparkWorker-akka.actor.default-dispatcher-3] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:53174]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:53174
]
2014-07-11 14:12:24,963 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registering app Simple Application
2014-07-11 14:12:24,964 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Registered app Simple Application with ID app-20140711141224-0002
2014-07-11 14:12:24,966 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-11 14:12:24,966 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-11 14:12:24,966 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-11 14:12:24,967 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-11 14:12:24,967 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-11 14:12:24,967 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-11 14:12:24,967 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-11 14:12:24,968 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-11 14:12:24,969 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140711141224-0002/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-11 14:12:24,980 [sparkWorker-akka.actor.default-dispatcher-6] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140711141224-0002/9 for Simple Application
2014-07-11 14:12:24,983 [ExecutorRunner for app-20140711141224-0002/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-11 14:12:24,984 [ExecutorRunner for app-20140711141224-0002/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-11 14:12:25,943 [ExecutorRunner for app-20140711141224-0002/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms10240M" "-Xmx10240M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140711141224-0002"
2014-07-11 14:12:26,738 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-11 14:12:26,919 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-11 14:12:26,919 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-11 14:12:27,363 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-11 14:12:27,424 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-11 14:12:27,604 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]
2014-07-11 14:12:27,609 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]
2014-07-11 14:12:27,621 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/CoarseGrainedScheduler
2014-07-11 14:12:27,625 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-11 14:12:27,800 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-11 14:12:28,066 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2014-07-11 14:12:28,089 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-11 14:12:28,090 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-11 14:12:28,113 [spark-akka.actor.default-dispatcher-6] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-11 14:12:28,121 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Starting remoting
2014-07-11 14:12:28,140 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:53076]
2014-07-11 14:12:28,141 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:53076]
2014-07-11 14:12:28,151 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SparkEnv - Connecting to MapOutputTracker: akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker
2014-07-11 14:12:28,191 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SparkEnv - Connecting to BlockManagerMaster: akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/BlockManagerMaster
2014-07-11 14:12:28,234 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /disk3/spark_local_dirs/spark-local-20140711141228-6783
2014-07-11 14:12:28,238 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 5.8 GB.
2014-07-11 14:12:28,268 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 60805 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,60805)
2014-07-11 14:12:28,273 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-11 14:12:28,293 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-11 14:12:28,316 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-88c0feca-67eb-4bbd-b49f-abe6453efb60
2014-07-11 14:12:28,320 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-11 14:12:28,379 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-11 14:12:28,401 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:47193
2014-07-11 14:12:28,556 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 144
2014-07-11 14:12:28,559 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 145
2014-07-11 14:12:28,559 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 146
2014-07-11 14:12:28,560 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 147
2014-07-11 14:12:28,562 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 148
2014-07-11 14:12:28,563 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 149
2014-07-11 14:12:28,564 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 150
2014-07-11 14:12:28,565 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 151
2014-07-11 14:12:28,565 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 152
2014-07-11 14:12:28,566 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 153
2014-07-11 14:12:28,566 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Running task ID 150
2014-07-11 14:12:28,566 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Running task ID 146
2014-07-11 14:12:28,567 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 152
2014-07-11 14:12:28,566 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Running task ID 148
2014-07-11 14:12:28,566 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Running task ID 147
2014-07-11 14:12:28,566 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task ID 145
2014-07-11 14:12:28,566 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task ID 144
2014-07-11 14:12:28,568 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Running task ID 153
2014-07-11 14:12:28,566 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Running task ID 149
2014-07-11 14:12:28,568 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 154
2014-07-11 14:12:28,568 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 151
2014-07-11 14:12:28,570 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 155
2014-07-11 14:12:28,570 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Running task ID 154
2014-07-11 14:12:28,571 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 156
2014-07-11 14:12:28,571 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 155
2014-07-11 14:12:28,572 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 157
2014-07-11 14:12:28,573 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 156
2014-07-11 14:12:28,573 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 158
2014-07-11 14:12:28,574 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Running task ID 157
2014-07-11 14:12:28,574 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 159
2014-07-11 14:12:28,575 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Running task ID 158
2014-07-11 14:12:28,576 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Running task ID 159
2014-07-11 14:12:28,603 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Fetching http://172.31.109.132:49720/jars/LDA.jar with timestamp 1405080744564
2014-07-11 14:12:28,607 [Executor task launch worker-8] INFO  org.apache.spark.util.Utils - Fetching http://172.31.109.132:49720/jars/LDA.jar to /disk3/spark_local_dirs/fetchFileTemp6539138722333411039.tmp
2014-07-11 14:12:41,090 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Adding file:/disk3/spark_work/app-20140711141224-0002/9/./LDA.jar to class loader
2014-07-11 14:12:41,243 [Executor task launch worker-13] INFO  org.apache.spark.broadcast.HttpBroadcast - Started reading broadcast variable 0
2014-07-11 14:12:41,666 [Executor task launch worker-13] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(329483) called with curMem=0, maxMem=6174120345
2014-07-11 14:12:41,668 [Executor task launch worker-13] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values to memory (estimated size 321.8 KB, free 5.7 GB)
2014-07-11 14:12:41,683 [Executor task launch worker-13] INFO  org.apache.spark.broadcast.HttpBroadcast - Reading broadcast variable 0 took 0.429774198 s
2014-07-11 14:12:41,687 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,688 [Executor task launch worker-1] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,689 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,690 [Executor task launch worker-15] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,691 [Executor task launch worker-3] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,691 [Executor task launch worker-4] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,692 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,692 [Executor task launch worker-5] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,693 [Executor task launch worker-0] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,696 [Executor task launch worker-6] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,698 [Executor task launch worker-9] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,699 [Executor task launch worker-10] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,700 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,703 [Executor task launch worker-2] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,704 [Executor task launch worker-14] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:12:41,752 [Executor task launch worker-10] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:988680+6420
2014-07-11 14:12:41,753 [Executor task launch worker-6] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:963000+6420
2014-07-11 14:12:41,752 [Executor task launch worker-0] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:924480+6420
2014-07-11 14:12:41,752 [Executor task launch worker-4] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:950160+6420
2014-07-11 14:12:41,752 [Executor task launch worker-1] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:930900+6420
2014-07-11 14:12:41,752 [Executor task launch worker-11] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:995100+6420
2014-07-11 14:12:41,752 [Executor task launch worker-9] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:982260+6420
2014-07-11 14:12:41,752 [Executor task launch worker-15] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:1020780+6420
2014-07-11 14:12:41,753 [Executor task launch worker-5] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:956580+6420
2014-07-11 14:12:41,753 [Executor task launch worker-7] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:969420+6420
2014-07-11 14:12:41,753 [Executor task launch worker-12] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:1001520+6420
2014-07-11 14:12:41,752 [Executor task launch worker-8] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:975840+6420
2014-07-11 14:12:41,752 [Executor task launch worker-14] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:1014360+6420
2014-07-11 14:12:41,752 [Executor task launch worker-2] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:937320+6420
2014-07-11 14:12:41,753 [Executor task launch worker-13] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:1007940+6420
2014-07-11 14:12:41,752 [Executor task launch worker-3] INFO  org.apache.spark.rdd.HadoopRDD - Input split: hdfs://dco-node121.dco.ethz.ch:54310/testh/ap50.dat:943740+6420
2014-07-11 14:12:42,405 [Executor task launch worker-2] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2014-07-11 14:12:42,406 [Executor task launch worker-7] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2014-07-11 14:12:42,406 [Executor task launch worker-11] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2014-07-11 14:12:42,406 [Executor task launch worker-2] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2014-07-11 14:12:42,406 [Executor task launch worker-7] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2014-07-11 14:12:42,706 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Serialized size of result for 153 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Serialized size of result for 146 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Serialized size of result for 159 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Serialized size of result for 154 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Serialized size of result for 147 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Serialized size of result for 157 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Sending result for 147 directly to driver
2014-07-11 14:12:42,707 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 155 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 156 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 152 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Serialized size of result for 158 is 535
2014-07-11 14:12:42,708 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Sending result for 158 directly to driver
2014-07-11 14:12:42,707 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Sending result for 154 directly to driver
2014-07-11 14:12:42,707 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 151 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Serialized size of result for 144 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Sending result for 159 directly to driver
2014-07-11 14:12:42,709 [Executor task launch worker-15] INFO  org.apache.spark.executor.Executor - Finished task ID 159
2014-07-11 14:12:42,707 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Sending result for 153 directly to driver
2014-07-11 14:12:42,707 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Sending result for 146 directly to driver
2014-07-11 14:12:42,710 [Executor task launch worker-9] INFO  org.apache.spark.executor.Executor - Finished task ID 153
2014-07-11 14:12:42,709 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Sending result for 144 directly to driver
2014-07-11 14:12:42,709 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 151 directly to driver
2014-07-11 14:12:42,709 [Executor task launch worker-10] INFO  org.apache.spark.executor.Executor - Finished task ID 154
2014-07-11 14:12:42,708 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Finished task ID 158
2014-07-11 14:12:42,708 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Finished task ID 147
2014-07-11 14:12:42,708 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 152 directly to driver
2014-07-11 14:12:42,708 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 156 directly to driver
2014-07-11 14:12:42,711 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 156
2014-07-11 14:12:42,711 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 152
2014-07-11 14:12:42,708 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 155 directly to driver
2014-07-11 14:12:42,708 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Serialized size of result for 149 is 535
2014-07-11 14:12:42,708 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Serialized size of result for 148 is 535
2014-07-11 14:12:42,708 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Serialized size of result for 150 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Serialized size of result for 145 is 535
2014-07-11 14:12:42,707 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Sending result for 157 directly to driver
2014-07-11 14:12:42,712 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Sending result for 145 directly to driver
2014-07-11 14:12:42,712 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Sending result for 150 directly to driver
2014-07-11 14:12:42,712 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Sending result for 148 directly to driver
2014-07-11 14:12:42,712 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Sending result for 149 directly to driver
2014-07-11 14:12:42,712 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 155
2014-07-11 14:12:42,710 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 151
2014-07-11 14:12:42,710 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task ID 144
2014-07-11 14:12:42,710 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Finished task ID 146
2014-07-11 14:12:42,713 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Finished task ID 149
2014-07-11 14:12:42,713 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Finished task ID 148
2014-07-11 14:12:42,713 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Finished task ID 150
2014-07-11 14:12:42,713 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task ID 145
2014-07-11 14:12:42,712 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Finished task ID 157
2014-07-11 14:13:00,200 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 903
2014-07-11 14:13:00,200 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Running task ID 903
2014-07-11 14:13:00,210 [Executor task launch worker-13] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,292 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 919
2014-07-11 14:13:00,292 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Running task ID 919
2014-07-11 14:13:00,297 [Executor task launch worker-1] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,348 [Executor task launch worker-13] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 1 and clearing cache
2014-07-11 14:13:00,349 [Executor task launch worker-13] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 0, fetching them
2014-07-11 14:13:00,349 [Executor task launch worker-1] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 0, fetching them
2014-07-11 14:13:00,351 [Executor task launch worker-13] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:13:00,388 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 935
2014-07-11 14:13:00,389 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Running task ID 935
2014-07-11 14:13:00,395 [Executor task launch worker-6] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,416 [Executor task launch worker-13] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:13:00,429 [Executor task launch worker-13] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,429 [Executor task launch worker-1] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,435 [Executor task launch worker-6] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,446 [Executor task launch worker-13] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,446 [Executor task launch worker-1] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,446 [Executor task launch worker-6] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,483 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 951
2014-07-11 14:13:00,483 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Running task ID 951
2014-07-11 14:13:00,488 [connection-manager-thread] INFO  org.apache.spark.network.SendingConnection - Initiating connection to [dco-node131-mgt.dco.ethz.ch/172.31.109.141:58856]
2014-07-11 14:13:00,488 [connection-manager-thread] INFO  org.apache.spark.network.SendingConnection - Initiating connection to [dco-node123-mgt.dco.ethz.ch/172.31.109.133:41983]
2014-07-11 14:13:00,489 [Executor task launch worker-4] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,491 [pool-3-thread-1] INFO  org.apache.spark.network.SendingConnection - Connected to [dco-node131-mgt.dco.ethz.ch/172.31.109.141:58856], 2 messages pending
2014-07-11 14:13:00,492 [pool-3-thread-1] INFO  org.apache.spark.network.SendingConnection - Connected to [dco-node123-mgt.dco.ethz.ch/172.31.109.133:41983], 1 messages pending
2014-07-11 14:13:00,500 [connection-manager-thread] INFO  org.apache.spark.network.SendingConnection - Initiating connection to [dco-node136-mgt.dco.ethz.ch/172.31.109.146:52795]
2014-07-11 14:13:00,501 [pool-3-thread-1] INFO  org.apache.spark.network.SendingConnection - Connected to [dco-node136-mgt.dco.ethz.ch/172.31.109.146:52795], 2 messages pending
2014-07-11 14:13:00,507 [Executor task launch worker-13] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 79 ms
2014-07-11 14:13:00,508 [Executor task launch worker-6] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 73 ms
2014-07-11 14:13:00,508 [Executor task launch worker-1] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 80 ms
2014-07-11 14:13:00,535 [Executor task launch worker-4] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,538 [Executor task launch worker-4] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,548 [Executor task launch worker-4] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 13 ms
2014-07-11 14:13:00,572 [connection-manager-thread] INFO  org.apache.spark.network.ConnectionManager - Accepted connection from [dco-node136-mgt.dco.ethz.ch/172.31.109.146]
2014-07-11 14:13:00,575 [connection-manager-thread] INFO  org.apache.spark.network.ConnectionManager - Accepted connection from [dco-node131-mgt.dco.ethz.ch/172.31.109.141]
2014-07-11 14:13:00,579 [connection-manager-thread] INFO  org.apache.spark.network.ConnectionManager - Accepted connection from [dco-node123-mgt.dco.ethz.ch/172.31.109.133]
2014-07-11 14:13:00,582 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 967
2014-07-11 14:13:00,582 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Running task ID 967
2014-07-11 14:13:00,586 [Executor task launch worker-5] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,621 [Executor task launch worker-5] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,623 [Executor task launch worker-5] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,630 [Executor task launch worker-5] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 9 ms
2014-07-11 14:13:00,695 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 983
2014-07-11 14:13:00,695 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Running task ID 983
2014-07-11 14:13:00,700 [Executor task launch worker-2] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,737 [Executor task launch worker-2] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,741 [Executor task launch worker-2] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,746 [Executor task launch worker-2] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 9 ms
2014-07-11 14:13:00,786 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 999
2014-07-11 14:13:00,787 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Running task ID 999
2014-07-11 14:13:00,792 [Executor task launch worker-0] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,829 [Executor task launch worker-0] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,831 [Executor task launch worker-0] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,839 [Executor task launch worker-0] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 10 ms
2014-07-11 14:13:00,887 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1015
2014-07-11 14:13:00,887 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 1015
2014-07-11 14:13:00,890 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:00,928 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:00,930 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:00,936 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 8 ms
2014-07-11 14:13:00,980 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1031
2014-07-11 14:13:00,980 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 1031
2014-07-11 14:13:00,985 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:01,033 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:01,035 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:01,040 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 8 ms
2014-07-11 14:13:01,068 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1047
2014-07-11 14:13:01,068 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 1047
2014-07-11 14:13:01,072 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:01,124 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:01,125 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:01,132 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 8 ms
2014-07-11 14:13:01,171 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1063
2014-07-11 14:13:01,171 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 1063
2014-07-11 14:13:01,174 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:01,215 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:01,217 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:01,222 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 7 ms
2014-07-11 14:13:01,257 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1079
2014-07-11 14:13:01,257 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Running task ID 1079
2014-07-11 14:13:01,261 [Executor task launch worker-3] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:01,300 [Executor task launch worker-3] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:01,302 [Executor task launch worker-3] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:01,307 [Executor task launch worker-3] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 7 ms
2014-07-11 14:13:01,351 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1095
2014-07-11 14:13:01,351 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Running task ID 1095
2014-07-11 14:13:01,358 [Executor task launch worker-14] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:01,396 [Executor task launch worker-14] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:01,397 [Executor task launch worker-14] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:01,403 [Executor task launch worker-14] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 7 ms
2014-07-11 14:13:01,912 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Serialized size of result for 903 is 23376
2014-07-11 14:13:01,913 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Sending result for 903 directly to driver
2014-07-11 14:13:01,914 [Executor task launch worker-13] INFO  org.apache.spark.executor.Executor - Finished task ID 903
2014-07-11 14:13:01,977 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Serialized size of result for 967 is 22428
2014-07-11 14:13:01,977 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Sending result for 967 directly to driver
2014-07-11 14:13:01,978 [Executor task launch worker-5] INFO  org.apache.spark.executor.Executor - Finished task ID 967
2014-07-11 14:13:01,986 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Serialized size of result for 951 is 21562
2014-07-11 14:13:01,986 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Sending result for 951 directly to driver
2014-07-11 14:13:01,986 [Executor task launch worker-4] INFO  org.apache.spark.executor.Executor - Finished task ID 951
2014-07-11 14:13:02,019 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Serialized size of result for 999 is 21329
2014-07-11 14:13:02,019 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Sending result for 999 directly to driver
2014-07-11 14:13:02,019 [Executor task launch worker-0] INFO  org.apache.spark.executor.Executor - Finished task ID 999
2014-07-11 14:13:02,065 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Serialized size of result for 919 is 23292
2014-07-11 14:13:02,066 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Sending result for 919 directly to driver
2014-07-11 14:13:02,066 [Executor task launch worker-1] INFO  org.apache.spark.executor.Executor - Finished task ID 919
2014-07-11 14:13:02,079 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1095 is 23082
2014-07-11 14:13:02,079 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Sending result for 1095 directly to driver
2014-07-11 14:13:02,080 [Executor task launch worker-14] INFO  org.apache.spark.executor.Executor - Finished task ID 1095
2014-07-11 14:13:02,084 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1079 is 22321
2014-07-11 14:13:02,084 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Sending result for 1079 directly to driver
2014-07-11 14:13:02,084 [Executor task launch worker-3] INFO  org.apache.spark.executor.Executor - Finished task ID 1079
2014-07-11 14:13:02,102 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Serialized size of result for 983 is 23187
2014-07-11 14:13:02,102 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Sending result for 983 directly to driver
2014-07-11 14:13:02,103 [Executor task launch worker-2] INFO  org.apache.spark.executor.Executor - Finished task ID 983
2014-07-11 14:13:02,109 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Serialized size of result for 935 is 22830
2014-07-11 14:13:02,109 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Sending result for 935 directly to driver
2014-07-11 14:13:02,109 [Executor task launch worker-6] INFO  org.apache.spark.executor.Executor - Finished task ID 935
2014-07-11 14:13:02,124 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1015 is 22491
2014-07-11 14:13:02,124 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 1015 directly to driver
2014-07-11 14:13:02,125 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 1015
2014-07-11 14:13:02,164 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1047 is 21245
2014-07-11 14:13:02,164 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 1047 directly to driver
2014-07-11 14:13:02,164 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 1047
2014-07-11 14:13:02,261 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1031 is 22704
2014-07-11 14:13:02,261 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 1031 directly to driver
2014-07-11 14:13:02,261 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 1031
2014-07-11 14:13:02,281 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1063 is 23651
2014-07-11 14:13:02,281 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 1063 directly to driver
2014-07-11 14:13:02,281 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 1063
2014-07-11 14:13:04,913 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 0 for deleting
2014-07-11 14:13:14,937 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1405
2014-07-11 14:13:14,937 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 1405
2014-07-11 14:13:14,940 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:14,975 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 2 and clearing cache
2014-07-11 14:13:14,975 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 1, fetching them
2014-07-11 14:13:14,975 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:13:15,023 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1421
2014-07-11 14:13:15,023 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 1421
2014-07-11 14:13:15,026 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,057 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:13:15,060 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,060 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,063 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,064 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,068 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 7 ms
2014-07-11 14:13:15,071 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 11 ms
2014-07-11 14:13:15,121 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1437
2014-07-11 14:13:15,121 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 1437
2014-07-11 14:13:15,127 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,161 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,162 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,165 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:13:15,212 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1453
2014-07-11 14:13:15,212 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 1453
2014-07-11 14:13:15,219 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,253 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,255 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,258 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 5 ms
2014-07-11 14:13:15,290 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1421 is 21922
2014-07-11 14:13:15,290 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 1421 directly to driver
2014-07-11 14:13:15,290 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 1421
2014-07-11 14:13:15,290 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1405 is 21056
2014-07-11 14:13:15,290 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 1405 directly to driver
2014-07-11 14:13:15,290 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 1405
2014-07-11 14:13:15,304 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1469
2014-07-11 14:13:15,304 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 1469
2014-07-11 14:13:15,308 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,338 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,340 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,342 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:13:15,377 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1437 is 23418
2014-07-11 14:13:15,377 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 1437 directly to driver
2014-07-11 14:13:15,377 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 1437
2014-07-11 14:13:15,399 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1485
2014-07-11 14:13:15,399 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 1485
2014-07-11 14:13:15,403 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,433 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,434 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,437 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:13:15,461 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1453 is 24772
2014-07-11 14:13:15,461 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 1453 directly to driver
2014-07-11 14:13:15,461 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 1453
2014-07-11 14:13:15,493 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1501
2014-07-11 14:13:15,494 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 1501
2014-07-11 14:13:15,498 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,525 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1469 is 22767
2014-07-11 14:13:15,526 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 1469 directly to driver
2014-07-11 14:13:15,526 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 1469
2014-07-11 14:13:15,532 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,534 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,536 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:13:15,585 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1517
2014-07-11 14:13:15,585 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 1517
2014-07-11 14:13:15,588 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,611 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1485 is 23397
2014-07-11 14:13:15,612 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 1485 directly to driver
2014-07-11 14:13:15,612 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 1485
2014-07-11 14:13:15,618 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,619 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,620 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:15,686 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1533
2014-07-11 14:13:15,686 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 1533
2014-07-11 14:13:15,691 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,700 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1501 is 24116
2014-07-11 14:13:15,700 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 1501 directly to driver
2014-07-11 14:13:15,700 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 1501
2014-07-11 14:13:15,724 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,726 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,727 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:15,790 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1517 is 22746
2014-07-11 14:13:15,790 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 1517 directly to driver
2014-07-11 14:13:15,790 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 1517
2014-07-11 14:13:15,799 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1549
2014-07-11 14:13:15,799 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 1549
2014-07-11 14:13:15,803 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,833 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,834 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,835 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:15,889 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1533 is 21901
2014-07-11 14:13:15,889 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 1533 directly to driver
2014-07-11 14:13:15,889 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 1533
2014-07-11 14:13:15,892 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1565
2014-07-11 14:13:15,892 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 1565
2014-07-11 14:13:15,895 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:15,926 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:15,927 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:15,928 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:15,988 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1581
2014-07-11 14:13:15,989 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 1581
2014-07-11 14:13:15,992 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:16,022 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:16,023 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:16,024 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1549 is 23040
2014-07-11 14:13:16,024 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:16,024 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 1549 directly to driver
2014-07-11 14:13:16,024 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 1549
2014-07-11 14:13:16,084 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1597
2014-07-11 14:13:16,084 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 1597
2014-07-11 14:13:16,089 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:16,111 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1565 is 21499
2014-07-11 14:13:16,111 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 1565 directly to driver
2014-07-11 14:13:16,111 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 1565
2014-07-11 14:13:16,118 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:16,119 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:16,120 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:16,185 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1581 is 24242
2014-07-11 14:13:16,185 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 1581 directly to driver
2014-07-11 14:13:16,185 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 1581
2014-07-11 14:13:16,275 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1597 is 23166
2014-07-11 14:13:16,275 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 1597 directly to driver
2014-07-11 14:13:16,275 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 1597
2014-07-11 14:13:27,958 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1902
2014-07-11 14:13:27,959 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 1902
2014-07-11 14:13:27,963 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:27,992 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 3 and clearing cache
2014-07-11 14:13:27,993 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 2, fetching them
2014-07-11 14:13:27,993 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:13:28,043 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1918
2014-07-11 14:13:28,043 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 1918
2014-07-11 14:13:28,043 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:13:28,044 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,046 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,048 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:13:28,050 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,086 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,087 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,088 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:28,128 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1934
2014-07-11 14:13:28,128 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 1934
2014-07-11 14:13:28,131 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,165 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,166 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,167 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:28,210 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1950
2014-07-11 14:13:28,211 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 1950
2014-07-11 14:13:28,214 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,221 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1902 is 23250
2014-07-11 14:13:28,221 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 1902 directly to driver
2014-07-11 14:13:28,221 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 1902
2014-07-11 14:13:28,243 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,244 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,245 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:28,273 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1918 is 23061
2014-07-11 14:13:28,273 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 1918 directly to driver
2014-07-11 14:13:28,273 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 1918
2014-07-11 14:13:28,291 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1966
2014-07-11 14:13:28,291 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 1966
2014-07-11 14:13:28,296 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,325 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,326 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,327 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:28,345 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1934 is 22237
2014-07-11 14:13:28,345 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 1934 directly to driver
2014-07-11 14:13:28,345 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 1934
2014-07-11 14:13:28,374 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1982
2014-07-11 14:13:28,375 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 1982
2014-07-11 14:13:28,378 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,407 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,408 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,409 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1950 is 22830
2014-07-11 14:13:28,409 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 1950 directly to driver
2014-07-11 14:13:28,409 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:28,409 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 1950
2014-07-11 14:13:28,458 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 1998
2014-07-11 14:13:28,458 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 1998
2014-07-11 14:13:28,462 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,492 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,493 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,496 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:13:28,518 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1966 is 21035
2014-07-11 14:13:28,518 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 1966 directly to driver
2014-07-11 14:13:28,518 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 1966
2014-07-11 14:13:28,542 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2014
2014-07-11 14:13:28,542 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2014
2014-07-11 14:13:28,545 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,578 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,579 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,580 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1982 is 23355
2014-07-11 14:13:28,580 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 1982 directly to driver
2014-07-11 14:13:28,580 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 1982
2014-07-11 14:13:28,580 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:28,626 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2030
2014-07-11 14:13:28,626 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 2030
2014-07-11 14:13:28,629 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,661 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,662 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,664 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:28,671 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 1998 is 22893
2014-07-11 14:13:28,671 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 1998 directly to driver
2014-07-11 14:13:28,671 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 1998
2014-07-11 14:13:28,709 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2046
2014-07-11 14:13:28,710 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 2046
2014-07-11 14:13:28,713 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,744 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,745 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,747 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:28,770 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2014 is 23187
2014-07-11 14:13:28,770 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2014 directly to driver
2014-07-11 14:13:28,770 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2014
2014-07-11 14:13:28,788 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 1 for deleting
2014-07-11 14:13:28,819 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2062
2014-07-11 14:13:28,819 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2062
2014-07-11 14:13:28,822 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,850 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2030 is 23082
2014-07-11 14:13:28,850 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 2030 directly to driver
2014-07-11 14:13:28,850 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 2030
2014-07-11 14:13:28,854 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,855 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,857 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:28,903 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2078
2014-07-11 14:13:28,904 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 2078
2014-07-11 14:13:28,906 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:28,929 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2046 is 23672
2014-07-11 14:13:28,929 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 2046 directly to driver
2014-07-11 14:13:28,929 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 2046
2014-07-11 14:13:28,934 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:28,934 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:28,936 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:28,990 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2094
2014-07-11 14:13:28,990 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 2094
2014-07-11 14:13:28,994 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:29,023 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:29,024 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:29,025 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:29,030 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2062 is 22449
2014-07-11 14:13:29,030 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2062 directly to driver
2014-07-11 14:13:29,030 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2062
2014-07-11 14:13:29,102 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2078 is 21541
2014-07-11 14:13:29,102 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 2078 directly to driver
2014-07-11 14:13:29,102 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 2078
2014-07-11 14:13:29,174 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2094 is 21499
2014-07-11 14:13:29,174 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 2094 directly to driver
2014-07-11 14:13:29,174 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 2094
2014-07-11 14:13:40,523 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2414
2014-07-11 14:13:40,523 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 2414
2014-07-11 14:13:40,527 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:40,559 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 4 and clearing cache
2014-07-11 14:13:40,559 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 3, fetching them
2014-07-11 14:13:40,559 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:13:40,598 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2430
2014-07-11 14:13:40,598 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 2430
2014-07-11 14:13:40,600 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:40,617 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:13:40,618 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:40,619 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:40,621 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:40,630 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:40,631 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:40,632 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:40,678 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2446
2014-07-11 14:13:40,679 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2446
2014-07-11 14:13:40,681 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:40,712 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:40,713 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:40,715 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:40,754 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2462
2014-07-11 14:13:40,754 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 2462
2014-07-11 14:13:40,757 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:40,773 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2430 is 22935
2014-07-11 14:13:40,773 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 2430 directly to driver
2014-07-11 14:13:40,773 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 2430
2014-07-11 14:13:40,782 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2414 is 23208
2014-07-11 14:13:40,782 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 2414 directly to driver
2014-07-11 14:13:40,782 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 2414
2014-07-11 14:13:40,793 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:40,794 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:40,795 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:40,829 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2478
2014-07-11 14:13:40,830 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 2478
2014-07-11 14:13:40,833 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:40,854 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2446 is 22258
2014-07-11 14:13:40,854 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2446 directly to driver
2014-07-11 14:13:40,854 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2446
2014-07-11 14:13:40,863 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:40,864 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:40,866 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:40,908 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2494
2014-07-11 14:13:40,908 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2494
2014-07-11 14:13:40,912 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:40,941 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:40,942 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:40,943 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:40,951 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2462 is 22872
2014-07-11 14:13:40,951 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 2462 directly to driver
2014-07-11 14:13:40,951 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 2462
2014-07-11 14:13:40,983 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2510
2014-07-11 14:13:40,983 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 2510
2014-07-11 14:13:40,986 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:41,013 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:41,014 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:41,015 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:41,030 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2478 is 22554
2014-07-11 14:13:41,030 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 2478 directly to driver
2014-07-11 14:13:41,030 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 2478
2014-07-11 14:13:41,064 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2526
2014-07-11 14:13:41,064 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 2526
2014-07-11 14:13:41,070 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:41,088 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2494 is 22830
2014-07-11 14:13:41,088 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2494 directly to driver
2014-07-11 14:13:41,088 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2494
2014-07-11 14:13:41,102 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:41,103 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:41,105 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:41,140 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2542
2014-07-11 14:13:41,140 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2542
2014-07-11 14:13:41,144 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:41,157 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2510 is 22195
2014-07-11 14:13:41,157 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 2510 directly to driver
2014-07-11 14:13:41,157 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 2510
2014-07-11 14:13:41,172 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:41,173 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:41,174 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:41,219 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2558
2014-07-11 14:13:41,220 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 2558
2014-07-11 14:13:41,223 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:41,241 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2526 is 21754
2014-07-11 14:13:41,241 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 2526 directly to driver
2014-07-11 14:13:41,241 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 2526
2014-07-11 14:13:41,252 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:41,252 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:41,254 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:41,299 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2574
2014-07-11 14:13:41,299 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 2574
2014-07-11 14:13:41,303 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:41,309 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2542 is 21922
2014-07-11 14:13:41,310 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2542 directly to driver
2014-07-11 14:13:41,310 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2542
2014-07-11 14:13:41,331 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:41,332 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:41,333 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:41,373 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2590
2014-07-11 14:13:41,374 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2590
2014-07-11 14:13:41,377 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:41,395 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2558 is 23418
2014-07-11 14:13:41,395 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 2558 directly to driver
2014-07-11 14:13:41,395 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 2558
2014-07-11 14:13:41,408 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:41,409 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:41,410 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:41,473 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2574 is 23609
2014-07-11 14:13:41,473 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 2574 directly to driver
2014-07-11 14:13:41,473 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 2574
2014-07-11 14:13:41,546 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2590 is 22767
2014-07-11 14:13:41,546 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2590 directly to driver
2014-07-11 14:13:41,546 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2590
2014-07-11 14:13:44,753 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 3 for deleting
2014-07-11 14:13:52,193 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2912
2014-07-11 14:13:52,193 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2912
2014-07-11 14:13:52,197 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,222 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 5 and clearing cache
2014-07-11 14:13:52,222 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 4, fetching them
2014-07-11 14:13:52,222 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:13:52,264 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2928
2014-07-11 14:13:52,265 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 2928
2014-07-11 14:13:52,268 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,292 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 4, fetching them
2014-07-11 14:13:52,299 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:13:52,299 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,300 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,300 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,301 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,301 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:52,303 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:13:52,340 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2944
2014-07-11 14:13:52,340 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 2944
2014-07-11 14:13:52,344 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,375 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,376 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,377 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:52,412 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2960
2014-07-11 14:13:52,412 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 2960
2014-07-11 14:13:52,416 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,446 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,447 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,447 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2928 is 23019
2014-07-11 14:13:52,447 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 2928 directly to driver
2014-07-11 14:13:52,447 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 2928
2014-07-11 14:13:52,448 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:52,453 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2912 is 23019
2014-07-11 14:13:52,453 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2912 directly to driver
2014-07-11 14:13:52,453 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2912
2014-07-11 14:13:52,482 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2976
2014-07-11 14:13:52,482 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 2976
2014-07-11 14:13:52,486 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,513 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,513 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,514 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:13:52,518 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2944 is 22132
2014-07-11 14:13:52,518 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 2944 directly to driver
2014-07-11 14:13:52,519 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 2944
2014-07-11 14:13:52,558 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 2992
2014-07-11 14:13:52,559 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 2992
2014-07-11 14:13:52,561 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,601 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2960 is 22893
2014-07-11 14:13:52,601 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 2960 directly to driver
2014-07-11 14:13:52,601 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 2960
2014-07-11 14:13:52,607 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,608 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,609 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:52,636 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3008
2014-07-11 14:13:52,637 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3008
2014-07-11 14:13:52,639 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,664 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,664 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,665 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:13:52,671 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2976 is 22449
2014-07-11 14:13:52,671 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 2976 directly to driver
2014-07-11 14:13:52,671 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 2976
2014-07-11 14:13:52,703 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3024
2014-07-11 14:13:52,704 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3024
2014-07-11 14:13:52,707 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,732 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,733 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,734 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:52,746 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 2992 is 23969
2014-07-11 14:13:52,746 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 2992 directly to driver
2014-07-11 14:13:52,746 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 2992
2014-07-11 14:13:52,777 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3040
2014-07-11 14:13:52,777 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 3040
2014-07-11 14:13:52,780 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,804 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3008 is 22914
2014-07-11 14:13:52,804 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3008 directly to driver
2014-07-11 14:13:52,804 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3008
2014-07-11 14:13:52,808 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,808 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,809 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:13:52,850 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3056
2014-07-11 14:13:52,850 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3056
2014-07-11 14:13:52,853 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,875 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3024 is 23822
2014-07-11 14:13:52,875 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3024 directly to driver
2014-07-11 14:13:52,875 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3024
2014-07-11 14:13:52,880 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,881 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,882 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:52,925 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3072
2014-07-11 14:13:52,925 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3072
2014-07-11 14:13:52,928 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:52,947 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3040 is 23525
2014-07-11 14:13:52,947 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 3040 directly to driver
2014-07-11 14:13:52,947 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 3040
2014-07-11 14:13:52,953 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:52,954 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:52,955 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:13:52,997 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3088
2014-07-11 14:13:52,997 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 3088
2014-07-11 14:13:53,000 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:13:53,022 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3056 is 22237
2014-07-11 14:13:53,022 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3056 directly to driver
2014-07-11 14:13:53,022 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3056
2014-07-11 14:13:53,029 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:13:53,029 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:13:53,030 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:13:53,095 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3072 is 23696
2014-07-11 14:13:53,095 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3072 directly to driver
2014-07-11 14:13:53,095 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3072
2014-07-11 14:13:53,168 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3088 is 23780
2014-07-11 14:13:53,168 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 3088 directly to driver
2014-07-11 14:13:53,168 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 3088
2014-07-11 14:14:03,105 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 4 for deleting
2014-07-11 14:14:03,477 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3402
2014-07-11 14:14:03,477 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 3402
2014-07-11 14:14:03,508 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,536 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 6 and clearing cache
2014-07-11 14:14:03,536 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 5, fetching them
2014-07-11 14:14:03,536 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:14:03,549 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3418
2014-07-11 14:14:03,549 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3418
2014-07-11 14:14:03,553 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,579 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 5, fetching them
2014-07-11 14:14:03,584 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:14:03,585 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:03,585 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:03,586 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:03,586 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:03,587 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:03,588 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:14:03,622 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3434
2014-07-11 14:14:03,623 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3434
2014-07-11 14:14:03,626 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,656 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:03,656 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:03,657 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:14:03,689 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3450
2014-07-11 14:14:03,689 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 3450
2014-07-11 14:14:03,694 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,726 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:03,727 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:03,728 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:03,737 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3402 is 23250
2014-07-11 14:14:03,737 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 3402 directly to driver
2014-07-11 14:14:03,737 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 3402
2014-07-11 14:14:03,740 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3418 is 23061
2014-07-11 14:14:03,740 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3418 directly to driver
2014-07-11 14:14:03,740 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3418
2014-07-11 14:14:03,762 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3466
2014-07-11 14:14:03,763 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3466
2014-07-11 14:14:03,766 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,791 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3434 is 22237
2014-07-11 14:14:03,791 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3434 directly to driver
2014-07-11 14:14:03,791 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3434
2014-07-11 14:14:03,791 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:03,792 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:03,795 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:14:03,831 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3482
2014-07-11 14:14:03,831 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3482
2014-07-11 14:14:03,834 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,860 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:03,860 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:03,861 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:14:03,883 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3450 is 22830
2014-07-11 14:14:03,883 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 3450 directly to driver
2014-07-11 14:14:03,883 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 3450
2014-07-11 14:14:03,902 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3498
2014-07-11 14:14:03,902 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 3498
2014-07-11 14:14:03,906 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,932 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:03,933 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:03,934 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:03,942 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3466 is 21035
2014-07-11 14:14:03,942 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3466 directly to driver
2014-07-11 14:14:03,942 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3466
2014-07-11 14:14:03,977 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3514
2014-07-11 14:14:03,977 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3514
2014-07-11 14:14:03,980 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:03,997 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3482 is 23355
2014-07-11 14:14:03,997 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3482 directly to driver
2014-07-11 14:14:03,997 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3482
2014-07-11 14:14:04,008 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:04,008 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:04,009 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:14:04,048 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3530
2014-07-11 14:14:04,048 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3530
2014-07-11 14:14:04,051 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:04,078 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:04,079 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:04,080 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:04,093 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3498 is 22893
2014-07-11 14:14:04,093 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 3498 directly to driver
2014-07-11 14:14:04,094 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 3498
2014-07-11 14:14:04,121 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3546
2014-07-11 14:14:04,122 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 3546
2014-07-11 14:14:04,125 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:04,149 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3514 is 23187
2014-07-11 14:14:04,149 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3514 directly to driver
2014-07-11 14:14:04,149 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3514
2014-07-11 14:14:04,152 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:04,153 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:04,154 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:04,192 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3562
2014-07-11 14:14:04,192 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3562
2014-07-11 14:14:04,194 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:04,217 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3530 is 23082
2014-07-11 14:14:04,217 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3530 directly to driver
2014-07-11 14:14:04,218 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3530
2014-07-11 14:14:04,218 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:04,219 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:04,220 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:04,264 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3578
2014-07-11 14:14:04,264 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3578
2014-07-11 14:14:04,267 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:04,291 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:04,292 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:04,293 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:04,313 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3546 is 23672
2014-07-11 14:14:04,313 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 3546 directly to driver
2014-07-11 14:14:04,313 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 3546
2014-07-11 14:14:04,329 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3594
2014-07-11 14:14:04,329 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 3594
2014-07-11 14:14:04,332 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:04,353 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3562 is 22449
2014-07-11 14:14:04,353 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3562 directly to driver
2014-07-11 14:14:04,353 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3562
2014-07-11 14:14:04,359 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:04,360 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:04,361 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:04,426 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3578 is 21541
2014-07-11 14:14:04,426 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3578 directly to driver
2014-07-11 14:14:04,427 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3578
2014-07-11 14:14:04,495 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3594 is 21499
2014-07-11 14:14:04,495 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 3594 directly to driver
2014-07-11 14:14:04,495 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 3594
2014-07-11 14:14:14,489 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3902
2014-07-11 14:14:14,489 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 3902
2014-07-11 14:14:14,493 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:14,520 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 7 and clearing cache
2014-07-11 14:14:14,520 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 6, fetching them
2014-07-11 14:14:14,520 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:14:14,559 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3918
2014-07-11 14:14:14,560 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3918
2014-07-11 14:14:14,563 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:14,589 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 6, fetching them
2014-07-11 14:14:14,602 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:14:14,603 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:14,603 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:14,604 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:14,604 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:14,607 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:14:14,608 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 5 ms
2014-07-11 14:14:14,634 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3934
2014-07-11 14:14:14,634 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3934
2014-07-11 14:14:14,638 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:14,662 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:14,663 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:14,664 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:14,702 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3950
2014-07-11 14:14:14,702 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 3950
2014-07-11 14:14:14,706 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:14,735 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:14,736 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:14,737 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:14,759 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3918 is 23061
2014-07-11 14:14:14,759 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3918 directly to driver
2014-07-11 14:14:14,759 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3918
2014-07-11 14:14:14,769 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3966
2014-07-11 14:14:14,770 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 3966
2014-07-11 14:14:14,773 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:14,779 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3902 is 23250
2014-07-11 14:14:14,779 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 3902 directly to driver
2014-07-11 14:14:14,779 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 3902
2014-07-11 14:14:14,799 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:14,800 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:14,801 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:14,810 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3934 is 22237
2014-07-11 14:14:14,810 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3934 directly to driver
2014-07-11 14:14:14,810 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3934
2014-07-11 14:14:14,844 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3982
2014-07-11 14:14:14,844 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 3982
2014-07-11 14:14:14,847 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:14,871 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:14,872 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:14,872 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3950 is 22830
2014-07-11 14:14:14,873 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 3950 directly to driver
2014-07-11 14:14:14,873 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 3950
2014-07-11 14:14:14,873 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:14,911 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 3998
2014-07-11 14:14:14,911 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 3998
2014-07-11 14:14:14,914 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:14,929 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3966 is 21035
2014-07-11 14:14:14,929 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 3966 directly to driver
2014-07-11 14:14:14,929 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 3966
2014-07-11 14:14:14,940 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:14,940 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:14,942 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:14,982 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4014
2014-07-11 14:14:14,982 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 4014
2014-07-11 14:14:14,985 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:15,009 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3982 is 23355
2014-07-11 14:14:15,009 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 3982 directly to driver
2014-07-11 14:14:15,009 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 3982
2014-07-11 14:14:15,009 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:15,010 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:15,011 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:15,056 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4030
2014-07-11 14:14:15,056 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4030
2014-07-11 14:14:15,058 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:15,082 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 3998 is 22893
2014-07-11 14:14:15,082 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 3998 directly to driver
2014-07-11 14:14:15,082 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 3998
2014-07-11 14:14:15,082 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:15,083 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:15,084 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:15,127 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4046
2014-07-11 14:14:15,127 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 4046
2014-07-11 14:14:15,130 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:15,149 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4014 is 23187
2014-07-11 14:14:15,149 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 4014 directly to driver
2014-07-11 14:14:15,149 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 4014
2014-07-11 14:14:15,158 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:15,158 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:15,160 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:15,197 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4062
2014-07-11 14:14:15,198 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 4062
2014-07-11 14:14:15,201 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:15,228 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:15,229 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:15,230 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:15,233 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4030 is 23082
2014-07-11 14:14:15,234 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4030 directly to driver
2014-07-11 14:14:15,234 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4030
2014-07-11 14:14:15,269 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4078
2014-07-11 14:14:15,269 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4078
2014-07-11 14:14:15,272 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:15,299 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:15,299 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:15,301 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:15,302 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4046 is 23672
2014-07-11 14:14:15,302 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 4046 directly to driver
2014-07-11 14:14:15,302 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 4046
2014-07-11 14:14:15,331 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4094
2014-07-11 14:14:15,331 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 4094
2014-07-11 14:14:15,334 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:15,359 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:15,360 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:15,361 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:15,367 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4062 is 22449
2014-07-11 14:14:15,367 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 4062 directly to driver
2014-07-11 14:14:15,367 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 4062
2014-07-11 14:14:15,435 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4078 is 21541
2014-07-11 14:14:15,435 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4078 directly to driver
2014-07-11 14:14:15,435 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4078
2014-07-11 14:14:15,496 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4094 is 21499
2014-07-11 14:14:15,496 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 4094 directly to driver
2014-07-11 14:14:15,496 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 4094
2014-07-11 14:14:17,185 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 6 for deleting
2014-07-11 14:14:17,186 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 5 for deleting
2014-07-11 14:14:26,858 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4410
2014-07-11 14:14:26,859 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 4410
2014-07-11 14:14:26,862 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:26,892 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 8 and clearing cache
2014-07-11 14:14:26,893 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 7, fetching them
2014-07-11 14:14:26,893 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:14:26,932 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4426
2014-07-11 14:14:26,933 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4426
2014-07-11 14:14:26,933 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:14:26,934 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:26,935 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:26,936 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:26,937 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:14:26,965 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:26,966 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:26,967 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,004 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4442
2014-07-11 14:14:27,004 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 4442
2014-07-11 14:14:27,007 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,036 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,037 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,038 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,073 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4458
2014-07-11 14:14:27,073 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 4458
2014-07-11 14:14:27,077 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,080 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4410 is 22069
2014-07-11 14:14:27,080 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 4410 directly to driver
2014-07-11 14:14:27,080 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 4410
2014-07-11 14:14:27,109 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,109 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,110 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4426 is 21922
2014-07-11 14:14:27,110 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4426 directly to driver
2014-07-11 14:14:27,110 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4426
2014-07-11 14:14:27,111 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,142 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4474
2014-07-11 14:14:27,142 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4474
2014-07-11 14:14:27,144 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,171 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4442 is 22617
2014-07-11 14:14:27,171 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 4442 directly to driver
2014-07-11 14:14:27,171 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 4442
2014-07-11 14:14:27,176 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,177 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,187 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 11 ms
2014-07-11 14:14:27,217 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4490
2014-07-11 14:14:27,218 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 4490
2014-07-11 14:14:27,219 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,243 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,244 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,245 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,282 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4458 is 23630
2014-07-11 14:14:27,282 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 4458 directly to driver
2014-07-11 14:14:27,282 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 4458
2014-07-11 14:14:27,283 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4506
2014-07-11 14:14:27,283 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 4506
2014-07-11 14:14:27,285 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,311 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,311 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,313 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,333 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4474 is 24664
2014-07-11 14:14:27,333 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4474 directly to driver
2014-07-11 14:14:27,333 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4474
2014-07-11 14:14:27,355 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4522
2014-07-11 14:14:27,355 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4522
2014-07-11 14:14:27,357 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,380 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4490 is 24032
2014-07-11 14:14:27,381 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 4490 directly to driver
2014-07-11 14:14:27,381 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 4490
2014-07-11 14:14:27,382 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,383 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,384 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,424 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4538
2014-07-11 14:14:27,424 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 4538
2014-07-11 14:14:27,427 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,451 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,452 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,453 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,460 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4506 is 23355
2014-07-11 14:14:27,461 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 4506 directly to driver
2014-07-11 14:14:27,461 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 4506
2014-07-11 14:14:27,496 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4554
2014-07-11 14:14:27,497 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 4554
2014-07-11 14:14:27,500 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,518 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4522 is 21817
2014-07-11 14:14:27,518 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4522 directly to driver
2014-07-11 14:14:27,518 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4522
2014-07-11 14:14:27,529 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,530 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,531 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,567 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4570
2014-07-11 14:14:27,568 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4570
2014-07-11 14:14:27,571 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,590 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4538 is 22363
2014-07-11 14:14:27,590 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 4538 directly to driver
2014-07-11 14:14:27,590 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 4538
2014-07-11 14:14:27,598 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,598 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,599 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:27,637 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4586
2014-07-11 14:14:27,637 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 4586
2014-07-11 14:14:27,640 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:27,667 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:27,667 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:27,668 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:14:27,677 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4554 is 23145
2014-07-11 14:14:27,677 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 4554 directly to driver
2014-07-11 14:14:27,677 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 4554
2014-07-11 14:14:27,737 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4570 is 22216
2014-07-11 14:14:27,737 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4570 directly to driver
2014-07-11 14:14:27,737 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4570
2014-07-11 14:14:27,805 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4586 is 22977
2014-07-11 14:14:27,805 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 4586 directly to driver
2014-07-11 14:14:27,805 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 4586
2014-07-11 14:14:44,721 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4909
2014-07-11 14:14:44,721 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 4909
2014-07-11 14:14:44,724 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:44,754 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 9 and clearing cache
2014-07-11 14:14:44,754 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 8, fetching them
2014-07-11 14:14:44,754 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:14:44,791 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4925
2014-07-11 14:14:44,791 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4925
2014-07-11 14:14:44,794 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:44,806 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:14:44,806 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:44,807 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:44,809 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:14:44,825 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:44,826 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:44,827 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:44,858 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4941
2014-07-11 14:14:44,859 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 4941
2014-07-11 14:14:44,862 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:44,888 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:44,889 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:44,890 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:44,930 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4957
2014-07-11 14:14:44,930 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 4957
2014-07-11 14:14:44,933 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:44,950 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4909 is 23124
2014-07-11 14:14:44,950 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 4909 directly to driver
2014-07-11 14:14:44,950 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 4909
2014-07-11 14:14:44,960 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4925 is 23040
2014-07-11 14:14:44,960 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4925 directly to driver
2014-07-11 14:14:44,960 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4925
2014-07-11 14:14:44,964 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:44,965 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:44,966 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:44,999 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4973
2014-07-11 14:14:44,999 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 4973
2014-07-11 14:14:45,002 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,027 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,028 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,029 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:45,031 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4941 is 24368
2014-07-11 14:14:45,031 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 4941 directly to driver
2014-07-11 14:14:45,031 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 4941
2014-07-11 14:14:45,070 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 4989
2014-07-11 14:14:45,070 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 4989
2014-07-11 14:14:45,073 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,099 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,099 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,100 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4957 is 24137
2014-07-11 14:14:45,100 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 4957 directly to driver
2014-07-11 14:14:45,100 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:14:45,100 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 4957
2014-07-11 14:14:45,148 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 7 for deleting
2014-07-11 14:14:45,164 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4973 is 23990
2014-07-11 14:14:45,164 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 4973 directly to driver
2014-07-11 14:14:45,164 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 4973
2014-07-11 14:14:45,211 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5005
2014-07-11 14:14:45,211 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 5005
2014-07-11 14:14:45,214 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,229 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 4989 is 24095
2014-07-11 14:14:45,229 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 4989 directly to driver
2014-07-11 14:14:45,229 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 4989
2014-07-11 14:14:45,239 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,240 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,241 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:45,280 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5021
2014-07-11 14:14:45,280 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5021
2014-07-11 14:14:45,283 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,309 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,310 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,311 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:45,352 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5037
2014-07-11 14:14:45,352 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 5037
2014-07-11 14:14:45,356 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,379 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5005 is 24326
2014-07-11 14:14:45,379 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 5005 directly to driver
2014-07-11 14:14:45,379 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 5005
2014-07-11 14:14:45,380 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,380 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,381 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:14:45,423 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5053
2014-07-11 14:14:45,423 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 5053
2014-07-11 14:14:45,426 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,441 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5021 is 22342
2014-07-11 14:14:45,441 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5021 directly to driver
2014-07-11 14:14:45,441 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5021
2014-07-11 14:14:45,451 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,452 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,453 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:45,494 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5069
2014-07-11 14:14:45,494 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5069
2014-07-11 14:14:45,498 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,520 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5037 is 23334
2014-07-11 14:14:45,520 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 5037 directly to driver
2014-07-11 14:14:45,520 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 5037
2014-07-11 14:14:45,522 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,522 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,523 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:14:45,562 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5085
2014-07-11 14:14:45,562 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 5085
2014-07-11 14:14:45,566 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:14:45,589 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5053 is 23145
2014-07-11 14:14:45,589 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 5053 directly to driver
2014-07-11 14:14:45,590 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 5053
2014-07-11 14:14:45,591 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:14:45,591 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:14:45,593 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:14:45,660 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5069 is 22596
2014-07-11 14:14:45,660 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5069 directly to driver
2014-07-11 14:14:45,660 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5069
2014-07-11 14:14:45,730 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5085 is 22893
2014-07-11 14:14:45,730 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 5085 directly to driver
2014-07-11 14:14:45,730 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 5085
2014-07-11 14:15:28,642 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5411
2014-07-11 14:15:28,642 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 5411
2014-07-11 14:15:28,646 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:28,674 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 10 and clearing cache
2014-07-11 14:15:28,674 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 9, fetching them
2014-07-11 14:15:28,675 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:15:28,712 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5427
2014-07-11 14:15:28,712 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5427
2014-07-11 14:15:28,715 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:28,732 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:15:28,733 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:28,734 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:28,736 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:15:28,744 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:28,745 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:28,746 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:28,781 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5443
2014-07-11 14:15:28,781 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 5443
2014-07-11 14:15:28,784 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:28,809 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:28,810 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:28,811 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:28,851 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5459
2014-07-11 14:15:28,851 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 5459
2014-07-11 14:15:28,853 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:28,878 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:28,878 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:28,879 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:15:28,882 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5411 is 22767
2014-07-11 14:15:28,882 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 5411 directly to driver
2014-07-11 14:15:28,882 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5427 is 22470
2014-07-11 14:15:28,882 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 5411
2014-07-11 14:15:28,882 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5427 directly to driver
2014-07-11 14:15:28,882 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5427
2014-07-11 14:15:28,920 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5475
2014-07-11 14:15:28,920 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5475
2014-07-11 14:15:28,924 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:28,943 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5443 is 22956
2014-07-11 14:15:28,943 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 5443 directly to driver
2014-07-11 14:15:28,943 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 5443
2014-07-11 14:15:28,949 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:28,949 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:28,950 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:15:28,990 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5491
2014-07-11 14:15:28,990 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 5491
2014-07-11 14:15:28,993 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:29,011 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5459 is 20846
2014-07-11 14:15:29,011 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 5459 directly to driver
2014-07-11 14:15:29,011 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 5459
2014-07-11 14:15:29,019 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:29,019 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:29,020 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:15:29,061 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5507
2014-07-11 14:15:29,061 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 5507
2014-07-11 14:15:29,064 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:29,083 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5475 is 23948
2014-07-11 14:15:29,084 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5475 directly to driver
2014-07-11 14:15:29,084 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5475
2014-07-11 14:15:29,096 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:29,097 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:29,098 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:29,134 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5523
2014-07-11 14:15:29,134 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5523
2014-07-11 14:15:29,137 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:29,158 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5491 is 23546
2014-07-11 14:15:29,158 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 5491 directly to driver
2014-07-11 14:15:29,158 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 5491
2014-07-11 14:15:29,161 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:29,161 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:29,162 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:15:29,203 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5539
2014-07-11 14:15:29,203 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 5539
2014-07-11 14:15:29,206 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:29,230 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:29,231 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:29,232 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:29,244 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5507 is 22384
2014-07-11 14:15:29,244 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 5507 directly to driver
2014-07-11 14:15:29,244 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 5507
2014-07-11 14:15:29,276 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5555
2014-07-11 14:15:29,277 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 5555
2014-07-11 14:15:29,279 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:29,298 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5523 is 23567
2014-07-11 14:15:29,298 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5523 directly to driver
2014-07-11 14:15:29,299 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5523
2014-07-11 14:15:29,302 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:29,303 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:29,304 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:29,347 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5571
2014-07-11 14:15:29,348 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5571
2014-07-11 14:15:29,351 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:29,368 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5539 is 23609
2014-07-11 14:15:29,368 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 5539 directly to driver
2014-07-11 14:15:29,368 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 5539
2014-07-11 14:15:29,377 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:29,378 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:29,379 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:29,417 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5587
2014-07-11 14:15:29,417 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 5587
2014-07-11 14:15:29,420 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:29,437 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5555 is 22279
2014-07-11 14:15:29,437 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 5555 directly to driver
2014-07-11 14:15:29,437 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 5555
2014-07-11 14:15:29,447 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:29,448 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:29,449 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:29,512 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5571 is 23313
2014-07-11 14:15:29,512 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5571 directly to driver
2014-07-11 14:15:29,512 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5571
2014-07-11 14:15:29,580 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5587 is 23630
2014-07-11 14:15:29,580 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 5587 directly to driver
2014-07-11 14:15:29,580 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 5587
2014-07-11 14:15:33,896 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 9 for deleting
2014-07-11 14:15:33,903 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 8 for deleting
2014-07-11 14:15:47,986 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5902
2014-07-11 14:15:47,986 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Running task ID 5902
2014-07-11 14:15:47,988 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,012 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 11 and clearing cache
2014-07-11 14:15:48,012 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 10, fetching them
2014-07-11 14:15:48,012 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:15:48,056 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5918
2014-07-11 14:15:48,057 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5918
2014-07-11 14:15:48,060 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,087 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 10, fetching them
2014-07-11 14:15:48,111 [Executor task launch worker-7] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:15:48,112 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,112 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,113 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,114 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,115 [Executor task launch worker-7] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:15:48,115 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:15:48,128 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5934
2014-07-11 14:15:48,128 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 5934
2014-07-11 14:15:48,131 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,158 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,159 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,160 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,196 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5950
2014-07-11 14:15:48,196 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 5950
2014-07-11 14:15:48,199 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,227 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,227 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,229 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,262 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5902 is 23250
2014-07-11 14:15:48,262 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5966
2014-07-11 14:15:48,262 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Sending result for 5902 directly to driver
2014-07-11 14:15:48,263 [Executor task launch worker-7] INFO  org.apache.spark.executor.Executor - Finished task ID 5902
2014-07-11 14:15:48,263 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5918 is 23061
2014-07-11 14:15:48,263 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5918 directly to driver
2014-07-11 14:15:48,263 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5918
2014-07-11 14:15:48,263 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 5966
2014-07-11 14:15:48,265 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,289 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,290 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,291 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,294 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5934 is 22237
2014-07-11 14:15:48,294 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 5934 directly to driver
2014-07-11 14:15:48,294 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 5934
2014-07-11 14:15:48,356 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5982
2014-07-11 14:15:48,356 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 5982
2014-07-11 14:15:48,359 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,382 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,383 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,384 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,409 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 5998
2014-07-11 14:15:48,409 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 5998
2014-07-11 14:15:48,411 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5950 is 22830
2014-07-11 14:15:48,411 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 5950 directly to driver
2014-07-11 14:15:48,411 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 5950
2014-07-11 14:15:48,412 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,444 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,445 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,446 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,460 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5966 is 21035
2014-07-11 14:15:48,460 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 5966 directly to driver
2014-07-11 14:15:48,460 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 5966
2014-07-11 14:15:48,478 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6014
2014-07-11 14:15:48,479 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 6014
2014-07-11 14:15:48,482 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,508 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,509 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,510 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,515 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5982 is 23355
2014-07-11 14:15:48,515 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 5982 directly to driver
2014-07-11 14:15:48,516 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 5982
2014-07-11 14:15:48,550 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6030
2014-07-11 14:15:48,550 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6030
2014-07-11 14:15:48,553 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,583 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,584 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,585 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,597 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 5998 is 22893
2014-07-11 14:15:48,597 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 5998 directly to driver
2014-07-11 14:15:48,597 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 5998
2014-07-11 14:15:48,619 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6046
2014-07-11 14:15:48,619 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 6046
2014-07-11 14:15:48,622 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,650 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,650 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,651 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:15:48,661 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6014 is 23187
2014-07-11 14:15:48,661 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 6014 directly to driver
2014-07-11 14:15:48,661 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 6014
2014-07-11 14:15:48,689 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6062
2014-07-11 14:15:48,689 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 6062
2014-07-11 14:15:48,692 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,717 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,718 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,718 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6030 is 23082
2014-07-11 14:15:48,718 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6030 directly to driver
2014-07-11 14:15:48,718 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6030
2014-07-11 14:15:48,719 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,760 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6078
2014-07-11 14:15:48,760 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6078
2014-07-11 14:15:48,763 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,788 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,789 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,790 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:15:48,802 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6046 is 23672
2014-07-11 14:15:48,802 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 6046 directly to driver
2014-07-11 14:15:48,802 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 6046
2014-07-11 14:15:48,831 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6094
2014-07-11 14:15:48,831 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 6094
2014-07-11 14:15:48,834 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:15:48,860 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:15:48,860 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6062 is 22449
2014-07-11 14:15:48,860 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 6062 directly to driver
2014-07-11 14:15:48,860 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 6062
2014-07-11 14:15:48,860 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:15:48,861 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:15:48,926 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6078 is 21541
2014-07-11 14:15:48,926 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6078 directly to driver
2014-07-11 14:15:48,926 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6078
2014-07-11 14:15:48,996 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6094 is 21499
2014-07-11 14:15:48,996 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 6094 directly to driver
2014-07-11 14:15:48,996 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 6094
2014-07-11 14:16:14,720 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6410
2014-07-11 14:16:14,721 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 6410
2014-07-11 14:16:14,723 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:14,748 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 12 and clearing cache
2014-07-11 14:16:14,748 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 11, fetching them
2014-07-11 14:16:14,748 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:16:14,784 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:16:14,785 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:14,786 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:14,788 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:16:14,791 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6426
2014-07-11 14:16:14,791 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6426
2014-07-11 14:16:14,794 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:14,819 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:14,820 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:14,821 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:14,861 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6442
2014-07-11 14:16:14,861 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 6442
2014-07-11 14:16:14,865 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:14,897 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:14,897 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:14,899 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:14,930 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6458
2014-07-11 14:16:14,930 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 6458
2014-07-11 14:16:14,930 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6410 is 22069
2014-07-11 14:16:14,930 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 6410 directly to driver
2014-07-11 14:16:14,931 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 6410
2014-07-11 14:16:14,933 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:14,956 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6426 is 21922
2014-07-11 14:16:14,956 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6426 directly to driver
2014-07-11 14:16:14,956 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6426
2014-07-11 14:16:14,963 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:14,964 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:14,965 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:14,998 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6474
2014-07-11 14:16:14,998 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6474
2014-07-11 14:16:15,000 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,024 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,024 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,025 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:15,056 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6442 is 22617
2014-07-11 14:16:15,056 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 6442 directly to driver
2014-07-11 14:16:15,056 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 6442
2014-07-11 14:16:15,070 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6490
2014-07-11 14:16:15,070 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 6490
2014-07-11 14:16:15,073 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,100 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,100 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,101 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:15,105 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6458 is 23630
2014-07-11 14:16:15,105 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 6458 directly to driver
2014-07-11 14:16:15,105 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 6458
2014-07-11 14:16:15,141 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6506
2014-07-11 14:16:15,141 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 6506
2014-07-11 14:16:15,143 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,158 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6474 is 24664
2014-07-11 14:16:15,158 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6474 directly to driver
2014-07-11 14:16:15,158 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6474
2014-07-11 14:16:15,167 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,167 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,168 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:15,210 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6522
2014-07-11 14:16:15,210 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6522
2014-07-11 14:16:15,212 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,238 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,238 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 10 for deleting
2014-07-11 14:16:15,239 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,240 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:15,248 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6490 is 24032
2014-07-11 14:16:15,248 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 6490 directly to driver
2014-07-11 14:16:15,248 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 6490
2014-07-11 14:16:15,306 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6506 is 23355
2014-07-11 14:16:15,306 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 6506 directly to driver
2014-07-11 14:16:15,306 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 6506
2014-07-11 14:16:15,313 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6538
2014-07-11 14:16:15,313 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 6538
2014-07-11 14:16:15,316 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,340 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,341 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,342 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:15,381 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6522 is 21817
2014-07-11 14:16:15,381 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6522 directly to driver
2014-07-11 14:16:15,381 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6522
2014-07-11 14:16:15,386 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6554
2014-07-11 14:16:15,386 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6554
2014-07-11 14:16:15,389 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,415 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,416 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,417 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:15,456 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6570
2014-07-11 14:16:15,456 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 6570
2014-07-11 14:16:15,459 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,486 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6538 is 22363
2014-07-11 14:16:15,487 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 6538 directly to driver
2014-07-11 14:16:15,487 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 6538
2014-07-11 14:16:15,493 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,494 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,495 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:15,520 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6586
2014-07-11 14:16:15,520 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 6586
2014-07-11 14:16:15,523 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:15,554 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:15,554 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6554 is 23145
2014-07-11 14:16:15,554 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6554 directly to driver
2014-07-11 14:16:15,554 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6554
2014-07-11 14:16:15,555 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:15,556 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:15,632 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6570 is 22216
2014-07-11 14:16:15,632 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 6570 directly to driver
2014-07-11 14:16:15,632 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 6570
2014-07-11 14:16:15,693 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6586 is 22977
2014-07-11 14:16:15,694 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 6586 directly to driver
2014-07-11 14:16:15,694 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 6586
2014-07-11 14:16:32,520 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6913
2014-07-11 14:16:32,520 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 6913
2014-07-11 14:16:32,523 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:32,548 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 13 and clearing cache
2014-07-11 14:16:32,549 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 12, fetching them
2014-07-11 14:16:32,549 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:16:32,589 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6929
2014-07-11 14:16:32,590 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 6929
2014-07-11 14:16:32,593 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:32,602 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:16:32,603 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:32,604 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:32,608 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 5 ms
2014-07-11 14:16:32,629 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:32,629 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:32,630 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:32,659 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6945
2014-07-11 14:16:32,660 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6945
2014-07-11 14:16:32,661 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:32,686 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:32,687 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:32,688 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:32,729 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6961
2014-07-11 14:16:32,729 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 6961
2014-07-11 14:16:32,732 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:32,752 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6913 is 22809
2014-07-11 14:16:32,752 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 6913 directly to driver
2014-07-11 14:16:32,752 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 6913
2014-07-11 14:16:32,763 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:32,764 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:32,765 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:32,787 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6929 is 22788
2014-07-11 14:16:32,787 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 6929 directly to driver
2014-07-11 14:16:32,787 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 6929
2014-07-11 14:16:32,800 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6977
2014-07-11 14:16:32,801 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 6977
2014-07-11 14:16:32,803 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:32,822 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6945 is 23672
2014-07-11 14:16:32,822 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6945 directly to driver
2014-07-11 14:16:32,822 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6945
2014-07-11 14:16:32,830 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:32,831 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:32,832 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:32,872 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 6993
2014-07-11 14:16:32,872 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 6993
2014-07-11 14:16:32,875 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:32,900 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:32,901 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:32,902 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:32,911 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6961 is 24011
2014-07-11 14:16:32,911 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 6961 directly to driver
2014-07-11 14:16:32,911 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 6961
2014-07-11 14:16:32,943 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7009
2014-07-11 14:16:32,943 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7009
2014-07-11 14:16:32,946 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:32,970 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6977 is 22512
2014-07-11 14:16:32,970 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 6977 directly to driver
2014-07-11 14:16:32,970 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 6977
2014-07-11 14:16:32,970 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:32,971 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:32,972 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:33,013 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7025
2014-07-11 14:16:33,013 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 7025
2014-07-11 14:16:33,016 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:33,040 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 6993 is 23334
2014-07-11 14:16:33,040 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 6993 directly to driver
2014-07-11 14:16:33,040 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 6993
2014-07-11 14:16:33,040 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:33,041 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:33,042 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:33,084 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7041
2014-07-11 14:16:33,084 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 7041
2014-07-11 14:16:33,087 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:33,116 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:33,116 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:33,117 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:33,118 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7009 is 23250
2014-07-11 14:16:33,118 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7009 directly to driver
2014-07-11 14:16:33,118 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7009
2014-07-11 14:16:33,153 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7057
2014-07-11 14:16:33,154 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7057
2014-07-11 14:16:33,155 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:33,180 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:33,180 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:33,181 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7025 is 22914
2014-07-11 14:16:33,181 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 7025 directly to driver
2014-07-11 14:16:33,181 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 7025
2014-07-11 14:16:33,181 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:33,223 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7073
2014-07-11 14:16:33,223 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 7073
2014-07-11 14:16:33,226 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:33,250 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:33,251 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:33,252 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:33,257 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7041 is 23483
2014-07-11 14:16:33,257 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 7041 directly to driver
2014-07-11 14:16:33,257 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 7041
2014-07-11 14:16:33,295 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7089
2014-07-11 14:16:33,295 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 7089
2014-07-11 14:16:33,298 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:33,315 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7057 is 23040
2014-07-11 14:16:33,316 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7057 directly to driver
2014-07-11 14:16:33,316 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7057
2014-07-11 14:16:33,322 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:33,322 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:33,323 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:33,390 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7073 is 22048
2014-07-11 14:16:33,390 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 7073 directly to driver
2014-07-11 14:16:33,390 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 7073
2014-07-11 14:16:33,529 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7089 is 23208
2014-07-11 14:16:33,529 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 7089 directly to driver
2014-07-11 14:16:33,529 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 7089
2014-07-11 14:16:46,801 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 12 for deleting
2014-07-11 14:16:46,804 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 11 for deleting
2014-07-11 14:16:54,376 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7400
2014-07-11 14:16:54,377 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 7400
2014-07-11 14:16:54,380 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,411 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 14 and clearing cache
2014-07-11 14:16:54,411 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 13, fetching them
2014-07-11 14:16:54,411 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:16:54,448 [Executor task launch worker-8] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:16:54,448 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,448 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7416
2014-07-11 14:16:54,449 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 7416
2014-07-11 14:16:54,449 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,450 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:54,452 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,483 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,483 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,484 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:54,522 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7432
2014-07-11 14:16:54,522 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7432
2014-07-11 14:16:54,525 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,550 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,550 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,551 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:54,589 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7448
2014-07-11 14:16:54,589 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 7448
2014-07-11 14:16:54,592 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,593 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7400 is 23567
2014-07-11 14:16:54,593 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 7400 directly to driver
2014-07-11 14:16:54,593 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 7400
2014-07-11 14:16:54,622 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7416 is 23525
2014-07-11 14:16:54,623 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 7416 directly to driver
2014-07-11 14:16:54,623 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 7416
2014-07-11 14:16:54,623 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,623 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,624 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:54,657 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7464
2014-07-11 14:16:54,657 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 7464
2014-07-11 14:16:54,660 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,687 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,687 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,689 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:54,705 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7432 is 22809
2014-07-11 14:16:54,705 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7432 directly to driver
2014-07-11 14:16:54,706 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7432
2014-07-11 14:16:54,734 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7480
2014-07-11 14:16:54,734 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7480
2014-07-11 14:16:54,736 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,764 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,764 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7448 is 22914
2014-07-11 14:16:54,764 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 7448 directly to driver
2014-07-11 14:16:54,764 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 7448
2014-07-11 14:16:54,765 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,766 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:54,806 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7496
2014-07-11 14:16:54,806 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 7496
2014-07-11 14:16:54,809 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,832 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,833 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,834 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:54,843 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7464 is 22956
2014-07-11 14:16:54,843 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 7464 directly to driver
2014-07-11 14:16:54,843 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 7464
2014-07-11 14:16:54,874 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7512
2014-07-11 14:16:54,875 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 7512
2014-07-11 14:16:54,878 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,903 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,904 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,905 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:16:54,928 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7480 is 23208
2014-07-11 14:16:54,928 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7480 directly to driver
2014-07-11 14:16:54,928 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7480
2014-07-11 14:16:54,947 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7528
2014-07-11 14:16:54,947 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7528
2014-07-11 14:16:54,950 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:54,977 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:54,978 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:54,979 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7496 is 21394
2014-07-11 14:16:54,979 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 7496 directly to driver
2014-07-11 14:16:54,979 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 7496
2014-07-11 14:16:54,979 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:55,014 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7544
2014-07-11 14:16:55,014 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 7544
2014-07-11 14:16:55,017 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:55,046 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:55,047 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:55,049 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:16:55,057 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7512 is 23208
2014-07-11 14:16:55,057 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 7512 directly to driver
2014-07-11 14:16:55,057 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 7512
2014-07-11 14:16:55,090 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7560
2014-07-11 14:16:55,090 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 7560
2014-07-11 14:16:55,093 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:55,120 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:55,120 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:55,122 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:55,132 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7528 is 22725
2014-07-11 14:16:55,133 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7528 directly to driver
2014-07-11 14:16:55,133 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7528
2014-07-11 14:16:55,152 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7576
2014-07-11 14:16:55,152 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7576
2014-07-11 14:16:55,155 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:55,180 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:55,181 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:55,182 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:55,186 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7544 is 23271
2014-07-11 14:16:55,186 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 7544 directly to driver
2014-07-11 14:16:55,186 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 7544
2014-07-11 14:16:55,212 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7592
2014-07-11 14:16:55,212 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 7592
2014-07-11 14:16:55,215 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:16:55,240 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:16:55,241 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:16:55,242 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:16:55,273 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7560 is 23376
2014-07-11 14:16:55,273 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 7560 directly to driver
2014-07-11 14:16:55,273 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 7560
2014-07-11 14:16:55,333 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7576 is 22704
2014-07-11 14:16:55,333 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7576 directly to driver
2014-07-11 14:16:55,333 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7576
2014-07-11 14:16:55,385 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7592 is 22617
2014-07-11 14:16:55,385 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 7592 directly to driver
2014-07-11 14:16:55,385 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 7592
2014-07-11 14:17:17,131 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7905
2014-07-11 14:17:17,131 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 7905
2014-07-11 14:17:17,135 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,164 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 15 and clearing cache
2014-07-11 14:17:17,164 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 14, fetching them
2014-07-11 14:17:17,164 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:17:17,202 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7921
2014-07-11 14:17:17,203 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7921
2014-07-11 14:17:17,206 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,209 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:17:17,209 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,210 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,211 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:17,234 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,235 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,236 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:17,272 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7937
2014-07-11 14:17:17,273 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 7937
2014-07-11 14:17:17,276 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,306 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,307 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,308 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:17,344 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7953
2014-07-11 14:17:17,345 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 7953
2014-07-11 14:17:17,347 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,355 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7905 is 21056
2014-07-11 14:17:17,355 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 7905 directly to driver
2014-07-11 14:17:17,355 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 7905
2014-07-11 14:17:17,378 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,379 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,380 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:17,394 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7921 is 21922
2014-07-11 14:17:17,394 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7921 directly to driver
2014-07-11 14:17:17,394 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7921
2014-07-11 14:17:17,413 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7969
2014-07-11 14:17:17,413 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 7969
2014-07-11 14:17:17,416 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,462 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,462 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,463 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:17,484 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 7985
2014-07-11 14:17:17,484 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 7985
2014-07-11 14:17:17,487 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,503 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7937 is 23418
2014-07-11 14:17:17,504 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 7937 directly to driver
2014-07-11 14:17:17,504 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 7937
2014-07-11 14:17:17,510 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,511 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,512 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:17,552 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8001
2014-07-11 14:17:17,552 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 8001
2014-07-11 14:17:17,554 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7953 is 24772
2014-07-11 14:17:17,554 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 7953 directly to driver
2014-07-11 14:17:17,554 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 7953
2014-07-11 14:17:17,555 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,580 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,580 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,581 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:17,602 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7969 is 22767
2014-07-11 14:17:17,602 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 7969 directly to driver
2014-07-11 14:17:17,602 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 7969
2014-07-11 14:17:17,621 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8017
2014-07-11 14:17:17,621 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8017
2014-07-11 14:17:17,624 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,650 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 7985 is 23397
2014-07-11 14:17:17,650 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,650 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 7985 directly to driver
2014-07-11 14:17:17,650 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 7985
2014-07-11 14:17:17,650 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,651 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:17,692 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8033
2014-07-11 14:17:17,693 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 8033
2014-07-11 14:17:17,695 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,721 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,721 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,722 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8001 is 24116
2014-07-11 14:17:17,722 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 8001 directly to driver
2014-07-11 14:17:17,722 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 8001
2014-07-11 14:17:17,722 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:17,762 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8049
2014-07-11 14:17:17,762 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 8049
2014-07-11 14:17:17,764 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,790 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,791 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,791 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8017 is 22746
2014-07-11 14:17:17,791 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8017 directly to driver
2014-07-11 14:17:17,791 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8017
2014-07-11 14:17:17,792 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:17,834 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8065
2014-07-11 14:17:17,834 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8065
2014-07-11 14:17:17,837 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,856 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8033 is 21901
2014-07-11 14:17:17,856 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 8033 directly to driver
2014-07-11 14:17:17,856 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 8033
2014-07-11 14:17:17,866 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,866 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,867 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:17,903 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8081
2014-07-11 14:17:17,904 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 8081
2014-07-11 14:17:17,906 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,923 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8049 is 23040
2014-07-11 14:17:17,923 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 8049 directly to driver
2014-07-11 14:17:17,923 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 8049
2014-07-11 14:17:17,931 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,931 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,932 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:17,965 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8097
2014-07-11 14:17:17,965 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 8097
2014-07-11 14:17:17,968 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:17,997 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:17,997 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:17,998 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:18,011 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8065 is 21499
2014-07-11 14:17:18,011 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8065 directly to driver
2014-07-11 14:17:18,011 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8065
2014-07-11 14:17:18,069 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8081 is 24242
2014-07-11 14:17:18,069 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 8081 directly to driver
2014-07-11 14:17:18,069 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 8081
2014-07-11 14:17:18,131 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8097 is 23166
2014-07-11 14:17:18,131 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 8097 directly to driver
2014-07-11 14:17:18,131 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 8097
2014-07-11 14:17:18,441 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 13 for deleting
2014-07-11 14:17:39,169 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8412
2014-07-11 14:17:39,169 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 8412
2014-07-11 14:17:39,172 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,198 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 16 and clearing cache
2014-07-11 14:17:39,198 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 15, fetching them
2014-07-11 14:17:39,198 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:17:39,237 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8428
2014-07-11 14:17:39,237 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 8428
2014-07-11 14:17:39,240 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,251 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:17:39,251 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,252 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,255 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:17:39,272 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,273 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,273 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:39,312 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8444
2014-07-11 14:17:39,312 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8444
2014-07-11 14:17:39,316 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,340 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,341 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,342 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:39,376 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8460
2014-07-11 14:17:39,376 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 8460
2014-07-11 14:17:39,378 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,402 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8412 is 23019
2014-07-11 14:17:39,402 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 8412 directly to driver
2014-07-11 14:17:39,402 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 8412
2014-07-11 14:17:39,406 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,407 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,408 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:39,409 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8428 is 23019
2014-07-11 14:17:39,409 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 8428 directly to driver
2014-07-11 14:17:39,409 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 8428
2014-07-11 14:17:39,444 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8476
2014-07-11 14:17:39,444 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 8476
2014-07-11 14:17:39,447 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,471 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,472 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,473 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:39,484 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8444 is 22132
2014-07-11 14:17:39,484 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8444 directly to driver
2014-07-11 14:17:39,484 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8444
2014-07-11 14:17:39,515 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8492
2014-07-11 14:17:39,515 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8492
2014-07-11 14:17:39,518 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,542 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,542 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,543 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8460 is 22893
2014-07-11 14:17:39,543 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 8460 directly to driver
2014-07-11 14:17:39,543 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:39,543 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 8460
2014-07-11 14:17:39,584 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8508
2014-07-11 14:17:39,584 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 8508
2014-07-11 14:17:39,587 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,608 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8476 is 22449
2014-07-11 14:17:39,608 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 8476 directly to driver
2014-07-11 14:17:39,608 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 8476
2014-07-11 14:17:39,611 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,611 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,612 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:39,657 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8524
2014-07-11 14:17:39,657 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 8524
2014-07-11 14:17:39,660 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,687 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,687 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8492 is 23969
2014-07-11 14:17:39,687 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8492 directly to driver
2014-07-11 14:17:39,687 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8492
2014-07-11 14:17:39,687 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,688 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:39,727 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8540
2014-07-11 14:17:39,727 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8540
2014-07-11 14:17:39,730 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,748 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8508 is 22914
2014-07-11 14:17:39,748 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 8508 directly to driver
2014-07-11 14:17:39,748 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 8508
2014-07-11 14:17:39,757 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,758 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,759 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:39,797 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8556
2014-07-11 14:17:39,797 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 8556
2014-07-11 14:17:39,800 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,826 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8524 is 23822
2014-07-11 14:17:39,826 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 8524 directly to driver
2014-07-11 14:17:39,826 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 8524
2014-07-11 14:17:39,827 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,827 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,828 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:39,868 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8572
2014-07-11 14:17:39,868 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 8572
2014-07-11 14:17:39,870 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,894 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,895 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,896 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8540 is 23525
2014-07-11 14:17:39,896 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8540 directly to driver
2014-07-11 14:17:39,896 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8540
2014-07-11 14:17:39,896 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:39,935 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8588
2014-07-11 14:17:39,935 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8588
2014-07-11 14:17:39,938 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:39,960 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8556 is 22237
2014-07-11 14:17:39,960 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 8556 directly to driver
2014-07-11 14:17:39,960 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 8556
2014-07-11 14:17:39,966 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:39,967 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:39,968 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:40,031 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8572 is 23696
2014-07-11 14:17:40,031 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 8572 directly to driver
2014-07-11 14:17:40,031 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 8572
2014-07-11 14:17:40,108 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8588 is 23780
2014-07-11 14:17:40,109 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8588 directly to driver
2014-07-11 14:17:40,109 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8588
2014-07-11 14:17:54,660 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8903
2014-07-11 14:17:54,660 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8903
2014-07-11 14:17:54,662 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:54,685 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 17 and clearing cache
2014-07-11 14:17:54,686 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 16, fetching them
2014-07-11 14:17:54,686 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:17:54,753 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 15 for deleting
2014-07-11 14:17:54,791 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8919
2014-07-11 14:17:54,792 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 8919
2014-07-11 14:17:54,795 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:54,820 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 16, fetching them
2014-07-11 14:17:54,829 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 14 for deleting
2014-07-11 14:17:54,833 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:17:54,834 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:54,834 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:54,835 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:54,835 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:54,837 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:17:54,837 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:17:54,866 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8935
2014-07-11 14:17:54,866 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 8935
2014-07-11 14:17:54,869 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:54,896 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:54,897 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:54,898 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:54,930 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8951
2014-07-11 14:17:54,930 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 8951
2014-07-11 14:17:54,932 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:54,961 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:54,961 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:54,962 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:54,979 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8919 is 23292
2014-07-11 14:17:54,979 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 8919 directly to driver
2014-07-11 14:17:54,979 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 8919
2014-07-11 14:17:54,989 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8903 is 23376
2014-07-11 14:17:54,989 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8903 directly to driver
2014-07-11 14:17:54,989 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8903
2014-07-11 14:17:54,998 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8967
2014-07-11 14:17:54,998 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 8967
2014-07-11 14:17:55,001 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,028 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,028 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,029 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:55,045 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8935 is 22830
2014-07-11 14:17:55,045 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 8935 directly to driver
2014-07-11 14:17:55,045 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 8935
2014-07-11 14:17:55,068 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8983
2014-07-11 14:17:55,068 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 8983
2014-07-11 14:17:55,071 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,097 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,098 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,099 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:55,100 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8951 is 21562
2014-07-11 14:17:55,101 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 8951 directly to driver
2014-07-11 14:17:55,101 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 8951
2014-07-11 14:17:55,138 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 8999
2014-07-11 14:17:55,138 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 8999
2014-07-11 14:17:55,141 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,168 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,168 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,169 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:55,176 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8967 is 22428
2014-07-11 14:17:55,176 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 8967 directly to driver
2014-07-11 14:17:55,176 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 8967
2014-07-11 14:17:55,206 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9015
2014-07-11 14:17:55,207 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 9015
2014-07-11 14:17:55,208 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,232 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,233 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8983 is 23187
2014-07-11 14:17:55,233 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 8983 directly to driver
2014-07-11 14:17:55,233 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 8983
2014-07-11 14:17:55,233 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,235 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:17:55,277 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9031
2014-07-11 14:17:55,277 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9031
2014-07-11 14:17:55,280 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,306 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 8999 is 21329
2014-07-11 14:17:55,306 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 8999 directly to driver
2014-07-11 14:17:55,306 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 8999
2014-07-11 14:17:55,307 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,308 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,309 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:55,348 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9047
2014-07-11 14:17:55,349 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 9047
2014-07-11 14:17:55,352 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,378 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,378 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,379 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:55,381 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9015 is 22491
2014-07-11 14:17:55,381 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 9015 directly to driver
2014-07-11 14:17:55,382 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 9015
2014-07-11 14:17:55,420 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9063
2014-07-11 14:17:55,420 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 9063
2014-07-11 14:17:55,423 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,443 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9031 is 22704
2014-07-11 14:17:55,443 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9031 directly to driver
2014-07-11 14:17:55,443 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9031
2014-07-11 14:17:55,449 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,450 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,451 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:17:55,489 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9079
2014-07-11 14:17:55,489 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9079
2014-07-11 14:17:55,492 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,512 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9047 is 21245
2014-07-11 14:17:55,512 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 9047 directly to driver
2014-07-11 14:17:55,513 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 9047
2014-07-11 14:17:55,518 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,518 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,519 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:55,559 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9095
2014-07-11 14:17:55,559 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 9095
2014-07-11 14:17:55,562 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:17:55,589 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:17:55,589 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:17:55,590 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:17:55,599 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9063 is 23651
2014-07-11 14:17:55,599 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 9063 directly to driver
2014-07-11 14:17:55,599 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 9063
2014-07-11 14:17:55,651 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9079 is 22321
2014-07-11 14:17:55,651 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9079 directly to driver
2014-07-11 14:17:55,651 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9079
2014-07-11 14:17:55,719 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9095 is 23082
2014-07-11 14:17:55,719 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 9095 directly to driver
2014-07-11 14:17:55,719 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 9095
2014-07-11 14:18:09,906 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9414
2014-07-11 14:18:09,906 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 9414
2014-07-11 14:18:09,909 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:09,940 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 18 and clearing cache
2014-07-11 14:18:09,940 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 17, fetching them
2014-07-11 14:18:09,941 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:18:09,976 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9430
2014-07-11 14:18:09,976 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9430
2014-07-11 14:18:09,979 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:09,987 [Executor task launch worker-16] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:18:09,987 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:09,988 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:09,990 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 3 ms
2014-07-11 14:18:10,006 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,007 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,008 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:10,047 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9446
2014-07-11 14:18:10,048 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 9446
2014-07-11 14:18:10,051 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,077 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,078 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,079 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:10,113 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9462
2014-07-11 14:18:10,113 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 9462
2014-07-11 14:18:10,116 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,132 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9414 is 23208
2014-07-11 14:18:10,132 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 9414 directly to driver
2014-07-11 14:18:10,132 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 9414
2014-07-11 14:18:10,141 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,141 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,142 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:10,145 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9430 is 22935
2014-07-11 14:18:10,145 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9430 directly to driver
2014-07-11 14:18:10,145 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9430
2014-07-11 14:18:10,181 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9478
2014-07-11 14:18:10,181 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9478
2014-07-11 14:18:10,184 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,208 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,209 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,210 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:10,214 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9446 is 22258
2014-07-11 14:18:10,214 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 9446 directly to driver
2014-07-11 14:18:10,215 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 9446
2014-07-11 14:18:10,253 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9494
2014-07-11 14:18:10,253 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 9494
2014-07-11 14:18:10,256 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,276 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9462 is 22872
2014-07-11 14:18:10,276 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 9462 directly to driver
2014-07-11 14:18:10,276 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 9462
2014-07-11 14:18:10,280 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,281 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,282 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:10,325 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9510
2014-07-11 14:18:10,325 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 9510
2014-07-11 14:18:10,328 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,348 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9478 is 22554
2014-07-11 14:18:10,348 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9478 directly to driver
2014-07-11 14:18:10,348 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9478
2014-07-11 14:18:10,351 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,352 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,353 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:10,394 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9526
2014-07-11 14:18:10,395 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9526
2014-07-11 14:18:10,398 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,426 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,426 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,426 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9494 is 22830
2014-07-11 14:18:10,426 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 9494 directly to driver
2014-07-11 14:18:10,426 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 9494
2014-07-11 14:18:10,427 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:10,464 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9542
2014-07-11 14:18:10,465 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 9542
2014-07-11 14:18:10,468 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,488 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9510 is 22195
2014-07-11 14:18:10,488 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 9510 directly to driver
2014-07-11 14:18:10,488 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 9510
2014-07-11 14:18:10,496 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,496 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,497 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:10,534 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9558
2014-07-11 14:18:10,534 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 9558
2014-07-11 14:18:10,536 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,560 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,561 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9526 is 21754
2014-07-11 14:18:10,561 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,561 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9526 directly to driver
2014-07-11 14:18:10,561 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9526
2014-07-11 14:18:10,562 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:10,604 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9574
2014-07-11 14:18:10,604 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9574
2014-07-11 14:18:10,607 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,635 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,635 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,636 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:10,637 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9542 is 21922
2014-07-11 14:18:10,637 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 9542 directly to driver
2014-07-11 14:18:10,637 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 9542
2014-07-11 14:18:10,673 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9590
2014-07-11 14:18:10,673 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 9590
2014-07-11 14:18:10,676 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:10,697 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9558 is 23418
2014-07-11 14:18:10,697 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 9558 directly to driver
2014-07-11 14:18:10,697 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 9558
2014-07-11 14:18:10,701 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:10,701 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:10,702 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:10,769 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9574 is 23609
2014-07-11 14:18:10,769 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9574 directly to driver
2014-07-11 14:18:10,769 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9574
2014-07-11 14:18:10,835 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9590 is 22767
2014-07-11 14:18:10,835 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 9590 directly to driver
2014-07-11 14:18:10,835 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 9590
2014-07-11 14:18:16,669 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 17 for deleting
2014-07-11 14:18:16,674 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 16 for deleting
2014-07-11 14:18:24,229 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9907
2014-07-11 14:18:24,229 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 9907
2014-07-11 14:18:24,232 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,263 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 19 and clearing cache
2014-07-11 14:18:24,263 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 18, fetching them
2014-07-11 14:18:24,263 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:18:24,297 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9923
2014-07-11 14:18:24,298 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9923
2014-07-11 14:18:24,301 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,317 [Executor task launch worker-11] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:18:24,318 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,318 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,319 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:24,332 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,333 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,333 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:24,370 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9939
2014-07-11 14:18:24,370 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 9939
2014-07-11 14:18:24,373 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,399 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,399 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,400 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:24,439 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9955
2014-07-11 14:18:24,439 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 9955
2014-07-11 14:18:24,443 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,468 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9907 is 22935
2014-07-11 14:18:24,468 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 9907 directly to driver
2014-07-11 14:18:24,468 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 9907
2014-07-11 14:18:24,469 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9923 is 22956
2014-07-11 14:18:24,469 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9923 directly to driver
2014-07-11 14:18:24,469 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9923
2014-07-11 14:18:24,474 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,474 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,475 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:24,513 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9971
2014-07-11 14:18:24,513 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 9971
2014-07-11 14:18:24,529 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,550 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9939 is 22683
2014-07-11 14:18:24,551 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 9939 directly to driver
2014-07-11 14:18:24,551 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 9939
2014-07-11 14:18:24,561 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,562 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,563 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:24,582 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 9987
2014-07-11 14:18:24,583 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 9987
2014-07-11 14:18:24,585 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,609 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,610 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,611 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:24,619 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9955 is 22746
2014-07-11 14:18:24,619 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 9955 directly to driver
2014-07-11 14:18:24,620 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 9955
2014-07-11 14:18:24,652 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10003
2014-07-11 14:18:24,653 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 10003
2014-07-11 14:18:24,655 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,680 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,680 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,681 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:24,700 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9971 is 21838
2014-07-11 14:18:24,700 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 9971 directly to driver
2014-07-11 14:18:24,700 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 9971
2014-07-11 14:18:24,719 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10019
2014-07-11 14:18:24,719 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 10019
2014-07-11 14:18:24,722 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,746 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 9987 is 23271
2014-07-11 14:18:24,747 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 9987 directly to driver
2014-07-11 14:18:24,747 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 9987
2014-07-11 14:18:24,748 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,748 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,749 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:24,792 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10035
2014-07-11 14:18:24,792 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 10035
2014-07-11 14:18:24,794 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,818 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10003 is 22470
2014-07-11 14:18:24,818 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 10003 directly to driver
2014-07-11 14:18:24,818 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 10003
2014-07-11 14:18:24,819 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,820 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,821 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:24,862 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10051
2014-07-11 14:18:24,863 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 10051
2014-07-11 14:18:24,866 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,890 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10019 is 22300
2014-07-11 14:18:24,890 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 10019 directly to driver
2014-07-11 14:18:24,890 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 10019
2014-07-11 14:18:24,890 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,890 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,891 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:24,933 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10067
2014-07-11 14:18:24,933 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 10067
2014-07-11 14:18:24,936 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:24,957 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10035 is 23441
2014-07-11 14:18:24,957 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 10035 directly to driver
2014-07-11 14:18:24,957 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 10035
2014-07-11 14:18:24,960 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:24,961 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:24,962 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:25,000 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10083
2014-07-11 14:18:25,001 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 10083
2014-07-11 14:18:25,003 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:25,028 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:25,029 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10051 is 23906
2014-07-11 14:18:25,029 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 10051 directly to driver
2014-07-11 14:18:25,029 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:25,029 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 10051
2014-07-11 14:18:25,030 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:25,097 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10067 is 22662
2014-07-11 14:18:25,097 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 10067 directly to driver
2014-07-11 14:18:25,097 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 10067
2014-07-11 14:18:25,165 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10083 is 23145
2014-07-11 14:18:25,165 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 10083 directly to driver
2014-07-11 14:18:25,165 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 10083
2014-07-11 14:18:45,567 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10405
2014-07-11 14:18:45,567 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 10405
2014-07-11 14:18:45,570 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:45,597 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Updating epoch to 20 and clearing cache
2014-07-11 14:18:45,597 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Don't have map outputs for shuffle 19, fetching them
2014-07-11 14:18:45,597 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Doing the fetch; tracker actor = Actor[akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274/user/MapOutputTracker#-1480103703]
2014-07-11 14:18:45,637 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10421
2014-07-11 14:18:45,637 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 10421
2014-07-11 14:18:45,640 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:45,648 [Executor task launch worker-12] INFO  org.apache.spark.MapOutputTrackerWorker - Got the output locations
2014-07-11 14:18:45,649 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:45,649 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:45,652 [Executor task launch worker-12] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 4 ms
2014-07-11 14:18:45,667 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:45,668 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:45,669 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:45,706 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10437
2014-07-11 14:18:45,706 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 10437
2014-07-11 14:18:45,710 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:45,742 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:45,742 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:45,743 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:45,775 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10453
2014-07-11 14:18:45,775 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 10453
2014-07-11 14:18:45,778 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:45,788 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10405 is 21056
2014-07-11 14:18:45,788 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 10405 directly to driver
2014-07-11 14:18:45,788 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 10405
2014-07-11 14:18:45,802 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10421 is 21922
2014-07-11 14:18:45,802 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 10421 directly to driver
2014-07-11 14:18:45,802 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 10421
2014-07-11 14:18:45,803 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:45,803 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:45,804 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:45,844 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10469
2014-07-11 14:18:45,845 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 10469
2014-07-11 14:18:45,847 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:45,871 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:45,872 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:45,873 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:45,880 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10437 is 23418
2014-07-11 14:18:45,880 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 10437 directly to driver
2014-07-11 14:18:45,880 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 10437
2014-07-11 14:18:45,916 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10485
2014-07-11 14:18:45,916 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 10485
2014-07-11 14:18:45,919 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:45,944 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10453 is 24772
2014-07-11 14:18:45,944 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 10453 directly to driver
2014-07-11 14:18:45,944 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 10453
2014-07-11 14:18:45,947 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:45,948 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:45,949 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:45,984 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10501
2014-07-11 14:18:45,984 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 10501
2014-07-11 14:18:45,987 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:46,010 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10469 is 22767
2014-07-11 14:18:46,010 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 10469 directly to driver
2014-07-11 14:18:46,010 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 10469
2014-07-11 14:18:46,010 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:46,011 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:46,012 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:46,056 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10517
2014-07-11 14:18:46,056 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 10517
2014-07-11 14:18:46,058 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:46,082 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:46,083 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:46,084 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:46,092 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10485 is 23397
2014-07-11 14:18:46,092 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 10485 directly to driver
2014-07-11 14:18:46,092 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 10485
2014-07-11 14:18:46,128 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10533
2014-07-11 14:18:46,128 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 10533
2014-07-11 14:18:46,131 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:46,152 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10501 is 24116
2014-07-11 14:18:46,152 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 10501 directly to driver
2014-07-11 14:18:46,152 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 10501
2014-07-11 14:18:46,157 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:46,158 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:46,159 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:46,194 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10549
2014-07-11 14:18:46,194 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 10549
2014-07-11 14:18:46,196 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:46,220 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:46,220 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:46,221 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10517 is 22746
2014-07-11 14:18:46,221 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 10517 directly to driver
2014-07-11 14:18:46,221 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 10517
2014-07-11 14:18:46,221 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:46,263 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10565
2014-07-11 14:18:46,263 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 10565
2014-07-11 14:18:46,266 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:46,291 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:46,291 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:46,292 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10533 is 21901
2014-07-11 14:18:46,292 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 10533 directly to driver
2014-07-11 14:18:46,292 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 10533
2014-07-11 14:18:46,292 [Executor task launch worker-8] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 1 ms
2014-07-11 14:18:46,337 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10581
2014-07-11 14:18:46,337 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 10581
2014-07-11 14:18:46,339 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:46,359 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10549 is 23040
2014-07-11 14:18:46,359 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 10549 directly to driver
2014-07-11 14:18:46,359 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 10549
2014-07-11 14:18:46,365 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:46,365 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:46,366 [Executor task launch worker-16] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:46,397 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10597
2014-07-11 14:18:46,397 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 10597
2014-07-11 14:18:46,400 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockManager - Found block broadcast_0 locally
2014-07-11 14:18:46,427 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2014-07-11 14:18:46,427 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10565 is 21499
2014-07-11 14:18:46,427 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 10565 directly to driver
2014-07-11 14:18:46,427 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 10565
2014-07-11 14:18:46,428 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Getting 300 non-empty blocks out of 300 blocks
2014-07-11 14:18:46,429 [Executor task launch worker-11] INFO  org.apache.spark.storage.BlockFetcherIterator$BasicBlockFetcherIterator - Started 3 remote fetches in 2 ms
2014-07-11 14:18:46,443 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 18 for deleting
2014-07-11 14:18:46,509 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10581 is 24242
2014-07-11 14:18:46,509 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 10581 directly to driver
2014-07-11 14:18:46,509 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 10581
2014-07-11 14:18:46,560 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10597 is 23166
2014-07-11 14:18:46,560 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 10597 directly to driver
2014-07-11 14:18:46,560 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 10597
2014-07-11 14:18:52,721 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10600
2014-07-11 14:18:52,721 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Running task ID 10600
2014-07-11 14:18:52,721 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10616
2014-07-11 14:18:52,722 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Running task ID 10616
2014-07-11 14:18:52,722 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10632
2014-07-11 14:18:52,722 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Running task ID 10632
2014-07-11 14:18:52,723 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10648
2014-07-11 14:18:52,723 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Running task ID 10648
2014-07-11 14:18:52,724 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10664
2014-07-11 14:18:52,725 [sparkExecutor-akka.actor.default-dispatcher-16] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10680
2014-07-11 14:18:52,725 [Executor task launch worker-17] INFO  org.apache.spark.executor.Executor - Running task ID 10664
2014-07-11 14:18:52,726 [Executor task launch worker-18] INFO  org.apache.spark.executor.Executor - Running task ID 10680
2014-07-11 14:18:52,726 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10696
2014-07-11 14:18:52,727 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10712
2014-07-11 14:18:52,728 [Executor task launch worker-19] INFO  org.apache.spark.executor.Executor - Running task ID 10696
2014-07-11 14:18:52,728 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10728
2014-07-11 14:18:52,729 [Executor task launch worker-20] INFO  org.apache.spark.executor.Executor - Running task ID 10712
2014-07-11 14:18:52,729 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10744
2014-07-11 14:18:52,730 [Executor task launch worker-21] INFO  org.apache.spark.executor.Executor - Running task ID 10728
2014-07-11 14:18:52,731 [Executor task launch worker-22] INFO  org.apache.spark.executor.Executor - Running task ID 10744
2014-07-11 14:18:52,731 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10760
2014-07-11 14:18:52,733 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10776
2014-07-11 14:18:52,734 [Executor task launch worker-23] INFO  org.apache.spark.executor.Executor - Running task ID 10760
2014-07-11 14:18:52,734 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Got assigned task 10792
2014-07-11 14:18:52,735 [Executor task launch worker-24] INFO  org.apache.spark.executor.Executor - Running task ID 10776
2014-07-11 14:18:52,735 [Executor task launch worker-25] INFO  org.apache.spark.executor.Executor - Running task ID 10792
2014-07-11 14:18:52,821 [Executor task launch worker-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2014-07-11 14:18:52,822 [Executor task launch worker-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2014-07-11 14:18:52,823 [Executor task launch worker-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2014-07-11 14:18:52,827 [Executor task launch worker-24] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2014-07-11 14:18:54,372 [Executor task launch worker-18] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000081_10680' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000081
2014-07-11 14:18:54,373 [Executor task launch worker-18] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000081_10680: Committed
2014-07-11 14:18:54,375 [Executor task launch worker-18] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10680 is 535
2014-07-11 14:18:54,375 [Executor task launch worker-18] INFO  org.apache.spark.executor.Executor - Sending result for 10680 directly to driver
2014-07-11 14:18:54,375 [Executor task launch worker-18] INFO  org.apache.spark.executor.Executor - Finished task ID 10680
2014-07-11 14:18:54,376 [Executor task launch worker-24] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000177_10776' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000177
2014-07-11 14:18:54,377 [Executor task launch worker-24] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000177_10776: Committed
2014-07-11 14:18:54,379 [Executor task launch worker-24] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10776 is 535
2014-07-11 14:18:54,379 [Executor task launch worker-24] INFO  org.apache.spark.executor.Executor - Sending result for 10776 directly to driver
2014-07-11 14:18:54,379 [Executor task launch worker-24] INFO  org.apache.spark.executor.Executor - Finished task ID 10776
2014-07-11 14:18:54,384 [Executor task launch worker-20] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000113_10712' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000113
2014-07-11 14:18:54,384 [Executor task launch worker-20] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000113_10712: Committed
2014-07-11 14:18:54,386 [Executor task launch worker-20] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10712 is 535
2014-07-11 14:18:54,386 [Executor task launch worker-20] INFO  org.apache.spark.executor.Executor - Sending result for 10712 directly to driver
2014-07-11 14:18:54,386 [Executor task launch worker-20] INFO  org.apache.spark.executor.Executor - Finished task ID 10712
2014-07-11 14:18:54,543 [Executor task launch worker-11] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000001_10600' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000001
2014-07-11 14:18:54,543 [Executor task launch worker-11] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000001_10600: Committed
2014-07-11 14:18:54,544 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10600 is 535
2014-07-11 14:18:54,545 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Sending result for 10600 directly to driver
2014-07-11 14:18:54,545 [Executor task launch worker-11] INFO  org.apache.spark.executor.Executor - Finished task ID 10600
2014-07-11 14:18:54,576 [Executor task launch worker-22] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000145_10744' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000145
2014-07-11 14:18:54,576 [Executor task launch worker-22] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000145_10744: Committed
2014-07-11 14:18:54,576 [Executor task launch worker-25] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000193_10792' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000193
2014-07-11 14:18:54,576 [Executor task launch worker-12] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000049_10648' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000049
2014-07-11 14:18:54,576 [Executor task launch worker-25] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000193_10792: Committed
2014-07-11 14:18:54,576 [Executor task launch worker-12] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000049_10648: Committed
2014-07-11 14:18:54,578 [Executor task launch worker-22] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10744 is 535
2014-07-11 14:18:54,578 [Executor task launch worker-22] INFO  org.apache.spark.executor.Executor - Sending result for 10744 directly to driver
2014-07-11 14:18:54,578 [Executor task launch worker-22] INFO  org.apache.spark.executor.Executor - Finished task ID 10744
2014-07-11 14:18:54,578 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10648 is 535
2014-07-11 14:18:54,578 [Executor task launch worker-25] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10792 is 535
2014-07-11 14:18:54,578 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Sending result for 10648 directly to driver
2014-07-11 14:18:54,578 [Executor task launch worker-25] INFO  org.apache.spark.executor.Executor - Sending result for 10792 directly to driver
2014-07-11 14:18:54,578 [Executor task launch worker-12] INFO  org.apache.spark.executor.Executor - Finished task ID 10648
2014-07-11 14:18:54,578 [Executor task launch worker-25] INFO  org.apache.spark.executor.Executor - Finished task ID 10792
2014-07-11 14:18:54,584 [Executor task launch worker-23] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000161_10760' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000161
2014-07-11 14:18:54,584 [Executor task launch worker-23] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000161_10760: Committed
2014-07-11 14:18:54,585 [Executor task launch worker-23] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10760 is 535
2014-07-11 14:18:54,585 [Executor task launch worker-23] INFO  org.apache.spark.executor.Executor - Sending result for 10760 directly to driver
2014-07-11 14:18:54,585 [Executor task launch worker-23] INFO  org.apache.spark.executor.Executor - Finished task ID 10760
2014-07-11 14:18:54,592 [Executor task launch worker-17] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000065_10664' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000065
2014-07-11 14:18:54,592 [Executor task launch worker-8] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000033_10632' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000033
2014-07-11 14:18:54,592 [Executor task launch worker-17] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000065_10664: Committed
2014-07-11 14:18:54,593 [Executor task launch worker-19] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000097_10696' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000097
2014-07-11 14:18:54,593 [Executor task launch worker-8] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000033_10632: Committed
2014-07-11 14:18:54,593 [Executor task launch worker-19] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000097_10696: Committed
2014-07-11 14:18:54,593 [Executor task launch worker-16] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000017_10616' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000017
2014-07-11 14:18:54,593 [Executor task launch worker-21] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_201407111418_0000_m_000129_10728' to hdfs://dco-node121.dco.ethz.ch:54310/output_lda/_temporary/0/task_201407111418_0000_m_000129
2014-07-11 14:18:54,593 [Executor task launch worker-16] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000017_10616: Committed
2014-07-11 14:18:54,593 [Executor task launch worker-21] INFO  org.apache.spark.SparkHadoopWriter - attempt_201407111418_0000_m_000129_10728: Committed
2014-07-11 14:18:54,595 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10632 is 535
2014-07-11 14:18:54,595 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Sending result for 10632 directly to driver
2014-07-11 14:18:54,595 [Executor task launch worker-8] INFO  org.apache.spark.executor.Executor - Finished task ID 10632
2014-07-11 14:18:54,595 [Executor task launch worker-17] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10664 is 535
2014-07-11 14:18:54,595 [Executor task launch worker-17] INFO  org.apache.spark.executor.Executor - Sending result for 10664 directly to driver
2014-07-11 14:18:54,595 [Executor task launch worker-19] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10696 is 535
2014-07-11 14:18:54,595 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10616 is 535
2014-07-11 14:18:54,595 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Sending result for 10616 directly to driver
2014-07-11 14:18:54,595 [Executor task launch worker-21] INFO  org.apache.spark.executor.Executor - Serialized size of result for 10728 is 535
2014-07-11 14:18:54,595 [Executor task launch worker-21] INFO  org.apache.spark.executor.Executor - Sending result for 10728 directly to driver
2014-07-11 14:18:54,595 [Executor task launch worker-19] INFO  org.apache.spark.executor.Executor - Sending result for 10696 directly to driver
2014-07-11 14:18:54,595 [Executor task launch worker-17] INFO  org.apache.spark.executor.Executor - Finished task ID 10664
2014-07-11 14:18:54,596 [Executor task launch worker-19] INFO  org.apache.spark.executor.Executor - Finished task ID 10696
2014-07-11 14:18:54,596 [Executor task launch worker-21] INFO  org.apache.spark.executor.Executor - Finished task ID 10728
2014-07-11 14:18:54,595 [Executor task launch worker-16] INFO  org.apache.spark.executor.Executor - Finished task ID 10616
2014-07-11 14:19:06,694 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 2 for deleting
2014-07-11 14:19:06,695 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.ShuffleBlockManager - Could not find files for shuffle 19 for deleting
2014-07-11 14:19:07,313 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274 got disassociated, removing it.
2014-07-11 14:19:07,314 [sparkMaster-akka.actor.default-dispatcher-48] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A36981-25#517595525] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-11 14:19:07,314 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140711141224-0002
2014-07-11 14:19:07,323 [sparkMaster-akka.actor.default-dispatcher-31] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:54274
]
2014-07-11 14:19:07,332 [sparkMaster-akka.actor.default-dispatcher-26] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:54274
]
2014-07-11 14:19:07,333 [sparkExecutor-akka.actor.default-dispatcher-3] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - Driver Disassociated [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274] disassociated! Shutting down.
2014-07-11 14:19:07,338 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:54274
]
2014-07-11 14:19:07,366 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-11 14:19:07,367 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-11 14:19:07,726 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140711141224-0002/9 finished with state FAILED message Command exited with code 1 exitStatus 1
2014-07-11 14:19:07,729 [sparkWorker-akka.actor.default-dispatcher-3] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A52413-10#-1799831731] was not delivered. [3] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-11 14:19:07,737 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:51946
]
2014-07-11 14:19:07,745 [sparkWorker-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:51946
]
2014-07-11 14:19:07,751 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:51946]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:51946
]
2014-07-11 14:19:09,230 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274 got disassociated, removing it.
2014-07-11 14:19:09,230 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274 got disassociated, removing it.
2014-07-11 14:19:09,230 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274 got disassociated, removing it.
2014-07-11 14:19:09,230 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:54274 got disassociated, removing it.
2014-07-11 14:19:09,230 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/4
2014-07-11 14:19:09,230 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/5
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/15
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/8
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/10
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/11
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/6
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/13
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/1
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/9
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/2
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/7
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/12
2014-07-11 14:19:09,231 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/3
2014-07-11 14:19:09,232 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/14
2014-07-11 14:19:09,232 [sparkMaster-akka.actor.default-dispatcher-25] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140711141224-0002/0
2014-07-11 14:19:09,235 [sparkWorker-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill unknown executor app-20140711141224-0002/9
2014-07-12 21:11:17,715 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:11:17,716 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:11:17,717 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:11:17,780 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:11:17,810 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:44773
2014-07-12 21:11:21,726 [main] WARN  org.apache.spark.SparkConf - 
SPARK_JAVA_OPTS was detected (set to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
2014-07-12 21:11:21,727 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.executor.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:11:21,727 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.driver.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:11:21,743 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:11:21,743 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:11:22,352 [spark-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:11:22,401 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-12 21:11:22,588 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]
2014-07-12 21:11:22,592 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]
2014-07-12 21:11:22,626 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2014-07-12 21:11:22,628 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2014-07-12 21:11:22,644 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-local-20140712211122-1d00
2014-07-12 21:11:22,649 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:11:22,679 [main] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 40594 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,40594)
2014-07-12 21:11:22,684 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:11:22,688 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:40594 with 40.3 GB RAM
2014-07-12 21:11:22,689 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:11:22,701 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:11:22,702 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:11:22,705 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:48369
2014-07-12 21:11:22,706 [main] INFO  org.apache.spark.broadcast.HttpBroadcast - Broadcast server started at http://172.31.109.131:48369
2014-07-12 21:11:22,713 [main] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-638db266-ea1f-4c27-aac1-f4cc83fe8600
2014-07-12 21:11:22,714 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:11:22,714 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:11:22,718 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:54658
2014-07-12 21:11:22,973 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:11:22,989 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2014-07-12 21:11:23,000 [main] INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://dco-node121-mgt.dco.ethz.ch:4040
2014-07-12 21:11:23,212 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:11:23,863 [main] INFO  org.apache.spark.scheduler.EventLoggingListener - Logging events to hdfs://dco-node121.dco.ethz.ch:54310/spark_event_log/spark-shell-1405192283308
2014-07-12 21:11:24,034 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Connecting to master spark://dco-node121.dco.ethz.ch:7077...
2014-07-12 21:11:24,054 [main] INFO  org.apache.spark.repl.SparkILoop - Created spark context..
2014-07-12 21:11:24,300 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Registering app Spark shell
2014-07-12 21:11:24,301 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Registered app Spark shell with ID app-20140712211124-0003
2014-07-12 21:11:24,303 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-12 21:11:24,303 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-12 21:11:24,303 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-12 21:11:24,303 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-12 21:11:24,304 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-12 21:11:24,304 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-12 21:11:24,304 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-12 21:11:24,304 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-12 21:11:24,304 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-12 21:11:24,304 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-12 21:11:24,305 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-12 21:11:24,305 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-12 21:11:24,305 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-12 21:11:24,305 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-12 21:11:24,305 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-12 21:11:24,306 [sparkMaster-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211124-0003/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-12 21:11:24,320 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Connected to Spark cluster with app ID app-20140712211124-0003
2014-07-12 21:11:24,322 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140712211124-0003/9 for Spark shell
2014-07-12 21:11:24,325 [ExecutorRunner for app-20140712211124-0003/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-12 21:11:24,324 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/0 on worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773 (dco-node131-mgt.dco.ethz.ch:51773) with 16 cores
2014-07-12 21:11:24,325 [ExecutorRunner for app-20140712211124-0003/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-12 21:11:24,328 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/0 on hostPort dco-node131-mgt.dco.ethz.ch:51773 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,328 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/1 on worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480 (dco-node126-mgt.dco.ethz.ch:60480) with 16 cores
2014-07-12 21:11:24,329 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/1 on hostPort dco-node126-mgt.dco.ethz.ch:60480 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,330 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/2 on worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839 (dco-node125-mgt.dco.ethz.ch:42839) with 16 cores
2014-07-12 21:11:24,330 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/2 on hostPort dco-node125-mgt.dco.ethz.ch:42839 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,331 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/3 on worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212 (dco-node123-mgt.dco.ethz.ch:58212) with 16 cores
2014-07-12 21:11:24,332 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/3 on hostPort dco-node123-mgt.dco.ethz.ch:58212 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,333 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/4 on worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580 (dco-node135-mgt.dco.ethz.ch:58580) with 16 cores
2014-07-12 21:11:24,334 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/4 on hostPort dco-node135-mgt.dco.ethz.ch:58580 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,334 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/5 on worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081 (dco-node133-mgt.dco.ethz.ch:48081) with 16 cores
2014-07-12 21:11:24,335 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/5 on hostPort dco-node133-mgt.dco.ethz.ch:48081 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,335 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/6 on worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082 (dco-node134-mgt.dco.ethz.ch:39082) with 16 cores
2014-07-12 21:11:24,336 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/6 on hostPort dco-node134-mgt.dco.ethz.ch:39082 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,337 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/7 on worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515 (dco-node127-mgt.dco.ethz.ch:34515) with 16 cores
2014-07-12 21:11:24,337 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/7 on hostPort dco-node127-mgt.dco.ethz.ch:34515 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,337 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/8 on worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548 (dco-node130-mgt.dco.ethz.ch:48548) with 16 cores
2014-07-12 21:11:24,338 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/8 on hostPort dco-node130-mgt.dco.ethz.ch:48548 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,338 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/9 on worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479 (dco-node121-mgt.dco.ethz.ch:60479) with 16 cores
2014-07-12 21:11:24,338 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/9 on hostPort dco-node121-mgt.dco.ethz.ch:60479 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,339 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/10 on worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757 (dco-node128-mgt.dco.ethz.ch:51757) with 16 cores
2014-07-12 21:11:24,339 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/10 on hostPort dco-node128-mgt.dco.ethz.ch:51757 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,340 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/11 on worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781 (dco-node124-mgt.dco.ethz.ch:39781) with 16 cores
2014-07-12 21:11:24,340 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/11 on hostPort dco-node124-mgt.dco.ethz.ch:39781 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,341 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/12 on worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810 (dco-node132-mgt.dco.ethz.ch:60810) with 16 cores
2014-07-12 21:11:24,341 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/12 on hostPort dco-node132-mgt.dco.ethz.ch:60810 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,342 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/13 on worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826 (dco-node122-mgt.dco.ethz.ch:45826) with 16 cores
2014-07-12 21:11:24,346 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/13 on hostPort dco-node122-mgt.dco.ethz.ch:45826 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,346 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/14 on worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584 (dco-node136-mgt.dco.ethz.ch:49584) with 16 cores
2014-07-12 21:11:24,347 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/14 on hostPort dco-node136-mgt.dco.ethz.ch:49584 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,347 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211124-0003/15 on worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845 (dco-node129-mgt.dco.ethz.ch:44845) with 16 cores
2014-07-12 21:11:24,347 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211124-0003/15 on hostPort dco-node129-mgt.dco.ethz.ch:44845 with 16 cores, 70.0 GB RAM
2014-07-12 21:11:24,358 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/4 is now RUNNING
2014-07-12 21:11:24,358 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/10 is now RUNNING
2014-07-12 21:11:24,361 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/8 is now RUNNING
2014-07-12 21:11:24,363 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/9 is now RUNNING
2014-07-12 21:11:24,365 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/2 is now RUNNING
2014-07-12 21:11:24,367 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/1 is now RUNNING
2014-07-12 21:11:24,369 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/6 is now RUNNING
2014-07-12 21:11:24,372 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/15 is now RUNNING
2014-07-12 21:11:24,373 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/13 is now RUNNING
2014-07-12 21:11:24,375 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/3 is now RUNNING
2014-07-12 21:11:24,376 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/7 is now RUNNING
2014-07-12 21:11:24,378 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/0 is now RUNNING
2014-07-12 21:11:24,379 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/12 is now RUNNING
2014-07-12 21:11:24,381 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/11 is now RUNNING
2014-07-12 21:11:24,382 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/14 is now RUNNING
2014-07-12 21:11:24,384 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211124-0003/5 is now RUNNING
2014-07-12 21:11:25,290 [ExecutorRunner for app-20140712211124-0003/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140712211124-0003"
2014-07-12 21:11:26,174 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:11:26,355 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:11:26,355 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:11:26,793 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:11:26,850 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-12 21:11:27,030 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]
2014-07-12 21:11:27,035 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]
2014-07-12 21:11:27,048 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930/user/CoarseGrainedScheduler
2014-07-12 21:11:27,052 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:11:27,224 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:11:27,387 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node135-mgt.dco.ethz.ch:51154/user/Executor#-170141693] with ID 4
2014-07-12 21:11:27,392 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009/user/Executor#422775400] with ID 9
2014-07-12 21:11:27,392 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node131-mgt.dco.ethz.ch:36508/user/Executor#-351278350] with ID 0
2014-07-12 21:11:27,393 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node130-mgt.dco.ethz.ch:50652/user/Executor#-266296461] with ID 8
2014-07-12 21:11:27,393 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node133-mgt.dco.ethz.ch:35923/user/Executor#-743693363] with ID 5
2014-07-12 21:11:27,394 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node125-mgt.dco.ethz.ch:36663/user/Executor#1260932736] with ID 2
2014-07-12 21:11:27,406 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node136-mgt.dco.ethz.ch:48936/user/Executor#1570244717] with ID 14
2014-07-12 21:11:27,410 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node129-mgt.dco.ethz.ch:44869/user/Executor#1972316194] with ID 15
2014-07-12 21:11:27,416 [spark-akka.actor.default-dispatcher-20] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node134-mgt.dco.ethz.ch:58575/user/Executor#-317471498] with ID 6
2014-07-12 21:11:27,418 [spark-akka.actor.default-dispatcher-20] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node123-mgt.dco.ethz.ch:39071/user/Executor#235601264] with ID 3
2014-07-12 21:11:27,420 [spark-akka.actor.default-dispatcher-20] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node132-mgt.dco.ethz.ch:39908/user/Executor#362752701] with ID 12
2014-07-12 21:11:27,431 [spark-akka.actor.default-dispatcher-20] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node128-mgt.dco.ethz.ch:37821/user/Executor#1039305277] with ID 10
2014-07-12 21:11:27,441 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2014-07-12 21:11:27,445 [spark-akka.actor.default-dispatcher-20] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node124-mgt.dco.ethz.ch:59450/user/Executor#-729114501] with ID 11
2014-07-12 21:11:27,460 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node122-mgt.dco.ethz.ch:34587/user/Executor#-1320599789] with ID 13
2014-07-12 21:11:27,461 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:11:27,461 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:11:27,475 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node127-mgt.dco.ethz.ch:36772/user/Executor#1134781081] with ID 7
2014-07-12 21:11:27,477 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node126-mgt.dco.ethz.ch:38029/user/Executor#1651980107] with ID 1
2014-07-12 21:11:27,487 [spark-akka.actor.default-dispatcher-6] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:11:27,494 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Starting remoting
2014-07-12 21:11:27,519 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56823]
2014-07-12 21:11:27,520 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56823]
2014-07-12 21:11:27,531 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.SparkEnv - Connecting to MapOutputTracker: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930/user/MapOutputTracker
2014-07-12 21:11:27,593 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.SparkEnv - Connecting to BlockManagerMaster: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930/user/BlockManagerMaster
2014-07-12 21:11:27,656 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /disk3/spark_local_dirs/spark-local-20140712211127-a3ed
2014-07-12 21:11:27,661 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:11:27,695 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 42679 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,42679)
2014-07-12 21:11:27,700 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:11:28,172 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node130-mgt.dco.ethz.ch:33241 with 40.3 GB RAM
2014-07-12 21:11:28,182 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node129-mgt.dco.ethz.ch:40373 with 40.3 GB RAM
2014-07-12 21:11:28,197 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node135-mgt.dco.ethz.ch:56827 with 40.3 GB RAM
2014-07-12 21:11:28,203 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node128-mgt.dco.ethz.ch:54164 with 40.3 GB RAM
2014-07-12 21:11:28,204 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node124-mgt.dco.ethz.ch:44653 with 40.3 GB RAM
2014-07-12 21:11:28,206 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node122-mgt.dco.ethz.ch:45156 with 40.3 GB RAM
2014-07-12 21:11:28,207 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:42789 with 40.3 GB RAM
2014-07-12 21:11:28,207 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node133-mgt.dco.ethz.ch:54042 with 40.3 GB RAM
2014-07-12 21:11:28,228 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node131-mgt.dco.ethz.ch:44972 with 40.3 GB RAM
2014-07-12 21:11:28,234 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node125-mgt.dco.ethz.ch:55581 with 40.3 GB RAM
2014-07-12 21:11:28,237 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node132-mgt.dco.ethz.ch:43471 with 40.3 GB RAM
2014-07-12 21:11:28,238 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node123-mgt.dco.ethz.ch:41377 with 40.3 GB RAM
2014-07-12 21:11:28,238 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:42679 with 40.3 GB RAM
2014-07-12 21:11:28,239 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node136-mgt.dco.ethz.ch:35934 with 40.3 GB RAM
2014-07-12 21:11:28,244 [spark-akka.actor.default-dispatcher-42] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node127-mgt.dco.ethz.ch:49377 with 40.3 GB RAM
2014-07-12 21:11:28,246 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:11:28,280 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node126-mgt.dco.ethz.ch:58823 with 40.3 GB RAM
2014-07-12 21:11:28,291 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-a4ca5855-f5cf-4a4d-ae3c-88c83fc40391
2014-07-12 21:11:28,294 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:11:28,354 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:11:28,374 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:37046
2014-07-12 21:11:28,563 [sparkExecutor-akka.actor.default-dispatcher-6] INFO  org.apache.spark.executor.Executor - Using REPL class URI: http://172.31.109.131:44773
2014-07-12 21:17:39,110 [main] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(239409) called with curMem=0, maxMem=43218213273
2014-07-12 21:17:39,112 [main] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_0 stored as values to memory (estimated size 233.8 KB, free 40.2 GB)
2014-07-12 21:18:19,180 [main] INFO  org.apache.spark.storage.MemoryStore - ensureFreeSpace(239409) called with curMem=239409, maxMem=43218213273
2014-07-12 21:18:19,180 [main] INFO  org.apache.spark.storage.MemoryStore - Block broadcast_1 stored as values to memory (estimated size 233.8 KB, free 40.2 GB)
2014-07-12 21:19:34,623 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930 got disassociated, removing it.
2014-07-12 21:19:34,624 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140712211124-0003
2014-07-12 21:19:34,625 [sparkMaster-akka.actor.default-dispatcher-48] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A37066-29#-1237787548] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-12 21:19:34,632 [sparkMaster-akka.actor.default-dispatcher-52] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:54930
]
2014-07-12 21:19:34,640 [sparkMaster-akka.actor.default-dispatcher-52] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:54930
]
2014-07-12 21:19:34,647 [sparkMaster-akka.actor.default-dispatcher-3] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:54930
]
2014-07-12 21:19:34,656 [sparkExecutor-akka.actor.default-dispatcher-2] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - Driver Disassociated [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930] disassociated! Shutting down.
2014-07-12 21:19:34,674 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:19:34,675 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:19:34,713 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930 got disassociated, removing it.
2014-07-12 21:19:34,713 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930 got disassociated, removing it.
2014-07-12 21:19:34,713 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930 got disassociated, removing it.
2014-07-12 21:19:34,713 [sparkMaster-akka.actor.default-dispatcher-16] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:54930 got disassociated, removing it.
2014-07-12 21:19:34,719 [sparkWorker-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140712211124-0003/9
2014-07-12 21:19:34,720 [ExecutorRunner for app-20140712211124-0003/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140712211124-0003/9 interrupted
2014-07-12 21:19:34,721 [ExecutorRunner for app-20140712211124-0003/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-12 21:19:34,721 [sparkWorker-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140712211124-0003/9 finished with state KILLED
2014-07-12 21:19:34,721 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/3
2014-07-12 21:19:34,723 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/9
2014-07-12 21:19:34,723 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/4
2014-07-12 21:19:34,723 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/8
2014-07-12 21:19:34,723 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/5
2014-07-12 21:19:34,723 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/14
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/12
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/2
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/10
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/6
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/13
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/0
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/15
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/1
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/11
2014-07-12 21:19:34,724 [sparkMaster-akka.actor.default-dispatcher-56] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211124-0003/7
2014-07-12 21:19:35,011 [sparkWorker-akka.actor.default-dispatcher-18] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A55164-14#-1709814430] was not delivered. [4] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-12 21:19:35,019 [sparkWorker-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:36009
]
2014-07-12 21:19:35,028 [sparkWorker-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:36009
]
2014-07-12 21:19:35,042 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:36009]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:36009
]
2014-07-12 21:19:40,799 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:19:40,800 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:19:40,801 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:19:40,861 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:19:40,890 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:34276
2014-07-12 21:19:44,666 [main] WARN  org.apache.spark.SparkConf - 
SPARK_JAVA_OPTS was detected (set to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
2014-07-12 21:19:44,667 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.executor.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:19:44,667 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.driver.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:19:44,686 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:19:44,686 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:19:45,320 [spark-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:19:45,372 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-12 21:19:45,555 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]
2014-07-12 21:19:45,558 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]
2014-07-12 21:19:45,586 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2014-07-12 21:19:45,590 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2014-07-12 21:19:45,607 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-local-20140712211945-c0cd
2014-07-12 21:19:45,612 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:19:45,642 [main] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 38698 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,38698)
2014-07-12 21:19:45,648 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:19:45,652 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:38698 with 40.3 GB RAM
2014-07-12 21:19:45,654 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:19:45,668 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:19:45,669 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:19:45,672 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:36706
2014-07-12 21:19:45,674 [main] INFO  org.apache.spark.broadcast.HttpBroadcast - Broadcast server started at http://172.31.109.131:36706
2014-07-12 21:19:45,681 [main] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-079bf3f7-5202-405d-9e1b-cdde992a6090
2014-07-12 21:19:45,681 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:19:45,682 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:19:45,684 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:50288
2014-07-12 21:19:45,927 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:19:45,947 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2014-07-12 21:19:45,954 [main] INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://dco-node121-mgt.dco.ethz.ch:4040
2014-07-12 21:19:46,174 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:19:46,839 [main] INFO  org.apache.spark.scheduler.EventLoggingListener - Logging events to hdfs://dco-node121.dco.ethz.ch:54310/spark_event_log/spark-shell-1405192786286
2014-07-12 21:19:47,017 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Connecting to master spark://dco-node121.dco.ethz.ch:7077...
2014-07-12 21:19:47,040 [main] INFO  org.apache.spark.repl.SparkILoop - Created spark context..
2014-07-12 21:19:47,260 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Registering app Spark shell
2014-07-12 21:19:47,261 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Registered app Spark shell with ID app-20140712211947-0004
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-12 21:19:47,262 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-12 21:19:47,263 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-12 21:19:47,263 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-12 21:19:47,263 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-12 21:19:47,263 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-12 21:19:47,263 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-12 21:19:47,263 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-12 21:19:47,263 [sparkMaster-akka.actor.default-dispatcher-44] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712211947-0004/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-12 21:19:47,268 [sparkWorker-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140712211947-0004/9 for Spark shell
2014-07-12 21:19:47,269 [ExecutorRunner for app-20140712211947-0004/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-12 21:19:47,270 [ExecutorRunner for app-20140712211947-0004/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-12 21:19:47,280 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Connected to Spark cluster with app ID app-20140712211947-0004
2014-07-12 21:19:47,283 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/0 on worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773 (dco-node131-mgt.dco.ethz.ch:51773) with 16 cores
2014-07-12 21:19:47,285 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/0 on hostPort dco-node131-mgt.dco.ethz.ch:51773 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,286 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/1 on worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480 (dco-node126-mgt.dco.ethz.ch:60480) with 16 cores
2014-07-12 21:19:47,287 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/1 on hostPort dco-node126-mgt.dco.ethz.ch:60480 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,287 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/2 on worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839 (dco-node125-mgt.dco.ethz.ch:42839) with 16 cores
2014-07-12 21:19:47,288 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/2 on hostPort dco-node125-mgt.dco.ethz.ch:42839 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,289 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/3 on worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212 (dco-node123-mgt.dco.ethz.ch:58212) with 16 cores
2014-07-12 21:19:47,290 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/3 on hostPort dco-node123-mgt.dco.ethz.ch:58212 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,290 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/4 on worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580 (dco-node135-mgt.dco.ethz.ch:58580) with 16 cores
2014-07-12 21:19:47,291 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/4 on hostPort dco-node135-mgt.dco.ethz.ch:58580 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,291 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/5 on worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081 (dco-node133-mgt.dco.ethz.ch:48081) with 16 cores
2014-07-12 21:19:47,292 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/5 on hostPort dco-node133-mgt.dco.ethz.ch:48081 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,293 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/6 on worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082 (dco-node134-mgt.dco.ethz.ch:39082) with 16 cores
2014-07-12 21:19:47,293 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/6 on hostPort dco-node134-mgt.dco.ethz.ch:39082 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,294 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/7 on worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515 (dco-node127-mgt.dco.ethz.ch:34515) with 16 cores
2014-07-12 21:19:47,294 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/7 on hostPort dco-node127-mgt.dco.ethz.ch:34515 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,295 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/8 on worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548 (dco-node130-mgt.dco.ethz.ch:48548) with 16 cores
2014-07-12 21:19:47,295 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/8 on hostPort dco-node130-mgt.dco.ethz.ch:48548 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,296 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/9 on worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479 (dco-node121-mgt.dco.ethz.ch:60479) with 16 cores
2014-07-12 21:19:47,297 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/9 on hostPort dco-node121-mgt.dco.ethz.ch:60479 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,297 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/10 on worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757 (dco-node128-mgt.dco.ethz.ch:51757) with 16 cores
2014-07-12 21:19:47,297 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/10 on hostPort dco-node128-mgt.dco.ethz.ch:51757 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,298 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/11 on worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781 (dco-node124-mgt.dco.ethz.ch:39781) with 16 cores
2014-07-12 21:19:47,298 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/11 on hostPort dco-node124-mgt.dco.ethz.ch:39781 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,298 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/12 on worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810 (dco-node132-mgt.dco.ethz.ch:60810) with 16 cores
2014-07-12 21:19:47,298 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/12 on hostPort dco-node132-mgt.dco.ethz.ch:60810 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,299 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/13 on worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826 (dco-node122-mgt.dco.ethz.ch:45826) with 16 cores
2014-07-12 21:19:47,299 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/13 on hostPort dco-node122-mgt.dco.ethz.ch:45826 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,300 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/14 on worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584 (dco-node136-mgt.dco.ethz.ch:49584) with 16 cores
2014-07-12 21:19:47,300 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/14 on hostPort dco-node136-mgt.dco.ethz.ch:49584 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,300 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712211947-0004/15 on worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845 (dco-node129-mgt.dco.ethz.ch:44845) with 16 cores
2014-07-12 21:19:47,300 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712211947-0004/15 on hostPort dco-node129-mgt.dco.ethz.ch:44845 with 16 cores, 70.0 GB RAM
2014-07-12 21:19:47,313 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/7 is now RUNNING
2014-07-12 21:19:47,313 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/2 is now RUNNING
2014-07-12 21:19:47,315 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/6 is now RUNNING
2014-07-12 21:19:47,317 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/4 is now RUNNING
2014-07-12 21:19:47,320 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/1 is now RUNNING
2014-07-12 21:19:47,322 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/3 is now RUNNING
2014-07-12 21:19:47,324 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/9 is now RUNNING
2014-07-12 21:19:47,326 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/0 is now RUNNING
2014-07-12 21:19:47,328 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/5 is now RUNNING
2014-07-12 21:19:47,330 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/10 is now RUNNING
2014-07-12 21:19:47,331 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/8 is now RUNNING
2014-07-12 21:19:47,333 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/12 is now RUNNING
2014-07-12 21:19:47,335 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/11 is now RUNNING
2014-07-12 21:19:47,338 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/13 is now RUNNING
2014-07-12 21:19:47,341 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/14 is now RUNNING
2014-07-12 21:19:47,345 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712211947-0004/15 is now RUNNING
2014-07-12 21:19:48,294 [ExecutorRunner for app-20140712211947-0004/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140712211947-0004"
2014-07-12 21:19:49,260 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:19:49,464 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:19:49,465 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:19:49,920 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:19:49,984 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-12 21:19:50,180 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]
2014-07-12 21:19:50,185 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]
2014-07-12 21:19:50,199 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371/user/CoarseGrainedScheduler
2014-07-12 21:19:50,201 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:19:50,291 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node128-mgt.dco.ethz.ch:58286/user/Executor#-1906045864] with ID 10
2014-07-12 21:19:50,318 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node126-mgt.dco.ethz.ch:48300/user/Executor#1682911770] with ID 1
2014-07-12 21:19:50,321 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node125-mgt.dco.ethz.ch:49159/user/Executor#1749641514] with ID 2
2014-07-12 21:19:50,329 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node136-mgt.dco.ethz.ch:54709/user/Executor#703474997] with ID 14
2014-07-12 21:19:50,342 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node124-mgt.dco.ethz.ch:42720/user/Executor#-1689785447] with ID 11
2014-07-12 21:19:50,343 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node130-mgt.dco.ethz.ch:51486/user/Executor#1666795065] with ID 8
2014-07-12 21:19:50,343 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node134-mgt.dco.ethz.ch:55054/user/Executor#552829451] with ID 6
2014-07-12 21:19:50,350 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node127-mgt.dco.ethz.ch:33312/user/Executor#-183699602] with ID 7
2014-07-12 21:19:50,357 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node129-mgt.dco.ethz.ch:57456/user/Executor#2024444022] with ID 15
2014-07-12 21:19:50,358 [spark-akka.actor.default-dispatcher-27] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node133-mgt.dco.ethz.ch:49709/user/Executor#1905347318] with ID 5
2014-07-12 21:19:50,360 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node131-mgt.dco.ethz.ch:43556/user/Executor#1137208808] with ID 0
2014-07-12 21:19:50,363 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node123-mgt.dco.ethz.ch:42040/user/Executor#-1048322743] with ID 3
2014-07-12 21:19:50,368 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node122-mgt.dco.ethz.ch:48834/user/Executor#1921312740] with ID 13
2014-07-12 21:19:50,374 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node132-mgt.dco.ethz.ch:49721/user/Executor#331051835] with ID 12
2014-07-12 21:19:50,380 [sparkExecutor-akka.actor.default-dispatcher-20] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:19:50,391 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node135-mgt.dco.ethz.ch:58553/user/Executor#1454470714] with ID 4
2014-07-12 21:19:50,534 [spark-akka.actor.default-dispatcher-25] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892/user/Executor#-1986216146] with ID 9
2014-07-12 21:19:50,576 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2014-07-12 21:19:50,594 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:19:50,594 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:19:50,616 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node128-mgt.dco.ethz.ch:49448 with 40.3 GB RAM
2014-07-12 21:19:50,618 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node127-mgt.dco.ethz.ch:35928 with 40.3 GB RAM
2014-07-12 21:19:50,618 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node125-mgt.dco.ethz.ch:48396 with 40.3 GB RAM
2014-07-12 21:19:50,619 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node126-mgt.dco.ethz.ch:57189 with 40.3 GB RAM
2014-07-12 21:19:50,619 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node124-mgt.dco.ethz.ch:34757 with 40.3 GB RAM
2014-07-12 21:19:50,619 [spark-akka.actor.default-dispatcher-30] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node136-mgt.dco.ethz.ch:51918 with 40.3 GB RAM
2014-07-12 21:19:50,619 [spark-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:19:50,620 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:41990 with 40.3 GB RAM
2014-07-12 21:19:50,621 [spark-akka.actor.default-dispatcher-16] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node130-mgt.dco.ethz.ch:42392 with 40.3 GB RAM
2014-07-12 21:19:50,623 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node131-mgt.dco.ethz.ch:34018 with 40.3 GB RAM
2014-07-12 21:19:50,626 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node133-mgt.dco.ethz.ch:53961 with 40.3 GB RAM
2014-07-12 21:19:50,626 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node122-mgt.dco.ethz.ch:50893 with 40.3 GB RAM
2014-07-12 21:19:50,627 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node123-mgt.dco.ethz.ch:43341 with 40.3 GB RAM
2014-07-12 21:19:50,628 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-12 21:19:50,648 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:52297]
2014-07-12 21:19:50,650 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:52297]
2014-07-12 21:19:50,654 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node132-mgt.dco.ethz.ch:56371 with 40.3 GB RAM
2014-07-12 21:19:50,655 [spark-akka.actor.default-dispatcher-32] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node129-mgt.dco.ethz.ch:36468 with 40.3 GB RAM
2014-07-12 21:19:50,661 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SparkEnv - Connecting to MapOutputTracker: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371/user/MapOutputTracker
2014-07-12 21:19:50,675 [spark-akka.actor.default-dispatcher-26] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node135-mgt.dco.ethz.ch:48735 with 40.3 GB RAM
2014-07-12 21:19:50,709 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SparkEnv - Connecting to BlockManagerMaster: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371/user/BlockManagerMaster
2014-07-12 21:19:50,748 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /disk3/spark_local_dirs/spark-local-20140712211950-5fe6
2014-07-12 21:19:50,753 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:19:50,783 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 35514 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,35514)
2014-07-12 21:19:50,788 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:19:50,800 [spark-akka.actor.default-dispatcher-34] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:35514 with 40.3 GB RAM
2014-07-12 21:19:50,806 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:19:50,831 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-53e37ccf-33ee-4028-8d09-bcbf7f4ef212
2014-07-12 21:19:50,834 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:19:50,893 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:19:50,913 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:56338
2014-07-12 21:19:51,069 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.Executor - Using REPL class URI: http://172.31.109.131:34276
2014-07-12 21:23:58,766 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371 got disassociated, removing it.
2014-07-12 21:23:58,766 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140712211947-0004
2014-07-12 21:23:58,767 [sparkMaster-akka.actor.default-dispatcher-21] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A37117-33#-770526488] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-12 21:23:58,774 [sparkMaster-akka.actor.default-dispatcher-21] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:59371
]
2014-07-12 21:23:58,782 [sparkMaster-akka.actor.default-dispatcher-20] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:59371
]
2014-07-12 21:23:58,791 [sparkMaster-akka.actor.default-dispatcher-21] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:59371
]
2014-07-12 21:23:58,798 [sparkExecutor-akka.actor.default-dispatcher-2] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - Driver Disassociated [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371] disassociated! Shutting down.
2014-07-12 21:23:58,819 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:23:58,820 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:23:58,851 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371 got disassociated, removing it.
2014-07-12 21:23:58,851 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371 got disassociated, removing it.
2014-07-12 21:23:58,851 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371 got disassociated, removing it.
2014-07-12 21:23:58,851 [sparkMaster-akka.actor.default-dispatcher-23] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:59371 got disassociated, removing it.
2014-07-12 21:23:58,853 [sparkWorker-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140712211947-0004/9
2014-07-12 21:23:58,854 [ExecutorRunner for app-20140712211947-0004/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140712211947-0004/9 interrupted
2014-07-12 21:23:58,854 [sparkWorker-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140712211947-0004/9 finished with state KILLED
2014-07-12 21:23:58,855 [ExecutorRunner for app-20140712211947-0004/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-12 21:23:58,855 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/15
2014-07-12 21:23:58,857 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/14
2014-07-12 21:23:58,857 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/6
2014-07-12 21:23:58,857 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/10
2014-07-12 21:23:58,857 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/11
2014-07-12 21:23:58,857 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/8
2014-07-12 21:23:58,857 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/9
2014-07-12 21:23:58,857 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/2
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/3
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/1
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/7
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/12
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/0
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/5
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/13
2014-07-12 21:23:58,858 [sparkMaster-akka.actor.default-dispatcher-20] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712211947-0004/4
2014-07-12 21:23:59,146 [sparkWorker-akka.actor.default-dispatcher-2] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A55216-18#-969061006] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-12 21:23:59,155 [sparkWorker-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:50892
]
2014-07-12 21:23:59,164 [sparkWorker-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:50892
]
2014-07-12 21:23:59,175 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:50892]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:50892
]
2014-07-12 21:24:39,068 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:24:39,069 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:24:39,070 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:24:39,131 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:24:39,161 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:39010
2014-07-12 21:24:42,917 [main] WARN  org.apache.spark.SparkConf - 
SPARK_JAVA_OPTS was detected (set to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
2014-07-12 21:24:42,918 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.executor.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:24:42,918 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.driver.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:24:42,934 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:24:42,934 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:24:43,508 [spark-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:24:43,554 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-12 21:24:43,745 [spark-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]
2014-07-12 21:24:43,747 [spark-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]
2014-07-12 21:24:43,774 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2014-07-12 21:24:43,777 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2014-07-12 21:24:43,794 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-local-20140712212443-83c8
2014-07-12 21:24:43,799 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:24:43,830 [main] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 57501 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,57501)
2014-07-12 21:24:43,835 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:24:43,838 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:57501 with 40.3 GB RAM
2014-07-12 21:24:43,839 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:24:43,851 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:24:43,852 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:24:43,855 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:34840
2014-07-12 21:24:43,857 [main] INFO  org.apache.spark.broadcast.HttpBroadcast - Broadcast server started at http://172.31.109.131:34840
2014-07-12 21:24:43,865 [main] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-05860963-686c-4280-b3b4-58ceb59094a1
2014-07-12 21:24:43,866 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:24:43,866 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:24:43,869 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:39899
2014-07-12 21:24:44,137 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:24:44,156 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2014-07-12 21:24:44,166 [main] INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://dco-node121-mgt.dco.ethz.ch:4040
2014-07-12 21:24:44,382 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:24:45,015 [main] INFO  org.apache.spark.scheduler.EventLoggingListener - Logging events to hdfs://dco-node121.dco.ethz.ch:54310/spark_event_log/spark-shell-1405193084480
2014-07-12 21:24:45,180 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Connecting to master spark://dco-node121.dco.ethz.ch:7077...
2014-07-12 21:24:45,204 [main] INFO  org.apache.spark.repl.SparkILoop - Created spark context..
2014-07-12 21:24:45,413 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Registering app Spark shell
2014-07-12 21:24:45,414 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Registered app Spark shell with ID app-20140712212445-0005
2014-07-12 21:24:45,414 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-12 21:24:45,414 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-12 21:24:45,414 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-12 21:24:45,414 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-12 21:24:45,414 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-12 21:24:45,415 [sparkMaster-akka.actor.default-dispatcher-39] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712212445-0005/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-12 21:24:45,419 [sparkWorker-akka.actor.default-dispatcher-18] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140712212445-0005/9 for Spark shell
2014-07-12 21:24:45,423 [ExecutorRunner for app-20140712212445-0005/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-12 21:24:45,423 [ExecutorRunner for app-20140712212445-0005/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-12 21:24:45,427 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Connected to Spark cluster with app ID app-20140712212445-0005
2014-07-12 21:24:45,431 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/0 on worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773 (dco-node131-mgt.dco.ethz.ch:51773) with 16 cores
2014-07-12 21:24:45,432 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/0 on hostPort dco-node131-mgt.dco.ethz.ch:51773 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,432 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/1 on worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480 (dco-node126-mgt.dco.ethz.ch:60480) with 16 cores
2014-07-12 21:24:45,433 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/1 on hostPort dco-node126-mgt.dco.ethz.ch:60480 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,433 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/2 on worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839 (dco-node125-mgt.dco.ethz.ch:42839) with 16 cores
2014-07-12 21:24:45,434 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/2 on hostPort dco-node125-mgt.dco.ethz.ch:42839 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,434 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/3 on worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212 (dco-node123-mgt.dco.ethz.ch:58212) with 16 cores
2014-07-12 21:24:45,435 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/3 on hostPort dco-node123-mgt.dco.ethz.ch:58212 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,435 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/4 on worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580 (dco-node135-mgt.dco.ethz.ch:58580) with 16 cores
2014-07-12 21:24:45,436 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/4 on hostPort dco-node135-mgt.dco.ethz.ch:58580 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,437 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/5 on worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081 (dco-node133-mgt.dco.ethz.ch:48081) with 16 cores
2014-07-12 21:24:45,437 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/5 on hostPort dco-node133-mgt.dco.ethz.ch:48081 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,438 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/6 on worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082 (dco-node134-mgt.dco.ethz.ch:39082) with 16 cores
2014-07-12 21:24:45,438 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/6 on hostPort dco-node134-mgt.dco.ethz.ch:39082 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,439 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/7 on worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515 (dco-node127-mgt.dco.ethz.ch:34515) with 16 cores
2014-07-12 21:24:45,439 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/7 on hostPort dco-node127-mgt.dco.ethz.ch:34515 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,440 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/8 on worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548 (dco-node130-mgt.dco.ethz.ch:48548) with 16 cores
2014-07-12 21:24:45,440 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/8 on hostPort dco-node130-mgt.dco.ethz.ch:48548 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,441 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/9 on worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479 (dco-node121-mgt.dco.ethz.ch:60479) with 16 cores
2014-07-12 21:24:45,441 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/9 on hostPort dco-node121-mgt.dco.ethz.ch:60479 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,442 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/10 on worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757 (dco-node128-mgt.dco.ethz.ch:51757) with 16 cores
2014-07-12 21:24:45,442 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/10 on hostPort dco-node128-mgt.dco.ethz.ch:51757 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,443 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/11 on worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781 (dco-node124-mgt.dco.ethz.ch:39781) with 16 cores
2014-07-12 21:24:45,443 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/11 on hostPort dco-node124-mgt.dco.ethz.ch:39781 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,444 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/12 on worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810 (dco-node132-mgt.dco.ethz.ch:60810) with 16 cores
2014-07-12 21:24:45,444 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/12 on hostPort dco-node132-mgt.dco.ethz.ch:60810 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,445 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/13 on worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826 (dco-node122-mgt.dco.ethz.ch:45826) with 16 cores
2014-07-12 21:24:45,445 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/13 on hostPort dco-node122-mgt.dco.ethz.ch:45826 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,446 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/14 on worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584 (dco-node136-mgt.dco.ethz.ch:49584) with 16 cores
2014-07-12 21:24:45,446 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/14 on hostPort dco-node136-mgt.dco.ethz.ch:49584 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,447 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712212445-0005/15 on worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845 (dco-node129-mgt.dco.ethz.ch:44845) with 16 cores
2014-07-12 21:24:45,447 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712212445-0005/15 on hostPort dco-node129-mgt.dco.ethz.ch:44845 with 16 cores, 70.0 GB RAM
2014-07-12 21:24:45,460 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/6 is now RUNNING
2014-07-12 21:24:45,461 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/3 is now RUNNING
2014-07-12 21:24:45,463 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/13 is now RUNNING
2014-07-12 21:24:45,465 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/4 is now RUNNING
2014-07-12 21:24:45,468 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/1 is now RUNNING
2014-07-12 21:24:45,470 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/5 is now RUNNING
2014-07-12 21:24:45,472 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/10 is now RUNNING
2014-07-12 21:24:45,474 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/15 is now RUNNING
2014-07-12 21:24:45,476 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/2 is now RUNNING
2014-07-12 21:24:45,478 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/7 is now RUNNING
2014-07-12 21:24:45,479 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/0 is now RUNNING
2014-07-12 21:24:45,481 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/12 is now RUNNING
2014-07-12 21:24:45,483 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/11 is now RUNNING
2014-07-12 21:24:45,484 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/8 is now RUNNING
2014-07-12 21:24:45,486 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/14 is now RUNNING
2014-07-12 21:24:45,488 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712212445-0005/9 is now RUNNING
2014-07-12 21:24:46,355 [ExecutorRunner for app-20140712212445-0005/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140712212445-0005"
2014-07-12 21:24:47,260 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:24:47,450 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:24:47,451 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:24:47,894 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:24:47,952 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-12 21:24:48,134 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]
2014-07-12 21:24:48,139 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]
2014-07-12 21:24:48,151 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431/user/CoarseGrainedScheduler
2014-07-12 21:24:48,155 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:24:48,336 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:24:48,444 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node136-mgt.dco.ethz.ch:59091/user/Executor#516050776] with ID 14
2014-07-12 21:24:48,447 [spark-akka.actor.default-dispatcher-17] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node125-mgt.dco.ethz.ch:40376/user/Executor#412440909] with ID 2
2014-07-12 21:24:48,466 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node128-mgt.dco.ethz.ch:59477/user/Executor#1986367968] with ID 10
2014-07-12 21:24:48,476 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node131-mgt.dco.ethz.ch:43979/user/Executor#-330598926] with ID 0
2014-07-12 21:24:48,492 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node133-mgt.dco.ethz.ch:48190/user/Executor#-543727726] with ID 5
2014-07-12 21:24:48,497 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node126-mgt.dco.ethz.ch:60704/user/Executor#-1102542777] with ID 1
2014-07-12 21:24:48,502 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node129-mgt.dco.ethz.ch:58605/user/Executor#94560574] with ID 15
2014-07-12 21:24:48,508 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node134-mgt.dco.ethz.ch:57204/user/Executor#-667166109] with ID 6
2014-07-12 21:24:48,510 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node130-mgt.dco.ethz.ch:41008/user/Executor#976666706] with ID 8
2014-07-12 21:24:48,514 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node123-mgt.dco.ethz.ch:34408/user/Executor#-2103721622] with ID 3
2014-07-12 21:24:48,516 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node127-mgt.dco.ethz.ch:44324/user/Executor#594916900] with ID 7
2014-07-12 21:24:48,518 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node132-mgt.dco.ethz.ch:40320/user/Executor#253165039] with ID 12
2014-07-12 21:24:48,536 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682/user/Executor#491703003] with ID 9
2014-07-12 21:24:48,547 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node122-mgt.dco.ethz.ch:48128/user/Executor#521897448] with ID 13
2014-07-12 21:24:48,564 [spark-akka.actor.default-dispatcher-13] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node124-mgt.dco.ethz.ch:34617/user/Executor#-886092596] with ID 11
2014-07-12 21:24:48,571 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2014-07-12 21:24:48,588 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:24:48,588 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:24:48,590 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node135-mgt.dco.ethz.ch:60887/user/Executor#1919704024] with ID 4
2014-07-12 21:24:48,614 [spark-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:24:48,623 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-12 21:24:48,649 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44807]
2014-07-12 21:24:48,651 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44807]
2014-07-12 21:24:48,663 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SparkEnv - Connecting to MapOutputTracker: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431/user/MapOutputTracker
2014-07-12 21:24:48,718 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SparkEnv - Connecting to BlockManagerMaster: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431/user/BlockManagerMaster
2014-07-12 21:24:49,249 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node132-mgt.dco.ethz.ch:58255 with 40.3 GB RAM
2014-07-12 21:24:49,256 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node126-mgt.dco.ethz.ch:52377 with 40.3 GB RAM
2014-07-12 21:24:49,269 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node123-mgt.dco.ethz.ch:47898 with 40.3 GB RAM
2014-07-12 21:24:49,270 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node125-mgt.dco.ethz.ch:32783 with 40.3 GB RAM
2014-07-12 21:24:49,271 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node131-mgt.dco.ethz.ch:35896 with 40.3 GB RAM
2014-07-12 21:24:49,274 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node129-mgt.dco.ethz.ch:53088 with 40.3 GB RAM
2014-07-12 21:24:49,274 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node130-mgt.dco.ethz.ch:42677 with 40.3 GB RAM
2014-07-12 21:24:49,275 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node127-mgt.dco.ethz.ch:41210 with 40.3 GB RAM
2014-07-12 21:24:49,275 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node128-mgt.dco.ethz.ch:37834 with 40.3 GB RAM
2014-07-12 21:24:49,280 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:35217 with 40.3 GB RAM
2014-07-12 21:24:49,282 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node133-mgt.dco.ethz.ch:49157 with 40.3 GB RAM
2014-07-12 21:24:49,283 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node136-mgt.dco.ethz.ch:58186 with 40.3 GB RAM
2014-07-12 21:24:49,321 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /disk3/spark_local_dirs/spark-local-20140712212449-7ad9
2014-07-12 21:24:49,325 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:24:49,354 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 34911 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,34911)
2014-07-12 21:24:49,359 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:24:49,372 [spark-akka.actor.default-dispatcher-55] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:34911 with 40.3 GB RAM
2014-07-12 21:24:49,377 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:24:49,381 [spark-akka.actor.default-dispatcher-56] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node124-mgt.dco.ethz.ch:54525 with 40.3 GB RAM
2014-07-12 21:24:49,383 [spark-akka.actor.default-dispatcher-55] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node122-mgt.dco.ethz.ch:44320 with 40.3 GB RAM
2014-07-12 21:24:49,398 [spark-akka.actor.default-dispatcher-15] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node135-mgt.dco.ethz.ch:40635 with 40.3 GB RAM
2014-07-12 21:24:49,420 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-31517686-47c0-47c4-84f8-2f3272164ae2
2014-07-12 21:24:49,424 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:24:49,484 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:24:49,503 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:46021
2014-07-12 21:24:49,658 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.executor.Executor - Using REPL class URI: http://172.31.109.131:39010
2014-07-12 21:29:21,922 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431 got disassociated, removing it.
2014-07-12 21:29:21,922 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140712212445-0005
2014-07-12 21:29:21,923 [sparkMaster-akka.actor.default-dispatcher-24] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A37156-37#1249344057] was not delivered. [6] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-12 21:29:21,929 [sparkMaster-akka.actor.default-dispatcher-53] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:58431
]
2014-07-12 21:29:21,936 [sparkMaster-akka.actor.default-dispatcher-24] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:58431
]
2014-07-12 21:29:21,944 [sparkMaster-akka.actor.default-dispatcher-16] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:58431
]
2014-07-12 21:29:21,960 [sparkExecutor-akka.actor.default-dispatcher-4] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - Driver Disassociated [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431] disassociated! Shutting down.
2014-07-12 21:29:21,966 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:29:21,966 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:29:21,992 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431 got disassociated, removing it.
2014-07-12 21:29:21,992 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431 got disassociated, removing it.
2014-07-12 21:29:21,992 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431 got disassociated, removing it.
2014-07-12 21:29:21,992 [sparkMaster-akka.actor.default-dispatcher-49] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:58431 got disassociated, removing it.
2014-07-12 21:29:21,994 [sparkWorker-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140712212445-0005/9
2014-07-12 21:29:21,995 [ExecutorRunner for app-20140712212445-0005/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140712212445-0005/9 interrupted
2014-07-12 21:29:21,995 [sparkWorker-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140712212445-0005/9 finished with state KILLED
2014-07-12 21:29:21,995 [ExecutorRunner for app-20140712212445-0005/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-12 21:29:21,996 [sparkMaster-akka.actor.default-dispatcher-40] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/1
2014-07-12 21:29:21,997 [sparkMaster-akka.actor.default-dispatcher-30] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/14
2014-07-12 21:29:21,997 [sparkMaster-akka.actor.default-dispatcher-30] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/12
2014-07-12 21:29:21,997 [sparkMaster-akka.actor.default-dispatcher-30] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/9
2014-07-12 21:29:21,997 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/11
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/3
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/8
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/4
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/6
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/13
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/5
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/15
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/0
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/7
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/10
2014-07-12 21:29:21,998 [sparkMaster-akka.actor.default-dispatcher-51] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712212445-0005/2
2014-07-12 21:29:22,313 [sparkWorker-akka.actor.default-dispatcher-4] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A55256-22#-748850234] was not delivered. [6] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-12 21:29:22,321 [sparkWorker-akka.actor.default-dispatcher-4] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:60682
]
2014-07-12 21:29:22,329 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:60682
]
2014-07-12 21:29:22,337 [sparkWorker-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:60682]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:60682
]
2014-07-12 21:51:54,837 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:51:54,838 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:51:54,839 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:51:54,902 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:51:54,934 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:37771
2014-07-12 21:51:58,753 [main] WARN  org.apache.spark.SparkConf - 
SPARK_JAVA_OPTS was detected (set to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200').
This is deprecated in Spark 1.0+.

Please instead use:
 - ./spark-submit with conf/spark-defaults.conf to set defaults for an application
 - ./spark-submit with --driver-java-options to set -X options for a driver
 - spark.executor.extraJavaOptions to set -X options for executors
 - SPARK_DAEMON_JAVA_OPTS to set java options for standalone daemons (master or worker)
        
2014-07-12 21:51:58,755 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.executor.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:51:58,755 [main] WARN  org.apache.spark.SparkConf - Setting 'spark.driver.extraJavaOptions' to '-Xms4g -Xmx70g -XX:MaxPermSize=10g -Dspark.akka.frameSize=200' as a work-around.
2014-07-12 21:51:58,775 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:51:58,775 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:51:59,401 [spark-akka.actor.default-dispatcher-3] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:51:59,455 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-12 21:51:59,640 [spark-akka.actor.default-dispatcher-4] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]
2014-07-12 21:51:59,644 [spark-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]
2014-07-12 21:51:59,674 [main] INFO  org.apache.spark.SparkEnv - Registering MapOutputTracker
2014-07-12 21:51:59,677 [main] INFO  org.apache.spark.SparkEnv - Registering BlockManagerMaster
2014-07-12 21:51:59,694 [main] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /tmp/spark-local-20140712215159-851d
2014-07-12 21:51:59,706 [main] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:51:59,741 [main] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 32855 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,32855)
2014-07-12 21:51:59,746 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:51:59,751 [spark-akka.actor.default-dispatcher-5] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:32855 with 40.3 GB RAM
2014-07-12 21:51:59,753 [main] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:51:59,768 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:51:59,769 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:51:59,773 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:34534
2014-07-12 21:51:59,774 [main] INFO  org.apache.spark.broadcast.HttpBroadcast - Broadcast server started at http://172.31.109.131:34534
2014-07-12 21:51:59,781 [main] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-7ce7ceea-10a5-4819-a9ee-6bcbfbf87bfe
2014-07-12 21:51:59,781 [main] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:51:59,782 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:51:59,786 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:35695
2014-07-12 21:52:00,034 [main] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:52:00,059 [main] INFO  org.eclipse.jetty.server.AbstractConnector - Started SelectChannelConnector@0.0.0.0:4040
2014-07-12 21:52:00,071 [main] INFO  org.apache.spark.ui.SparkUI - Started SparkUI at http://dco-node121-mgt.dco.ethz.ch:4040
2014-07-12 21:52:00,308 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:52:00,997 [main] INFO  org.apache.spark.scheduler.EventLoggingListener - Logging events to hdfs://dco-node121.dco.ethz.ch:54310/spark_event_log/spark-shell-1405194720413
2014-07-12 21:52:01,168 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Connecting to master spark://dco-node121.dco.ethz.ch:7077...
2014-07-12 21:52:01,193 [main] INFO  org.apache.spark.repl.SparkILoop - Created spark context..
2014-07-12 21:52:01,413 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Registering app Spark shell
2014-07-12 21:52:01,413 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Registered app Spark shell with ID app-20140712215201-0006
2014-07-12 21:52:01,414 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-12 21:52:01,414 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-12 21:52:01,414 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-12 21:52:01,414 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-12 21:52:01,415 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-12 21:52:01,415 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-12 21:52:01,415 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-12 21:52:01,415 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-12 21:52:01,415 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-12 21:52:01,415 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-12 21:52:01,415 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-12 21:52:01,416 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-12 21:52:01,416 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-12 21:52:01,416 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-12 21:52:01,416 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-12 21:52:01,416 [sparkMaster-akka.actor.default-dispatcher-46] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140712215201-0006/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-12 21:52:01,420 [sparkWorker-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140712215201-0006/9 for Spark shell
2014-07-12 21:52:01,423 [ExecutorRunner for app-20140712215201-0006/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-12 21:52:01,423 [ExecutorRunner for app-20140712215201-0006/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-12 21:52:01,434 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Connected to Spark cluster with app ID app-20140712215201-0006
2014-07-12 21:52:01,438 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/0 on worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773 (dco-node131-mgt.dco.ethz.ch:51773) with 16 cores
2014-07-12 21:52:01,440 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/0 on hostPort dco-node131-mgt.dco.ethz.ch:51773 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,440 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/1 on worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480 (dco-node126-mgt.dco.ethz.ch:60480) with 16 cores
2014-07-12 21:52:01,441 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/1 on hostPort dco-node126-mgt.dco.ethz.ch:60480 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,443 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/2 on worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839 (dco-node125-mgt.dco.ethz.ch:42839) with 16 cores
2014-07-12 21:52:01,443 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/2 on hostPort dco-node125-mgt.dco.ethz.ch:42839 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,444 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/3 on worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212 (dco-node123-mgt.dco.ethz.ch:58212) with 16 cores
2014-07-12 21:52:01,446 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/3 on hostPort dco-node123-mgt.dco.ethz.ch:58212 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,446 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/4 on worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580 (dco-node135-mgt.dco.ethz.ch:58580) with 16 cores
2014-07-12 21:52:01,447 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/4 on hostPort dco-node135-mgt.dco.ethz.ch:58580 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,448 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/5 on worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081 (dco-node133-mgt.dco.ethz.ch:48081) with 16 cores
2014-07-12 21:52:01,448 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/5 on hostPort dco-node133-mgt.dco.ethz.ch:48081 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,449 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/6 on worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082 (dco-node134-mgt.dco.ethz.ch:39082) with 16 cores
2014-07-12 21:52:01,449 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/6 on hostPort dco-node134-mgt.dco.ethz.ch:39082 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,450 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/7 on worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515 (dco-node127-mgt.dco.ethz.ch:34515) with 16 cores
2014-07-12 21:52:01,450 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/7 on hostPort dco-node127-mgt.dco.ethz.ch:34515 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,452 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/8 on worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548 (dco-node130-mgt.dco.ethz.ch:48548) with 16 cores
2014-07-12 21:52:01,452 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/8 on hostPort dco-node130-mgt.dco.ethz.ch:48548 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,453 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/9 on worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479 (dco-node121-mgt.dco.ethz.ch:60479) with 16 cores
2014-07-12 21:52:01,454 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/9 on hostPort dco-node121-mgt.dco.ethz.ch:60479 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,455 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/10 on worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757 (dco-node128-mgt.dco.ethz.ch:51757) with 16 cores
2014-07-12 21:52:01,456 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/10 on hostPort dco-node128-mgt.dco.ethz.ch:51757 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,456 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/11 on worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781 (dco-node124-mgt.dco.ethz.ch:39781) with 16 cores
2014-07-12 21:52:01,457 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/11 on hostPort dco-node124-mgt.dco.ethz.ch:39781 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,458 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/12 on worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810 (dco-node132-mgt.dco.ethz.ch:60810) with 16 cores
2014-07-12 21:52:01,458 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/12 on hostPort dco-node132-mgt.dco.ethz.ch:60810 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,459 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/13 on worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826 (dco-node122-mgt.dco.ethz.ch:45826) with 16 cores
2014-07-12 21:52:01,460 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/13 on hostPort dco-node122-mgt.dco.ethz.ch:45826 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,460 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/14 on worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584 (dco-node136-mgt.dco.ethz.ch:49584) with 16 cores
2014-07-12 21:52:01,461 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/14 on hostPort dco-node136-mgt.dco.ethz.ch:49584 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,461 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor added: app-20140712215201-0006/15 on worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845 (dco-node129-mgt.dco.ethz.ch:44845) with 16 cores
2014-07-12 21:52:01,462 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Granted executor ID app-20140712215201-0006/15 on hostPort dco-node129-mgt.dco.ethz.ch:44845 with 16 cores, 70.0 GB RAM
2014-07-12 21:52:01,478 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/3 is now RUNNING
2014-07-12 21:52:01,479 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/5 is now RUNNING
2014-07-12 21:52:01,483 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/0 is now RUNNING
2014-07-12 21:52:01,486 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/1 is now RUNNING
2014-07-12 21:52:01,489 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/8 is now RUNNING
2014-07-12 21:52:01,491 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/7 is now RUNNING
2014-07-12 21:52:01,494 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/2 is now RUNNING
2014-07-12 21:52:01,497 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/10 is now RUNNING
2014-07-12 21:52:01,499 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/4 is now RUNNING
2014-07-12 21:52:01,501 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/9 is now RUNNING
2014-07-12 21:52:01,503 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/12 is now RUNNING
2014-07-12 21:52:01,505 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/14 is now RUNNING
2014-07-12 21:52:01,507 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/11 is now RUNNING
2014-07-12 21:52:01,508 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/13 is now RUNNING
2014-07-12 21:52:01,510 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/6 is now RUNNING
2014-07-12 21:52:01,513 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.client.AppClient$ClientActor - Executor updated: app-20140712215201-0006/15 is now RUNNING
2014-07-12 21:52:02,408 [ExecutorRunner for app-20140712215201-0006/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140712215201-0006"
2014-07-12 21:52:03,451 [main] WARN  org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-12 21:52:03,642 [main] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:52:03,642 [main] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:52:04,115 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:52:04,181 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  Remoting - Starting remoting
2014-07-12 21:52:04,394 [sparkExecutor-akka.actor.default-dispatcher-3] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]
2014-07-12 21:52:04,398 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]
2014-07-12 21:52:04,412 [sparkExecutor-akka.actor.default-dispatcher-5] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Connecting to driver: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139/user/CoarseGrainedScheduler
2014-07-12 21:52:04,416 [sparkExecutor-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Connecting to worker akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:52:04,463 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node129-mgt.dco.ethz.ch:44357/user/Executor#33571273] with ID 15
2014-07-12 21:52:04,466 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node133-mgt.dco.ethz.ch:55466/user/Executor#-1271785526] with ID 5
2014-07-12 21:52:04,466 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node136-mgt.dco.ethz.ch:39315/user/Executor#2041843477] with ID 14
2014-07-12 21:52:04,467 [spark-akka.actor.default-dispatcher-2] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node126-mgt.dco.ethz.ch:41926/user/Executor#1274073746] with ID 1
2014-07-12 21:52:04,476 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node122-mgt.dco.ethz.ch:57457/user/Executor#-1787994226] with ID 13
2014-07-12 21:52:04,487 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node125-mgt.dco.ethz.ch:42120/user/Executor#1980318338] with ID 2
2014-07-12 21:52:04,499 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node123-mgt.dco.ethz.ch:40470/user/Executor#1014122823] with ID 3
2014-07-12 21:52:04,509 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node131-mgt.dco.ethz.ch:56947/user/Executor#-433624043] with ID 0
2014-07-12 21:52:04,516 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node124-mgt.dco.ethz.ch:51983/user/Executor#-191662250] with ID 11
2014-07-12 21:52:04,522 [spark-akka.actor.default-dispatcher-23] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node132-mgt.dco.ethz.ch:39460/user/Executor#539562327] with ID 12
2014-07-12 21:52:04,525 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node128-mgt.dco.ethz.ch:33809/user/Executor#-919706143] with ID 10
2014-07-12 21:52:04,536 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node130-mgt.dco.ethz.ch:39865/user/Executor#1155433390] with ID 8
2014-07-12 21:52:04,572 [spark-akka.actor.default-dispatcher-24] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node134-mgt.dco.ethz.ch:44102/user/Executor#1529420030] with ID 6
2014-07-12 21:52:04,584 [spark-akka.actor.default-dispatcher-3] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node135-mgt.dco.ethz.ch:47874/user/Executor#-2133892298] with ID 4
2014-07-12 21:52:04,594 [spark-akka.actor.default-dispatcher-22] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node127-mgt.dco.ethz.ch:56244/user/Executor#-1169205371] with ID 7
2014-07-12 21:52:04,626 [sparkExecutor-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.worker.WorkerWatcher - Successfully connected to akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker
2014-07-12 21:52:05,357 [spark-akka.actor.default-dispatcher-4] INFO  org.apache.spark.scheduler.cluster.SparkDeploySchedulerBackend - Registered executor: Actor[akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445/user/Executor#-888221997] with ID 9
2014-07-12 21:52:05,415 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.CoarseGrainedExecutorBackend - Successfully registered with driver
2014-07-12 21:52:05,434 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-12 21:52:05,434 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-12 21:52:05,458 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node133-mgt.dco.ethz.ch:38594 with 40.3 GB RAM
2014-07-12 21:52:05,460 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node125-mgt.dco.ethz.ch:57333 with 40.3 GB RAM
2014-07-12 21:52:05,464 [spark-akka.actor.default-dispatcher-4] INFO  akka.event.slf4j.Slf4jLogger - Slf4jLogger started
2014-07-12 21:52:05,466 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node136-mgt.dco.ethz.ch:54925 with 40.3 GB RAM
2014-07-12 21:52:05,472 [spark-akka.actor.default-dispatcher-37] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node122-mgt.dco.ethz.ch:52525 with 40.3 GB RAM
2014-07-12 21:52:05,476 [spark-akka.actor.default-dispatcher-20] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node129-mgt.dco.ethz.ch:41184 with 40.3 GB RAM
2014-07-12 21:52:05,479 [spark-akka.actor.default-dispatcher-2] INFO  Remoting - Starting remoting
2014-07-12 21:52:05,500 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node123-mgt.dco.ethz.ch:33381 with 40.3 GB RAM
2014-07-12 21:52:05,501 [spark-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting started; listening on addresses :[akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:57682]
2014-07-12 21:52:05,503 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node128-mgt.dco.ethz.ch:43158 with 40.3 GB RAM
2014-07-12 21:52:05,504 [spark-akka.actor.default-dispatcher-5] INFO  Remoting - Remoting now listens on addresses: [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:57682]
2014-07-12 21:52:05,505 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node126-mgt.dco.ethz.ch:54737 with 40.3 GB RAM
2014-07-12 21:52:05,505 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node130-mgt.dco.ethz.ch:54521 with 40.3 GB RAM
2014-07-12 21:52:05,506 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node132-mgt.dco.ethz.ch:42363 with 40.3 GB RAM
2014-07-12 21:52:05,507 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node127-mgt.dco.ethz.ch:35469 with 40.3 GB RAM
2014-07-12 21:52:05,508 [spark-akka.actor.default-dispatcher-29] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node134-mgt.dco.ethz.ch:41042 with 40.3 GB RAM
2014-07-12 21:52:05,510 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node124-mgt.dco.ethz.ch:40088 with 40.3 GB RAM
2014-07-12 21:52:05,511 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node135-mgt.dco.ethz.ch:50529 with 40.3 GB RAM
2014-07-12 21:52:05,514 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SparkEnv - Connecting to MapOutputTracker: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139/user/MapOutputTracker
2014-07-12 21:52:05,526 [spark-akka.actor.default-dispatcher-38] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node131-mgt.dco.ethz.ch:58800 with 40.3 GB RAM
2014-07-12 21:52:05,564 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.SparkEnv - Connecting to BlockManagerMaster: akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139/user/BlockManagerMaster
2014-07-12 21:52:05,621 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.DiskBlockManager - Created local directory at /disk3/spark_local_dirs/spark-local-20140712215205-065a
2014-07-12 21:52:05,626 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.MemoryStore - MemoryStore started with capacity 40.3 GB.
2014-07-12 21:52:05,656 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.network.ConnectionManager - Bound socket to port 46451 with id = ConnectionManagerId(dco-node121-mgt.dco.ethz.ch,46451)
2014-07-12 21:52:05,661 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.BlockManagerMaster - Trying to register BlockManager
2014-07-12 21:52:05,679 [spark-akka.actor.default-dispatcher-6] INFO  org.apache.spark.storage.BlockManagerInfo - Registering block manager dco-node121-mgt.dco.ethz.ch:46451 with 40.3 GB RAM
2014-07-12 21:52:05,686 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.storage.BlockManagerMaster - Registered BlockManager
2014-07-12 21:52:05,713 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.HttpFileServer - HTTP File server directory is /tmp/spark-32a45380-57a9-4cac-9c50-dd71f96a5d12
2014-07-12 21:52:05,716 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.HttpServer - Starting HTTP Server
2014-07-12 21:52:05,781 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.eclipse.jetty.server.Server - jetty-8.y.z-SNAPSHOT
2014-07-12 21:52:05,802 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.eclipse.jetty.server.AbstractConnector - Started SocketConnector@0.0.0.0:50585
2014-07-12 21:52:05,972 [sparkExecutor-akka.actor.default-dispatcher-2] INFO  org.apache.spark.executor.Executor - Using REPL class URI: http://172.31.109.131:37771
2014-07-13 01:35:32,320 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139 got disassociated, removing it.
2014-07-13 01:35:32,321 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140712215201-0006
2014-07-13 01:35:32,321 [sparkMaster-akka.actor.default-dispatcher-35] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A41564-41#252510695] was not delivered. [7] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 01:35:32,329 [sparkMaster-akka.actor.default-dispatcher-29] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:37139
]
2014-07-13 01:35:32,337 [sparkMaster-akka.actor.default-dispatcher-23] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:37139
]
2014-07-13 01:35:32,346 [sparkMaster-akka.actor.default-dispatcher-45] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:37139
]
2014-07-13 01:35:32,358 [sparkExecutor-akka.actor.default-dispatcher-5] ERROR org.apache.spark.executor.CoarseGrainedExecutorBackend - Driver Disassociated [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139] disassociated! Shutting down.
2014-07-13 01:35:32,371 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 01:35:32,372 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 01:35:32,404 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139 got disassociated, removing it.
2014-07-13 01:35:32,404 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139 got disassociated, removing it.
2014-07-13 01:35:32,404 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139 got disassociated, removing it.
2014-07-13 01:35:32,404 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:37139 got disassociated, removing it.
2014-07-13 01:35:32,408 [sparkWorker-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140712215201-0006/9
2014-07-13 01:35:32,408 [sparkWorker-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140712215201-0006/9 finished with state KILLED
2014-07-13 01:35:32,408 [ExecutorRunner for app-20140712215201-0006/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140712215201-0006/9 interrupted
2014-07-13 01:35:32,409 [ExecutorRunner for app-20140712215201-0006/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-13 01:35:32,411 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/2
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/8
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/15
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/7
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/6
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/4
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/14
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/9
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/5
2014-07-13 01:35:32,412 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/3
2014-07-13 01:35:32,413 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/1
2014-07-13 01:35:32,413 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/10
2014-07-13 01:35:32,413 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/0
2014-07-13 01:35:32,413 [sparkMaster-akka.actor.default-dispatcher-42] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/12
2014-07-13 01:35:32,413 [sparkMaster-akka.actor.default-dispatcher-53] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/13
2014-07-13 01:35:32,413 [sparkMaster-akka.actor.default-dispatcher-29] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140712215201-0006/11
2014-07-13 01:35:32,711 [sparkWorker-akka.actor.default-dispatcher-18] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A59677-26#2059812159] was not delivered. [7] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 01:35:32,720 [sparkWorker-akka.actor.default-dispatcher-18] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:47445
]
2014-07-13 01:35:32,729 [sparkWorker-akka.actor.default-dispatcher-3] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:47445
]
2014-07-13 01:35:32,736 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:47445]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:47445
]
2014-07-13 03:05:06,739 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Registering app Spark shell
2014-07-13 03:05:06,740 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Registered app Spark shell with ID app-20140713030506-0007
2014-07-13 03:05:06,741 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-13 03:05:06,741 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-13 03:05:06,742 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-13 03:05:06,743 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-13 03:05:06,743 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-13 03:05:06,743 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-13 03:05:06,743 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-13 03:05:06,743 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-13 03:05:06,743 [sparkMaster-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030506-0007/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-13 03:05:06,749 [sparkWorker-akka.actor.default-dispatcher-18] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140713030506-0007/9 for Spark shell
2014-07-13 03:05:06,752 [ExecutorRunner for app-20140713030506-0007/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-13 03:05:06,752 [ExecutorRunner for app-20140713030506-0007/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-13 03:05:08,336 [ExecutorRunner for app-20140713030506-0007/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140713030506-0007"
2014-07-13 03:07:30,418 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541 got disassociated, removing it.
2014-07-13 03:07:30,418 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713030506-0007
2014-07-13 03:07:30,419 [sparkMaster-akka.actor.default-dispatcher-47] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A40392-46#-1218573304] was not delivered. [8] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 03:07:30,427 [sparkMaster-akka.actor.default-dispatcher-45] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:59541
]
2014-07-13 03:07:30,433 [sparkMaster-akka.actor.default-dispatcher-47] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:59541
]
2014-07-13 03:07:30,441 [sparkMaster-akka.actor.default-dispatcher-45] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:59541
]
2014-07-13 03:07:30,460 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 03:07:30,460 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 03:07:30,500 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541 got disassociated, removing it.
2014-07-13 03:07:30,500 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541 got disassociated, removing it.
2014-07-13 03:07:30,500 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541 got disassociated, removing it.
2014-07-13 03:07:30,500 [sparkMaster-akka.actor.default-dispatcher-24] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59541 got disassociated, removing it.
2014-07-13 03:07:30,503 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140713030506-0007/9
2014-07-13 03:07:30,504 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140713030506-0007/9 finished with state KILLED
2014-07-13 03:07:30,504 [ExecutorRunner for app-20140713030506-0007/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140713030506-0007/9 interrupted
2014-07-13 03:07:30,505 [ExecutorRunner for app-20140713030506-0007/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-13 03:07:30,505 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/7
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/10
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/4
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/12
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/8
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/5
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/15
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/9
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/3
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/1
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/11
2014-07-13 03:07:30,507 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/14
2014-07-13 03:07:30,508 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/0
2014-07-13 03:07:30,508 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/6
2014-07-13 03:07:30,508 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/2
2014-07-13 03:07:30,508 [sparkMaster-akka.actor.default-dispatcher-50] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030506-0007/13
2014-07-13 03:07:30,932 [sparkWorker-akka.actor.default-dispatcher-3] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A41408-30#951664688] was not delivered. [8] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 03:07:30,941 [sparkWorker-akka.actor.default-dispatcher-4] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:56580
]
2014-07-13 03:07:30,948 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:56580
]
2014-07-13 03:07:30,956 [sparkWorker-akka.actor.default-dispatcher-3] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:56580]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:56580
]
2014-07-13 03:08:42,254 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Registering app Spark shell
2014-07-13 03:08:42,254 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Registered app Spark shell with ID app-20140713030842-0008
2014-07-13 03:08:42,255 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-13 03:08:42,255 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-13 03:08:42,256 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-13 03:08:42,257 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-13 03:08:42,257 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-13 03:08:42,257 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-13 03:08:42,257 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-13 03:08:42,257 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-13 03:08:42,257 [sparkMaster-akka.actor.default-dispatcher-21] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713030842-0008/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-13 03:08:42,263 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140713030842-0008/9 for Spark shell
2014-07-13 03:08:42,264 [ExecutorRunner for app-20140713030842-0008/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-13 03:08:42,265 [ExecutorRunner for app-20140713030842-0008/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-13 03:08:43,327 [ExecutorRunner for app-20140713030842-0008/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140713030842-0008"
2014-07-13 04:21:23,416 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854 got disassociated, removing it.
2014-07-13 04:21:23,416 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713030842-0008
2014-07-13 04:21:23,416 [sparkMaster-akka.actor.default-dispatcher-21] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A40413-50#474402378] was not delivered. [9] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 04:21:23,423 [sparkMaster-akka.actor.default-dispatcher-3] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:47854
]
2014-07-13 04:21:23,429 [sparkMaster-akka.actor.default-dispatcher-21] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:47854
]
2014-07-13 04:21:23,437 [sparkMaster-akka.actor.default-dispatcher-3] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:47854
]
2014-07-13 04:21:23,463 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 04:21:23,463 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 04:21:23,497 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854 got disassociated, removing it.
2014-07-13 04:21:23,497 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854 got disassociated, removing it.
2014-07-13 04:21:23,497 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854 got disassociated, removing it.
2014-07-13 04:21:23,497 [sparkMaster-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:47854 got disassociated, removing it.
2014-07-13 04:21:23,498 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140713030842-0008/9
2014-07-13 04:21:23,499 [sparkWorker-akka.actor.default-dispatcher-4] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140713030842-0008/9 finished with state KILLED
2014-07-13 04:21:23,500 [sparkMaster-akka.actor.default-dispatcher-4] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/14
2014-07-13 04:21:23,499 [ExecutorRunner for app-20140713030842-0008/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140713030842-0008/9 interrupted
2014-07-13 04:21:23,500 [ExecutorRunner for app-20140713030842-0008/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-13 04:21:23,500 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/8
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/2
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/7
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/12
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/0
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/11
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/10
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/13
2014-07-13 04:21:23,501 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/1
2014-07-13 04:21:23,502 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/3
2014-07-13 04:21:23,502 [sparkMaster-akka.actor.default-dispatcher-35] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/6
2014-07-13 04:21:23,502 [sparkMaster-akka.actor.default-dispatcher-55] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/15
2014-07-13 04:21:23,502 [sparkMaster-akka.actor.default-dispatcher-55] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/5
2014-07-13 04:21:23,502 [sparkMaster-akka.actor.default-dispatcher-55] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/4
2014-07-13 04:21:23,502 [sparkMaster-akka.actor.default-dispatcher-55] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713030842-0008/9
2014-07-13 04:21:23,835 [sparkWorker-akka.actor.default-dispatcher-2] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A42149-34#-109673844] was not delivered. [9] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 04:21:23,843 [sparkWorker-akka.actor.default-dispatcher-4] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:46450
]
2014-07-13 04:21:23,850 [sparkWorker-akka.actor.default-dispatcher-18] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:46450
]
2014-07-13 04:21:23,858 [sparkWorker-akka.actor.default-dispatcher-2] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:46450]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:46450
]
2014-07-13 16:02:43,231 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Registering app HTML to Text Conversion Application
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Registered app HTML to Text Conversion Application with ID app-20140713160243-0009
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-13 16:02:43,233 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-13 16:02:43,234 [sparkMaster-akka.actor.default-dispatcher-56] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713160243-0009/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-13 16:02:43,256 [sparkWorker-akka.actor.default-dispatcher-2] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140713160243-0009/9 for HTML to Text Conversion Application
2014-07-13 16:02:43,258 [ExecutorRunner for app-20140713160243-0009/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-13 16:02:43,259 [ExecutorRunner for app-20140713160243-0009/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-13 16:02:44,691 [ExecutorRunner for app-20140713160243-0009/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140713160243-0009"
2014-07-13 16:03:08,289 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609 got disassociated, removing it.
2014-07-13 16:03:08,290 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713160243-0009
2014-07-13 16:03:08,290 [sparkMaster-akka.actor.default-dispatcher-32] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A42123-54#-837870966] was not delivered. [10] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:03:08,297 [sparkMaster-akka.actor.default-dispatcher-15] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:56609
]
2014-07-13 16:03:08,304 [sparkMaster-akka.actor.default-dispatcher-15] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:56609
]
2014-07-13 16:03:08,311 [sparkMaster-akka.actor.default-dispatcher-32] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:56609
]
2014-07-13 16:03:08,332 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 16:03:08,333 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 16:03:08,374 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609 got disassociated, removing it.
2014-07-13 16:03:08,374 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609 got disassociated, removing it.
2014-07-13 16:03:08,374 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609 got disassociated, removing it.
2014-07-13 16:03:08,374 [sparkMaster-akka.actor.default-dispatcher-38] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:56609 got disassociated, removing it.
2014-07-13 16:03:08,379 [sparkWorker-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.Worker - Asked to kill executor app-20140713160243-0009/9
2014-07-13 16:03:08,380 [ExecutorRunner for app-20140713160243-0009/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Runner thread for executor app-20140713160243-0009/9 interrupted
2014-07-13 16:03:08,381 [ExecutorRunner for app-20140713160243-0009/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-13 16:03:08,380 [sparkWorker-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140713160243-0009/9 finished with state KILLED
2014-07-13 16:03:08,381 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/8
2014-07-13 16:03:08,382 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/7
2014-07-13 16:03:08,382 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/2
2014-07-13 16:03:08,382 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/4
2014-07-13 16:03:08,382 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/5
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/0
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/12
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/3
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/11
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/9
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/15
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/14
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/6
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/13
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-54] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/1
2014-07-13 16:03:08,383 [sparkMaster-akka.actor.default-dispatcher-15] WARN  org.apache.spark.deploy.master.Master - Got status update for unknown executor app-20140713160243-0009/10
2014-07-13 16:03:08,683 [sparkWorker-akka.actor.default-dispatcher-4] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkWorker/deadLetters] to Actor[akka://sparkWorker/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkWorker%40172.31.109.131%3A60221-38#806568474] was not delivered. [10] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:03:08,690 [sparkWorker-akka.actor.default-dispatcher-15] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:55438
]
2014-07-13 16:03:08,698 [sparkWorker-akka.actor.default-dispatcher-3] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:55438
]
2014-07-13 16:03:08,705 [sparkWorker-akka.actor.default-dispatcher-15] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479] -> [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]: Error [Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkExecutor@dco-node121-mgt.dco.ethz.ch:55438]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:55438
]
2014-07-13 16:10:37,685 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registering app Spark shell
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Registered app Spark shell with ID app-20140713161037-0010
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/0 on worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/1 on worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/2 on worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/3 on worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/4 on worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/5 on worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/6 on worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/7 on worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515
2014-07-13 16:10:37,686 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/8 on worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548
2014-07-13 16:10:37,687 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/9 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-13 16:10:37,687 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/10 on worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757
2014-07-13 16:10:37,687 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/11 on worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781
2014-07-13 16:10:37,687 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/12 on worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810
2014-07-13 16:10:37,687 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/13 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-13 16:10:37,687 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/14 on worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584
2014-07-13 16:10:37,687 [sparkMaster-akka.actor.default-dispatcher-25] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/15 on worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845
2014-07-13 16:10:37,692 [sparkWorker-akka.actor.default-dispatcher-3] INFO  org.apache.spark.deploy.worker.Worker - Asked to launch executor app-20140713161037-0010/9 for Spark shell
2014-07-13 16:10:37,694 [ExecutorRunner for app-20140713161037-0010/9] WARN  org.apache.spark.deploy.worker.CommandUtils - SPARK_JAVA_OPTS was set on the worker. It is deprecated in Spark 1.0.
2014-07-13 16:10:37,695 [ExecutorRunner for app-20140713161037-0010/9] WARN  org.apache.spark.deploy.worker.CommandUtils - Set SPARK_LOCAL_DIRS for node-specific storage locations.
2014-07-13 16:10:38,647 [ExecutorRunner for app-20140713161037-0010/9] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Launch command: "/opt/jdk1.8.0_05/bin/java" "-cp" "::/root/spark/conf:/root/spark/lib/spark-assembly-1.0.0-hadoop2.2.0.jar:/root/spark/lib/datanucleus-rdbms-3.2.1.jar:/root/spark/lib/datanucleus-core-3.2.2.jar:/root/spark/lib/datanucleus-api-jdo-3.2.1.jar:/opt/hadoop-2.4.0/etc/hadoop" "-XX:MaxPermSize=128m" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms4g" "-Xmx70g" "-XX:MaxPermSize=10g" "-Dspark.akka.frameSize=200" "-Xms71680M" "-Xmx71680M" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828/user/CoarseGrainedScheduler" "9" "dco-node121-mgt.dco.ethz.ch" "16" "akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479/user/Worker" "app-20140713161037-0010"
2014-07-13 16:29:16,331 [sparkMaster-akka.actor.default-dispatcher-20] INFO  org.apache.spark.deploy.master.Master - Registering app Simple Application
2014-07-13 16:29:16,332 [sparkMaster-akka.actor.default-dispatcher-20] INFO  org.apache.spark.deploy.master.Master - Registered app Simple Application with ID app-20140713162916-0011
2014-07-13 16:30:22,453 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261 got disassociated, removing it.
2014-07-13 16:30:22,453 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713162916-0011
2014-07-13 16:30:22,453 [sparkMaster-akka.actor.default-dispatcher-51] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A41094-59#147681533] was not delivered. [11] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:22,461 [sparkMaster-akka.actor.default-dispatcher-34] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:40261
]
2014-07-13 16:30:22,467 [sparkMaster-akka.actor.default-dispatcher-34] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:40261
]
2014-07-13 16:30:22,472 [sparkMaster-akka.actor.default-dispatcher-51] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:40261
]
2014-07-13 16:30:22,491 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 16:30:22,492 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 16:30:22,516 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261 got disassociated, removing it.
2014-07-13 16:30:22,517 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261 got disassociated, removing it.
2014-07-13 16:30:22,517 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261 got disassociated, removing it.
2014-07-13 16:30:22,517 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:40261 got disassociated, removing it.
2014-07-13 16:30:46,391 [Thread-1066] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-13 16:30:46,391 [Thread-4066] INFO  org.apache.spark.deploy.worker.ExecutorRunner - Killing process!
2014-07-13 16:30:47,063 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781 got disassociated, removing it.
2014-07-13 16:30:47,065 [sparkMaster-akka.actor.default-dispatcher-22] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.134%3A52559-5#733174167] was not delivered. [12] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,066 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node124-mgt.dco.ethz.ch-39781 on dco-node124-mgt.dco.ethz.ch:39781
2014-07-13 16:30:47,067 [sparkMaster-akka.actor.default-dispatcher-22] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.146%3A34964-13#-1580130105] was not delivered. [13] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,068 [sparkMaster-akka.actor.default-dispatcher-22] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.137%3A42563-11#738706459] was not delivered. [14] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,070 [sparkMaster-akka.actor.default-dispatcher-16] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.139%3A41959-15#1726312262] was not delivered. [15] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,072 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 11
2014-07-13 16:30:47,076 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781 got disassociated, removing it.
2014-07-13 16:30:47,076 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]: Error [Association failed with [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node124-mgt.dco.ethz.ch/172.31.109.134:39781
]
2014-07-13 16:30:47,076 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584 got disassociated, removing it.
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node136-mgt.dco.ethz.ch-49584 on dco-node136-mgt.dco.ethz.ch:49584
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 14
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515 got disassociated, removing it.
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node127-mgt.dco.ethz.ch-34515 on dco-node127-mgt.dco.ethz.ch:34515
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 7
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584 got disassociated, removing it.
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515 got disassociated, removing it.
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845 got disassociated, removing it.
2014-07-13 16:30:47,079 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node129-mgt.dco.ethz.ch-44845 on dco-node129-mgt.dco.ethz.ch:44845
2014-07-13 16:30:47,080 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 15
2014-07-13 16:30:47,081 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845 got disassociated, removing it.
2014-07-13 16:30:47,081 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781 got disassociated, removing it.
2014-07-13 16:30:47,083 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]: Error [Association failed with [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node136-mgt.dco.ethz.ch/172.31.109.146:49584
]
2014-07-13 16:30:47,085 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]: Error [Association failed with [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node127-mgt.dco.ethz.ch/172.31.109.137:34515
]
2014-07-13 16:30:47,085 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584 got disassociated, removing it.
2014-07-13 16:30:47,085 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515 got disassociated, removing it.
2014-07-13 16:30:47,088 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]: Error [Association failed with [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node129-mgt.dco.ethz.ch/172.31.109.139:44845
]
2014-07-13 16:30:47,090 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Removing executor app-20140713161037-0010/13 because it is FAILED
2014-07-13 16:30:47,092 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/16 on worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826
2014-07-13 16:30:47,093 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845 got disassociated, removing it.
2014-07-13 16:30:47,093 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548 got disassociated, removing it.
2014-07-13 16:30:47,093 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node130-mgt.dco.ethz.ch-48548 on dco-node130-mgt.dco.ethz.ch:48548
2014-07-13 16:30:47,093 [sparkMaster-akka.actor.default-dispatcher-13] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.140%3A50013-2#-728714315] was not delivered. [16] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,093 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 8
2014-07-13 16:30:47,094 [sparkMaster-akka.actor.default-dispatcher-13] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]: Error [Association failed with [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node124-mgt.dco.ethz.ch/172.31.109.134:39781
]
2014-07-13 16:30:47,095 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548 got disassociated, removing it.
2014-07-13 16:30:47,096 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781 got disassociated, removing it.
2014-07-13 16:30:47,098 [sparkMaster-akka.actor.default-dispatcher-30] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]: Error [Association failed with [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node127-mgt.dco.ethz.ch/172.31.109.137:34515
]
2014-07-13 16:30:47,099 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515 got disassociated, removing it.
2014-07-13 16:30:47,103 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]: Error [Association failed with [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node136-mgt.dco.ethz.ch/172.31.109.146:49584
]
2014-07-13 16:30:47,107 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584 got disassociated, removing it.
2014-07-13 16:30:47,109 [sparkMaster-akka.actor.default-dispatcher-37] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]: Error [Association failed with [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node129-mgt.dco.ethz.ch/172.31.109.139:44845
]
2014-07-13 16:30:47,110 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845 got disassociated, removing it.
2014-07-13 16:30:47,115 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]: Error [Association failed with [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node130-mgt.dco.ethz.ch/172.31.109.140:48548
]
2014-07-13 16:30:47,116 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548 got disassociated, removing it.
2014-07-13 16:30:47,120 [sparkMaster-akka.actor.default-dispatcher-37] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]: Error [Association failed with [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node124-mgt.dco.ethz.ch/172.31.109.134:39781
]
2014-07-13 16:30:47,121 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node124-mgt.dco.ethz.ch:39781 got disassociated, removing it.
2014-07-13 16:30:47,123 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]: Error [Association failed with [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node127-mgt.dco.ethz.ch/172.31.109.137:34515
]
2014-07-13 16:30:47,126 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node127-mgt.dco.ethz.ch:34515 got disassociated, removing it.
2014-07-13 16:30:47,127 [sparkMaster-akka.actor.default-dispatcher-37] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]: Error [Association failed with [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node136-mgt.dco.ethz.ch/172.31.109.146:49584
]
2014-07-13 16:30:47,127 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node136-mgt.dco.ethz.ch:49584 got disassociated, removing it.
2014-07-13 16:30:47,129 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]: Error [Association failed with [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node129-mgt.dco.ethz.ch/172.31.109.139:44845
]
2014-07-13 16:30:47,129 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node129-mgt.dco.ethz.ch:44845 got disassociated, removing it.
2014-07-13 16:30:47,131 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]: Error [Association failed with [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node130-mgt.dco.ethz.ch/172.31.109.140:48548
]
2014-07-13 16:30:47,131 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548 got disassociated, removing it.
2014-07-13 16:30:47,136 [sparkMaster-akka.actor.default-dispatcher-30] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]: Error [Association failed with [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node130-mgt.dco.ethz.ch/172.31.109.140:48548
]
2014-07-13 16:30:47,136 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node130-mgt.dco.ethz.ch:48548 got disassociated, removing it.
2014-07-13 16:30:47,252 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212 got disassociated, removing it.
2014-07-13 16:30:47,253 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203731-dco-node123-mgt.dco.ethz.ch-58212 on dco-node123-mgt.dco.ethz.ch:58212
2014-07-13 16:30:47,253 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 3
2014-07-13 16:30:47,253 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212 got disassociated, removing it.
2014-07-13 16:30:47,253 [sparkMaster-akka.actor.default-dispatcher-14] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.133%3A46409-16#-757274171] was not delivered. [17] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,259 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]: Error [Association failed with [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node123-mgt.dco.ethz.ch/172.31.109.133:58212
]
2014-07-13 16:30:47,259 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212 got disassociated, removing it.
2014-07-13 16:30:47,264 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]: Error [Association failed with [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node123-mgt.dco.ethz.ch/172.31.109.133:58212
]
2014-07-13 16:30:47,264 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212 got disassociated, removing it.
2014-07-13 16:30:47,269 [sparkMaster-akka.actor.default-dispatcher-13] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]: Error [Association failed with [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node123-mgt.dco.ethz.ch/172.31.109.133:58212
]
2014-07-13 16:30:47,269 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node123-mgt.dco.ethz.ch:58212 got disassociated, removing it.
2014-07-13 16:30:47,305 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773 got disassociated, removing it.
2014-07-13 16:30:47,305 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node131-mgt.dco.ethz.ch-51773 on dco-node131-mgt.dco.ethz.ch:51773
2014-07-13 16:30:47,305 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 0
2014-07-13 16:30:47,305 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773 got disassociated, removing it.
2014-07-13 16:30:47,305 [sparkMaster-akka.actor.default-dispatcher-48] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.141%3A48526-1#1176888559] was not delivered. [18] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,310 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082 got disassociated, removing it.
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node134-mgt.dco.ethz.ch-39082 on dco-node134-mgt.dco.ethz.ch:39082
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 6
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081 got disassociated, removing it.
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node133-mgt.dco.ethz.ch-48081 on dco-node133-mgt.dco.ethz.ch:48081
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 5
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082 got disassociated, removing it.
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081 got disassociated, removing it.
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-37] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.144%3A48606-12#-1038979951] was not delivered. [19] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,311 [sparkMaster-akka.actor.default-dispatcher-37] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.143%3A51362-9#457802611] was not delivered. [20] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,313 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]: Error [Association failed with [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node131-mgt.dco.ethz.ch/172.31.109.141:51773
]
2014-07-13 16:30:47,313 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773 got disassociated, removing it.
2014-07-13 16:30:47,319 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]: Error [Association failed with [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node134-mgt.dco.ethz.ch/172.31.109.144:39082
]
2014-07-13 16:30:47,320 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082 got disassociated, removing it.
2014-07-13 16:30:47,321 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]: Error [Association failed with [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node133-mgt.dco.ethz.ch/172.31.109.143:48081
]
2014-07-13 16:30:47,322 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081 got disassociated, removing it.
2014-07-13 16:30:47,322 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]: Error [Association failed with [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node131-mgt.dco.ethz.ch/172.31.109.141:51773
]
2014-07-13 16:30:47,323 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773 got disassociated, removing it.
2014-07-13 16:30:47,328 [sparkMaster-akka.actor.default-dispatcher-30] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]: Error [Association failed with [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node133-mgt.dco.ethz.ch/172.31.109.143:48081
]
2014-07-13 16:30:47,329 [sparkMaster-akka.actor.default-dispatcher-13] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081 got disassociated, removing it.
2014-07-13 16:30:47,329 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]: Error [Association failed with [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node134-mgt.dco.ethz.ch/172.31.109.144:39082
]
2014-07-13 16:30:47,329 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082 got disassociated, removing it.
2014-07-13 16:30:47,332 [sparkMaster-akka.actor.default-dispatcher-27] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]: Error [Association failed with [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node131-mgt.dco.ethz.ch/172.31.109.141:51773
]
2014-07-13 16:30:47,332 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node131-mgt.dco.ethz.ch:51773 got disassociated, removing it.
2014-07-13 16:30:47,336 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]: Error [Association failed with [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node133-mgt.dco.ethz.ch/172.31.109.143:48081
]
2014-07-13 16:30:47,336 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node133-mgt.dco.ethz.ch:48081 got disassociated, removing it.
2014-07-13 16:30:47,338 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]: Error [Association failed with [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node134-mgt.dco.ethz.ch/172.31.109.144:39082
]
2014-07-13 16:30:47,338 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node134-mgt.dco.ethz.ch:39082 got disassociated, removing it.
2014-07-13 16:30:47,342 [sparkWorker-akka.actor.default-dispatcher-15] INFO  org.apache.spark.deploy.worker.Worker - Executor app-20140713161037-0010/9 finished with state FAILED message Command exited with code 143 exitStatus 143
2014-07-13 16:30:47,344 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - Removing executor app-20140713161037-0010/9 because it is FAILED
2014-07-13 16:30:47,345 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - Launching executor app-20140713161037-0010/17 on worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479
2014-07-13 16:30:47,364 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480 got disassociated, removing it.
2014-07-13 16:30:47,364 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node126-mgt.dco.ethz.ch-60480 on dco-node126-mgt.dco.ethz.ch:60480
2014-07-13 16:30:47,364 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 1
2014-07-13 16:30:47,364 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480 got disassociated, removing it.
2014-07-13 16:30:47,365 [sparkMaster-akka.actor.default-dispatcher-17] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.136%3A56139-7#590239499] was not delivered. [21] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,373 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]: Error [Association failed with [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node126-mgt.dco.ethz.ch/172.31.109.136:60480
]
2014-07-13 16:30:47,373 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480 got disassociated, removing it.
2014-07-13 16:30:47,378 [sparkMaster-akka.actor.default-dispatcher-27] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]: Error [Association failed with [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node126-mgt.dco.ethz.ch/172.31.109.136:60480
]
2014-07-13 16:30:47,378 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480 got disassociated, removing it.
2014-07-13 16:30:47,383 [sparkMaster-akka.actor.default-dispatcher-27] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]: Error [Association failed with [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node126-mgt.dco.ethz.ch/172.31.109.136:60480
]
2014-07-13 16:30:47,383 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node126-mgt.dco.ethz.ch:60480 got disassociated, removing it.
2014-07-13 16:30:47,416 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826 got disassociated, removing it.
2014-07-13 16:30:47,416 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203731-dco-node122-mgt.dco.ethz.ch-45826 on dco-node122-mgt.dco.ethz.ch:45826
2014-07-13 16:30:47,416 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 16
2014-07-13 16:30:47,416 [sparkMaster-akka.actor.default-dispatcher-40] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.AssociationHandle$Disassociated] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A34550-14#-1505753480] was not delivered. [22] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,416 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826 got disassociated, removing it.
2014-07-13 16:30:47,416 [sparkMaster-akka.actor.default-dispatcher-40] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A34550-14#-1505753480] was not delivered. [23] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,422 [sparkMaster-akka.actor.default-dispatcher-27] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]: Error [Association failed with [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:45826
]
2014-07-13 16:30:47,422 [sparkMaster-akka.actor.default-dispatcher-27] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826 got disassociated, removing it.
2014-07-13 16:30:47,426 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839 got disassociated, removing it.
2014-07-13 16:30:47,426 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node125-mgt.dco.ethz.ch-42839 on dco-node125-mgt.dco.ethz.ch:42839
2014-07-13 16:30:47,426 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 2
2014-07-13 16:30:47,427 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839 got disassociated, removing it.
2014-07-13 16:30:47,427 [sparkMaster-akka.actor.default-dispatcher-30] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.135%3A58270-6#684695940] was not delivered. [24] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,427 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]: Error [Association failed with [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:45826
]
2014-07-13 16:30:47,428 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826 got disassociated, removing it.
2014-07-13 16:30:47,433 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]: Error [Association failed with [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node125-mgt.dco.ethz.ch/172.31.109.135:42839
]
2014-07-13 16:30:47,433 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839 got disassociated, removing it.
2014-07-13 16:30:47,433 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]: Error [Association failed with [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:45826
]
2014-07-13 16:30:47,433 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node122-mgt.dco.ethz.ch:45826 got disassociated, removing it.
2014-07-13 16:30:47,435 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810 got disassociated, removing it.
2014-07-13 16:30:47,435 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node132-mgt.dco.ethz.ch-60810 on dco-node132-mgt.dco.ethz.ch:60810
2014-07-13 16:30:47,435 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 12
2014-07-13 16:30:47,436 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810 got disassociated, removing it.
2014-07-13 16:30:47,437 [sparkMaster-akka.actor.default-dispatcher-37] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.142%3A36711-10#-1489637378] was not delivered. [25] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,440 [sparkMaster-akka.actor.default-dispatcher-30] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]: Error [Association failed with [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node125-mgt.dco.ethz.ch/172.31.109.135:42839
]
2014-07-13 16:30:47,440 [sparkMaster-akka.actor.default-dispatcher-14] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839 got disassociated, removing it.
2014-07-13 16:30:47,442 [sparkMaster-akka.actor.default-dispatcher-37] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]: Error [Association failed with [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node132-mgt.dco.ethz.ch/172.31.109.142:60810
]
2014-07-13 16:30:47,442 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810 got disassociated, removing it.
2014-07-13 16:30:47,443 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]: Error [Association failed with [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node125-mgt.dco.ethz.ch/172.31.109.135:42839
]
2014-07-13 16:30:47,443 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node125-mgt.dco.ethz.ch:42839 got disassociated, removing it.
2014-07-13 16:30:47,446 [sparkMaster-akka.actor.default-dispatcher-30] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]: Error [Association failed with [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node132-mgt.dco.ethz.ch/172.31.109.142:60810
]
2014-07-13 16:30:47,447 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810 got disassociated, removing it.
2014-07-13 16:30:47,449 [sparkMaster-akka.actor.default-dispatcher-30] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]: Error [Association failed with [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node132-mgt.dco.ethz.ch/172.31.109.142:60810
]
2014-07-13 16:30:47,449 [sparkMaster-akka.actor.default-dispatcher-30] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node132-mgt.dco.ethz.ch:60810 got disassociated, removing it.
2014-07-13 16:30:47,549 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580 got disassociated, removing it.
2014-07-13 16:30:47,549 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node135-mgt.dco.ethz.ch-58580 on dco-node135-mgt.dco.ethz.ch:58580
2014-07-13 16:30:47,549 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 4
2014-07-13 16:30:47,549 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580 got disassociated, removing it.
2014-07-13 16:30:47,549 [sparkMaster-akka.actor.default-dispatcher-48] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.145%3A43510-4#1980576746] was not delivered. [26] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,554 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]: Error [Association failed with [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node135-mgt.dco.ethz.ch/172.31.109.145:58580
]
2014-07-13 16:30:47,554 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580 got disassociated, removing it.
2014-07-13 16:30:47,557 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]: Error [Association failed with [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node135-mgt.dco.ethz.ch/172.31.109.145:58580
]
2014-07-13 16:30:47,557 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580 got disassociated, removing it.
2014-07-13 16:30:47,560 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]: Error [Association failed with [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node135-mgt.dco.ethz.ch/172.31.109.145:58580
]
2014-07-13 16:30:47,561 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node135-mgt.dco.ethz.ch:58580 got disassociated, removing it.
2014-07-13 16:30:47,670 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757 got disassociated, removing it.
2014-07-13 16:30:47,671 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node128-mgt.dco.ethz.ch-51757 on dco-node128-mgt.dco.ethz.ch:51757
2014-07-13 16:30:47,671 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 10
2014-07-13 16:30:47,671 [sparkMaster-akka.actor.default-dispatcher-48] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.138%3A44780-8#344071476] was not delivered. [27] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,671 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757 got disassociated, removing it.
2014-07-13 16:30:47,672 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479 got disassociated, removing it.
2014-07-13 16:30:47,672 [sparkMaster-akka.actor.default-dispatcher-17] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.AssociationHandle$Disassociated] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A57961-3#864166280] was not delivered. [28] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,672 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - Removing worker worker-20140710203730-dco-node121-mgt.dco.ethz.ch-60479 on dco-node121-mgt.dco.ethz.ch:60479
2014-07-13 16:30:47,672 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - Telling app of lost executor: 17
2014-07-13 16:30:47,672 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479 got disassociated, removing it.
2014-07-13 16:30:47,672 [sparkMaster-akka.actor.default-dispatcher-17] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A57961-3#864166280] was not delivered. [29] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:30:47,675 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]: Error [Association failed with [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node128-mgt.dco.ethz.ch/172.31.109.138:51757
]
2014-07-13 16:30:47,675 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757 got disassociated, removing it.
2014-07-13 16:30:47,676 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]: Error [Association failed with [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:60479
]
2014-07-13 16:30:47,676 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479 got disassociated, removing it.
2014-07-13 16:30:47,678 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]: Error [Association failed with [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node128-mgt.dco.ethz.ch/172.31.109.138:51757
]
2014-07-13 16:30:47,678 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757 got disassociated, removing it.
2014-07-13 16:30:47,679 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]: Error [Association failed with [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:60479
]
2014-07-13 16:30:47,679 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479 got disassociated, removing it.
2014-07-13 16:30:47,682 [sparkMaster-akka.actor.default-dispatcher-37] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]: Error [Association failed with [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node128-mgt.dco.ethz.ch/172.31.109.138:51757
]
2014-07-13 16:30:47,682 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node128-mgt.dco.ethz.ch:51757 got disassociated, removing it.
2014-07-13 16:30:47,684 [sparkMaster-akka.actor.default-dispatcher-37] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]: Error [Association failed with [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:60479
]
2014-07-13 16:30:47,685 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://sparkWorker@dco-node121-mgt.dco.ethz.ch:60479 got disassociated, removing it.
2014-07-13 16:31:05,548 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Registering app Simple Application
2014-07-13 16:31:05,548 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Registered app Simple Application with ID app-20140713163105-0012
2014-07-13 16:31:06,341 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295 got disassociated, removing it.
2014-07-13 16:31:06,341 [sparkMaster-akka.actor.default-dispatcher-17] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A41221-111#-1828781340] was not delivered. [30] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:31:06,341 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713163105-0012
2014-07-13 16:31:06,346 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:59295
]
2014-07-13 16:31:06,350 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:59295
]
2014-07-13 16:31:06,353 [sparkMaster-akka.actor.default-dispatcher-37] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:59295
]
2014-07-13 16:31:06,366 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 16:31:06,366 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 16:31:06,389 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295 got disassociated, removing it.
2014-07-13 16:31:06,390 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295 got disassociated, removing it.
2014-07-13 16:31:06,390 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295 got disassociated, removing it.
2014-07-13 16:31:06,390 [sparkMaster-akka.actor.default-dispatcher-48] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:59295 got disassociated, removing it.
2014-07-13 16:31:45,181 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Registering app Simple Application
2014-07-13 16:31:45,181 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Registered app Simple Application with ID app-20140713163145-0013
2014-07-13 16:32:02,879 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826 got disassociated, removing it.
2014-07-13 16:32:02,880 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713163145-0013
2014-07-13 16:32:02,880 [sparkMaster-akka.actor.default-dispatcher-5] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A41230-115#1777306382] was not delivered. [31] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:32:02,885 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:60826
]
2014-07-13 16:32:02,889 [sparkMaster-akka.actor.default-dispatcher-48] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:60826
]
2014-07-13 16:32:02,893 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:60826
]
2014-07-13 16:32:02,907 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 16:32:02,907 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 16:32:02,937 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826 got disassociated, removing it.
2014-07-13 16:32:02,937 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826 got disassociated, removing it.
2014-07-13 16:32:02,937 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826 got disassociated, removing it.
2014-07-13 16:32:02,937 [sparkMaster-akka.actor.default-dispatcher-40] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:60826 got disassociated, removing it.
2014-07-13 16:32:17,323 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828 got disassociated, removing it.
2014-07-13 16:32:17,323 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713161037-0010
2014-07-13 16:32:17,323 [sparkMaster-akka.actor.default-dispatcher-17] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.131%3A42161-58#1240901123] was not delivered. [32] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:32:17,328 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:44828
]
2014-07-13 16:32:17,332 [sparkMaster-akka.actor.default-dispatcher-17] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:44828
]
2014-07-13 16:32:17,335 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]: Error [Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node121-mgt.dco.ethz.ch/172.31.109.131:44828
]
2014-07-13 16:32:17,347 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 16:32:17,347 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 16:32:17,378 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828 got disassociated, removing it.
2014-07-13 16:32:17,378 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828 got disassociated, removing it.
2014-07-13 16:32:17,378 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828 got disassociated, removing it.
2014-07-13 16:32:17,379 [sparkMaster-akka.actor.default-dispatcher-5] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node121-mgt.dco.ethz.ch:44828 got disassociated, removing it.
2014-07-13 16:32:32,585 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Registering app Simple Application
2014-07-13 16:32:32,585 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Registered app Simple Application with ID app-20140713163232-0014
2014-07-13 16:32:33,363 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206 got disassociated, removing it.
2014-07-13 16:32:33,363 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713163232-0014
2014-07-13 16:32:33,364 [sparkMaster-akka.actor.default-dispatcher-17] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A41335-122#295485912] was not delivered. [33] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:32:33,368 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:50206
]
2014-07-13 16:32:33,372 [sparkMaster-akka.actor.default-dispatcher-5] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:50206
]
2014-07-13 16:32:33,375 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:50206
]
2014-07-13 16:32:33,385 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 16:32:33,385 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 16:32:33,418 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206 got disassociated, removing it.
2014-07-13 16:32:33,418 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206 got disassociated, removing it.
2014-07-13 16:32:33,418 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206 got disassociated, removing it.
2014-07-13 16:32:33,418 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:50206 got disassociated, removing it.
2014-07-13 16:32:58,891 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Registering app Simple Application
2014-07-13 16:32:58,892 [sparkMaster-akka.actor.default-dispatcher-17] INFO  org.apache.spark.deploy.master.Master - Registered app Simple Application with ID app-20140713163258-0015
2014-07-13 16:33:42,606 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896 got disassociated, removing it.
2014-07-13 16:33:42,606 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - Removing app app-20140713163258-0015
2014-07-13 16:33:42,606 [sparkMaster-akka.actor.default-dispatcher-40] INFO  akka.actor.LocalActorRef - Message [akka.remote.transport.ActorTransportAdapter$DisassociateUnderlying] from Actor[akka://sparkMaster/deadLetters] to Actor[akka://sparkMaster/system/transports/akkaprotocolmanager.tcp0/akkaProtocol-tcp%3A%2F%2FsparkMaster%40172.31.109.132%3A41338-126#840464120] was not delivered. [34] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.
2014-07-13 16:33:42,611 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:42896
]
2014-07-13 16:33:42,615 [sparkMaster-akka.actor.default-dispatcher-40] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:42896
]
2014-07-13 16:33:42,618 [sparkMaster-akka.actor.default-dispatcher-14] ERROR akka.remote.EndpointWriter - AssociationError [akka.tcp://sparkMaster@dco-node121.dco.ethz.ch:7077] -> [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]: Error [Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]] [
akka.remote.EndpointAssociationException: Association failed with [akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896]
Caused by: akka.remote.transport.netty.NettyTransport$$anonfun$associate$1$$anon$2: Connection refused: dco-node122-mgt.dco.ethz.ch/172.31.109.132:42896
]
2014-07-13 16:33:42,628 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.SecurityManager - Changing view acls to: root
2014-07-13 16:33:42,628 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-13 16:33:42,656 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896 got disassociated, removing it.
2014-07-13 16:33:42,657 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896 got disassociated, removing it.
2014-07-13 16:33:42,657 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896 got disassociated, removing it.
2014-07-13 16:33:42,657 [sparkMaster-akka.actor.default-dispatcher-37] INFO  org.apache.spark.deploy.master.Master - akka.tcp://spark@dco-node122-mgt.dco.ethz.ch:42896 got disassociated, removing it.
